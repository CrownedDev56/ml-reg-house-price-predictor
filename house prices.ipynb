{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "perfect-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error \n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning)\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "active-batman",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First : Processing the dataset\n",
    "\n",
    "def get_data():\n",
    "    #get train data\n",
    "    train_data_path ='train.csv'\n",
    "    train = pd.read_csv(train_data_path)\n",
    "    \n",
    "    #get test data\n",
    "    test_data_path ='test.csv'\n",
    "    test = pd.read_csv(test_data_path)\n",
    "    \n",
    "    return train , test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immune-finding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_data():\n",
    "    # reading train data\n",
    "    \n",
    "    train, test = get_data()\n",
    "    \n",
    "    target = train.SalePrice\n",
    "    train.drop(['SalePrice'], axis = 1, inplace = True)\n",
    "    \n",
    "    combined = train.append(test)\n",
    "    combined.reset_index(inplace=True)\n",
    "    combined.drop(['index', 'Id'], inplace=True,axis=1)\n",
    "    return combined, target   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "russian-semiconductor",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load train and test data into pandas DataFrames\n",
    "train_data, test_data = get_data()\n",
    "\n",
    "#Combine train and test data to process them together\n",
    "combined, target = get_combined_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sapphire-davis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtFinSF2</th>\n",
       "      <th>...</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2433.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2896.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2918.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "      <td>2919.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>57.137718</td>\n",
       "      <td>69.305795</td>\n",
       "      <td>10168.114080</td>\n",
       "      <td>6.089072</td>\n",
       "      <td>5.564577</td>\n",
       "      <td>1971.312778</td>\n",
       "      <td>1984.264474</td>\n",
       "      <td>102.201312</td>\n",
       "      <td>441.423235</td>\n",
       "      <td>49.582248</td>\n",
       "      <td>...</td>\n",
       "      <td>472.874572</td>\n",
       "      <td>93.709832</td>\n",
       "      <td>47.486811</td>\n",
       "      <td>23.098321</td>\n",
       "      <td>2.602261</td>\n",
       "      <td>16.062350</td>\n",
       "      <td>2.251799</td>\n",
       "      <td>50.825968</td>\n",
       "      <td>6.213087</td>\n",
       "      <td>2007.792737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.517628</td>\n",
       "      <td>23.344905</td>\n",
       "      <td>7886.996359</td>\n",
       "      <td>1.409947</td>\n",
       "      <td>1.113131</td>\n",
       "      <td>30.291442</td>\n",
       "      <td>20.894344</td>\n",
       "      <td>179.334253</td>\n",
       "      <td>455.610826</td>\n",
       "      <td>169.205611</td>\n",
       "      <td>...</td>\n",
       "      <td>215.394815</td>\n",
       "      <td>126.526589</td>\n",
       "      <td>67.575493</td>\n",
       "      <td>64.244246</td>\n",
       "      <td>25.188169</td>\n",
       "      <td>56.184365</td>\n",
       "      <td>35.663946</td>\n",
       "      <td>567.402211</td>\n",
       "      <td>2.714762</td>\n",
       "      <td>1.314964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1300.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1872.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>7478.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1953.500000</td>\n",
       "      <td>1965.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2007.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>50.000000</td>\n",
       "      <td>68.000000</td>\n",
       "      <td>9453.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1973.000000</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>368.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>480.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2008.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>11570.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2001.000000</td>\n",
       "      <td>2004.000000</td>\n",
       "      <td>164.000000</td>\n",
       "      <td>733.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>168.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2009.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>190.000000</td>\n",
       "      <td>313.000000</td>\n",
       "      <td>215245.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "      <td>1600.000000</td>\n",
       "      <td>5644.000000</td>\n",
       "      <td>1526.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1488.000000</td>\n",
       "      <td>1424.000000</td>\n",
       "      <td>742.000000</td>\n",
       "      <td>1012.000000</td>\n",
       "      <td>508.000000</td>\n",
       "      <td>576.000000</td>\n",
       "      <td>800.000000</td>\n",
       "      <td>17000.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2010.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MSSubClass  LotFrontage        LotArea  OverallQual  OverallCond  \\\n",
       "count  2919.000000  2433.000000    2919.000000  2919.000000  2919.000000   \n",
       "mean     57.137718    69.305795   10168.114080     6.089072     5.564577   \n",
       "std      42.517628    23.344905    7886.996359     1.409947     1.113131   \n",
       "min      20.000000    21.000000    1300.000000     1.000000     1.000000   \n",
       "25%      20.000000    59.000000    7478.000000     5.000000     5.000000   \n",
       "50%      50.000000    68.000000    9453.000000     6.000000     5.000000   \n",
       "75%      70.000000    80.000000   11570.000000     7.000000     6.000000   \n",
       "max     190.000000   313.000000  215245.000000    10.000000     9.000000   \n",
       "\n",
       "         YearBuilt  YearRemodAdd   MasVnrArea   BsmtFinSF1   BsmtFinSF2  ...  \\\n",
       "count  2919.000000   2919.000000  2896.000000  2918.000000  2918.000000  ...   \n",
       "mean   1971.312778   1984.264474   102.201312   441.423235    49.582248  ...   \n",
       "std      30.291442     20.894344   179.334253   455.610826   169.205611  ...   \n",
       "min    1872.000000   1950.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%    1953.500000   1965.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%    1973.000000   1993.000000     0.000000   368.500000     0.000000  ...   \n",
       "75%    2001.000000   2004.000000   164.000000   733.000000     0.000000  ...   \n",
       "max    2010.000000   2010.000000  1600.000000  5644.000000  1526.000000  ...   \n",
       "\n",
       "        GarageArea   WoodDeckSF  OpenPorchSF  EnclosedPorch    3SsnPorch  \\\n",
       "count  2918.000000  2919.000000  2919.000000    2919.000000  2919.000000   \n",
       "mean    472.874572    93.709832    47.486811      23.098321     2.602261   \n",
       "std     215.394815   126.526589    67.575493      64.244246    25.188169   \n",
       "min       0.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "25%     320.000000     0.000000     0.000000       0.000000     0.000000   \n",
       "50%     480.000000     0.000000    26.000000       0.000000     0.000000   \n",
       "75%     576.000000   168.000000    70.000000       0.000000     0.000000   \n",
       "max    1488.000000  1424.000000   742.000000    1012.000000   508.000000   \n",
       "\n",
       "       ScreenPorch     PoolArea       MiscVal       MoSold       YrSold  \n",
       "count  2919.000000  2919.000000   2919.000000  2919.000000  2919.000000  \n",
       "mean     16.062350     2.251799     50.825968     6.213087  2007.792737  \n",
       "std      56.184365    35.663946    567.402211     2.714762     1.314964  \n",
       "min       0.000000     0.000000      0.000000     1.000000  2006.000000  \n",
       "25%       0.000000     0.000000      0.000000     4.000000  2007.000000  \n",
       "50%       0.000000     0.000000      0.000000     6.000000  2008.000000  \n",
       "75%       0.000000     0.000000      0.000000     8.000000  2009.000000  \n",
       "max     576.000000   800.000000  17000.000000    12.000000  2010.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "waiting-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get columns that dont have any missing values\n",
    "\n",
    "def get_cols_with_no_nans(df,col_type):\n",
    "    '''\n",
    "    Arguments :\n",
    "    df : The dataframe to process\n",
    "    col_type : \n",
    "          num : to only get numerical columns with no nans\n",
    "          no_num : to only get nun-numerical columns with no nans\n",
    "          all : to get any columns with no nans    \n",
    "    '''\n",
    "    if (col_type == 'num'):\n",
    "        predictors = df.select_dtypes(exclude=['object'])\n",
    "    elif (col_type == 'no_num'):\n",
    "        predictors = df.select_dtypes(include=['object'])\n",
    "    elif (col_type == 'all'):\n",
    "        predictors = df\n",
    "    else :\n",
    "        print('Error : choose a type (num, no_num, all)')\n",
    "        return 0\n",
    "    cols_with_no_nans = []\n",
    "    for col in predictors.columns:\n",
    "        if not df[col].isnull().any():\n",
    "            cols_with_no_nans.append(col)\n",
    "    return cols_with_no_nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "asian-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = get_cols_with_no_nans(combined , 'num')\n",
    "cat_cols = get_cols_with_no_nans(combined , 'no_num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "following-notion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of numerical columns with no nan values : 25\n",
      "Number of nun-numerical columns with no nan values : 20\n"
     ]
    }
   ],
   "source": [
    "print ('Number of numerical columns with no nan values :',len(num_cols))\n",
    "print ('Number of nun-numerical columns with no nan values :',len(cat_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "foreign-thumbnail",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAtQAAAJOCAYAAACX0JDVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAACmpUlEQVR4nOzdeZhcVZ3/8feHPYY1BiKbBMegsgwIEVEcDSKyqTBuPxCFDCjq4IBOVAJuuKDRUVxQUVQmoGxRRBgE2TQyjGGLRgICEiBCSEggEEgQgYTv749zir5dXdVd1bV3f17P009XnXvr3lP3njr33HPPoojAzMzMzMyGZ61OR8DMzMzMrJe5QG1mZmZm1gAXqM3MzMzMGuACtZmZmZlZA1ygNjMzMzNrgAvUZmZmZmYNcIG6jSSFpJd26vNmZmaVSDpF0s/y64n5erNOB+IxRdKidu/X2kfSEZKuKrwfEWWbUVWglrRQ0jOSxpeFz8sndKKkbSRdJOkRSY9Lmi9pamHdYyTdKWmlpKWSfi1poybFb0tJP5G0JG//TkmflzS2Gdu31stp7E11rF/14iFpak6X725eDG006WQhyQWj2uTf+XxJf5f0kKQzJG3a6XiVk7S/pOvytelhSb+X9LZOx8v6k3SupLPKwt4gabmkLZu0jymSnpO0Kv89KOnztX4+Is6NiDdX2fZMSV9qRjzbbVQVqLP7gMNLbyTtAowpLP8p8ACwHfBC4EhgaV73DcCXgcMjYiPgFcCsZkRK0jhgTo7La/L29wM2Bf6pGfuwnnMU8Gj+X1UnapFscD1USHqLpJskPZkvuD+TtHWn4zVaSJoGfBX4BLAJsBfp2nO1pPWauJ+G8ghJ7wR+DpwDbANMAD4LvLXx2FmTHQ8cJGk/AEkbAD8CpkXEkkY3XkhLiyNiw4jYEHgdcIykQxvdfi8bjQXqn5IKySVHkTKJklcBMyPiyYhYHRF/iogrCsvmRMSfACLi0Yg4OyJWAkiaLen9pQ3li+r1Zfs/SNK9uQb8vySVzsF/AiuB90bEwrz9ByLihIi4tfxLSDpY0p8kPSHpAUmnFJZtkC+MyyWtkHSzpAmFON2baxnuk3REncfP6iRpfUnfkrQ4/30rh40FrgC2Ktzpb5U/sx3wBuBYYP/S+cvLpkhaJOlESQ8B/y1pLUnTJd2Tz/usfJNW+szPc8Hu8VzLtFN7j8Lo0WOFpPOAbwPjgZ2AZ4D/7cbC/0gjaWPg88B/RMRvIuLZnPe/m5RePi7pqbLf8SvztWPd/P5oSXdIekzSlTnfKK0bko6TdDdwdw77dr5ePCFprqR/qSGeAk4DvhgRP46IxyPiuYj4fUR8IK+zlqRPS/qbpGWSzpG0SV5WejJylKT7c/w/Vdj+mFwr+Zikv5CuszZMEbEc+A/gzHyN+RxwD3CnpD/kMsGfJU0pfUbSv+V0tDKXDz5YWDbgelNhn/cBfwB2zJ8Z8DSsWD6qUjZC0rHAEcAn8/Xwf5pxTNplNBaobwA2lvQKSWsD/w/4Wdny70k6TNKLyz57I6lw83lJe0tafxj7/1dgMrA7cAhwdA5/E/DLiHiuxu08Sbox2BQ4GPiw+u4OjyJdyLcl1bJ/CHgq/7i+AxyYa8BfC8wbxnew+nyKVKjaDdgV2BP4dEQ8CRxI4U4/IhbnzxwJ3BIRFwF3kDKZohcB40gX3mNJtRKHkgrhWwGPAd8rrH8FMAnYAvgjcG5zv6JBzxWSvgF8KT9+fSoiHgLeD/wdOCGv93yTkfy+34VysAuxDem1wAbAL4uBEbGK9HvdhfTU8h2Fxe8BfhERz+b8/mTg7cDmwP8C55ft41Dg1eSCDnAzKR8aR7qZ+rlSDeZgXka6lvxikHWm5r99gJcAGwLfLVvndXlb+wKflfSKHP450lPYfwL2Z4gncja0iPg5MJeUHo4llQF+DXyJdO4/DlwkafP8kWXAW4CNgX8Dvilp98Imy683/UiaBOxNKj81Eu8zSdemr+XrYU89ARmNBWroq6XeD7gTeLCw7F2kjOkzwH1K7atfBRAR/0vKvHYnJc7lkk7LBfNafTXXbN8PfIu+5icvBGp+HBMRsyNifq4puJX0w3lDXvxs3t5LI2JNRMyNiCfysueAnSWNiYglEXF7HXG34TkC+EJELIuIh0kFrvcN8ZkjSRc88v/yi8xzwOci4umIeAr4IPCpiFgUEU8DpwDvLBV8IuKsiFhZWLZrqQbJmqqXCkkvJj3GL8bzOeAioGL7xgqGuhBbdeOBRyJidYVlS/Ly88jXiHwTdBh9+cIHga9ExB15G18GdivegOXlj+Y8goj4WUQsz09fvwGsT0oLg3lhIU7VHAGcFhH35rR+EnCY+j9F+Xy+cfsz8GdS5QKkm81TczwfIFX6WOOOA94IfIGUbi6PiMtzmeFq4BbgIICI+HVE3BPJ74GrgOKNefn1BtKT1RWSngD+SqpwHFDrPJqM5gL1e0h31MXmHkTEYxExPSJ2IrUTmwf8KmdmRMQV+a5pHKmGeSqpVqdWDxRe/41UmwiwHKi5w4CkV0v6nVLnkMdJd6ClzpY/Ba4ELlBqYvA1SevmGtH/l9ddotSh8uV1xN2GZyvSuS4pnvcBJO0NbA9ckIPOA3aRtFthtYcj4h+F99sBF+cMbgWpVnsNMEHS2pJmKDUHeQJYmD/Tr3OuNUWvFJJK575SIWkJqTA/pBouxFbdI8B4VW66s2Ve/gvgNUpNwV4PBOkmC9Jv/tuF3/yjgIBiG/ji9QZJ0/IThcfzZzZh6HxgeSFO1VTK49YhXUNLHiq8/jupFrv02fLrojUoIpaS0tDtpLTyrlJayef+deRzKulASTdIejQvO4j+6aL8egPpyeqmEbEx6Un5U8DZrfxO3W5UFqgj4m+kzokHUVaTVLbeI8DXST/4cWXLnouIa4HfAjvn4CeBFxRWe1GFzW5beP1ioPSI/xrgX9XXpnoo5wGXAttGxCbAD0iZKfkx8+cjYkdSjdlbyO3GI+LKiNiP9EO6k9RZwVprMSlDKyme96iw/lGkczkvt1m7MYcX2/6Xf+4BUlOeTQt/G0TEg6Sbx0NIzYo2ASbmz2iY38eq65VC0iOFOFWK58NDfL6076EuxFbdHOBp0tOI5+WmeQcC10bECtJNyrtJv+PzI6L0238A+GDZb35MRPyhsLkobPdfgBPztjaLiE2Bxxk6H7gr7+sdg6xTKY9bTe7QP4QlDLwuWnM9APy0LK2MjYgZuenqRaSyzoScLi6nf7qodJ3qWxjxOKlMUmqi8WT+P1R5qOLmalyv64zKAnV2DPDGXGv7PElflbSzpHWUhsP7MLAgIpZLOiS3rd5MyZ6kZhaldkPzgLdLeoHSmIrHVNjvJ/LntyW1U7wwh59Gemx6dqk2StLWuUnJP1fYzkbAoxHxjxyP9xS+wz6SdslNUZ4gNQFZI2mCpLflDPtpYBWpFtOaa12ljqEb5Efv5wOflrS50pCNn6Wv3f5S4IXq68CzAemCdyzpMX7p7z+AI6oU1CDdUJ1aSDubSzokL9uIdL6XkzK4Lzfxu1p/vVRIWkRq4laM51qkgtPvc1DVSoIaL8RWRS6EfB44XdIBktaVNJHUDGcR6UkjpILKkaTzcl5hEz8ATlLuYCxpE0n9zmeZjUiF3IeBdSR9lnTNGSqeQeo0/xmlNvMbK3VCfJ2kM/Nq5wMfk7S9pA1JecyFVZ7UlJuVv8dmkrYh5XXWXD8D3qo09OHa+do0JR/v9UhPtR4GVks6kNqbfAGQz/lhpNpwctPGB4H35v0dTe2jlS0ltcPvOaO2QJ0fU95SYdELgIuBFcC9pLvu0libjwEfIHUGeoKUSP8rIkodvL5J6iW/lPToo1LHr0tInQXmkdph/yTH51FSbfKzwI2SVgLXki6OCyps59+BL+T1Pkv/4fteRKoFe4L06P/3Oa5rAdNItQmPkm4G/r3Ctq0xl5Mef5X+NiC1V7sVmE/qFPglgIi4k3QxujfX8L09f+aciHio9EdKJ2sDB1TZ57dJTyyuymniBlI7W0jNmv5GyuD+QoMdR6y6HiskfZx0o/cepZEWXgT8mFTDfHpedR7wekkvzjd9JxU20/CFeLSLiK+R2sx/nZRf30i6qdo393eA9LueBCzN7Y9Ln72YNJrMBUpNuW4j3bRVcyWpHf9fSfnBPyh72jFIPH9Bai54NOn6sZSUh12SVzmLlLavIz39/Qe1F4w/n+NzH+lG86eDr271ym3TDyGltYdJ5/0TwFqRRik7nlSGeIx0k39pDZt9fnQq0vkbR//O8x/I+1hOGkHoDwM3UdFPgB3zU7pf1fiZrqC+ihEzM2sGSccAHyPVyjwB/AqYHhGP5eVjSB367s/9NYqffR/wSdLN/OPA1RFxdF4WwKSIWJDfrw2cSappfpJ0U//vwPsj4hql4TRfGhHvzQX7+4B1SzWH+SnGp0kXvDGkQtk7I+KuQny+R7pQPkIqwJ1Z2oak40g39OsD/wOsS3qi92mlYbl+FhHbNHo8zcy6nQvUZmaGpDeTnpbsGxHzOhwdM7OeMmqbfFhr5LZZNykNHH+78nSkksZJulrS3fn/ZoXPnCRpgaS7JO1fCN9Daba5BZK+I8ltM81aJCKuIo1atFeHo2Jm1nNcQ21NlQu9YyNildJEFdeTOl++ndSJcoak6aQOVCdK2pFUK7YnaTSVa4AdImKNpJvyZ28gtUv+TvTNWmlmZmbWFVxDbU2Vx6Ndld+um/+C1CGiNEbl2aTJKcjhF+QB4+8jdcDcU9KWwMYRMSd3oDqn8BkzMzOzrlFtCK6uMX78+Jg4cWLTt/vkk08yduzYpm93tO9z7ty5j5BGGZkLvBT4XkTcKGlCRCwBiIglkrbIH9ma/qNOLMphz+bX5eEDSDqWPB3qmDFj9th2274hTZ977jnWWqv37htHS7z/+te/PhIRNU0i0gqtyl/aqRP5SruUf7e5c+d2NL1Aa9NMJ8/lSN13p9NMO/KYkZwHNKreY9NIeun6AvXEiRO55ZZKo9s1Zvbs2UyZMqXp2x3t+5T0t4hYQ5rdbVPS7H07D/aRCmExSPjAwIgzSSMPMHny5Ciml04c82YYLfGW1NFZ0VqVv7RTr6aVWpR/t06nF2htmunkuRyp++50mmlHHjOS84BGtfOa1HtVYNYz8gQWs0ljJy/NzTjI/5fl1RbRf5asbUjjnC7Kr8vDzczMzLqKC9TWbOvkmunSWLtvIk1xfilpSm3y/9KEAJcCh0laX9L2pAkMbsrNQ1ZK2it3dDyy8BkzMzOzrtH1TT4qmTj910Ous3DGwW2IiVWwLvC7POHEWsCsiLhM0hxgVp7w4n7ylMcRcbukWaQZ/FYDx+UmI5CmfZ9JmnDiivxXt1rSCzjNWG8oT8/TdlnN1LIwp2Wr1/wHHx+Qjipx2rJeUMonK+WPJc1Oyz1ZoLau9lRETC4PjIjlwL6VPhARpwKnVgi/BRis/bWZmZlZx7nJh5mZmZlZA1ygNjMzMzNrgAvUZmZmZmYNcIHazLqSpJdJmlf4e0LSRyWdIunBQvhBhc+cJGmBpLsk7d/J+FvrSDpL0jJJtxXC6k4XkvaQND8v+04eUcjMrG4uUJtZV4qIuyJit4jYDdgD+DtwcV78zdKyiLgcQNKOwGHATqSxz7+fR5uxkWcm6RyXqzddnEGaZXVS/qu0TTOzIblAbWa9YF/gnogYbBarQ4ALIuLpiLgPWADs2ZbYWVtFxHXAozWuXjFd5AmmNo6IORERwDnAoS2JsJmNeB42z8x6wWHA+YX3H5F0JHALMC0iHgO2Bm4orLMoh/Uj6VhSrSQTJkxg9uzZrYpzS0zbZXW/9xPGDAzrte9UzapVq+r9LvWki2fz6/LwAdqVZobxfZumUjqqpBXx6+T3NmsWF6jNrKtJWg94G3BSDjoD+CIQ+f83gKOBSu1fY0BAxJnAmQCTJ0+OKVOmND/SLVQ+ScG0XVbzjfn9s/KFR0xpY4xaZ/bs2dRxfupNFzWlF2hfmqnz+zbV6edeMiAdVdKKtNXJ723WLC5Qm1m3OxD4Y0QsBSj9B5D0I+Cy/HYRsG3hc9sAi9sVyW4yGmcHHUa6WJRfl4ebmdXNbajNrNsdTqG5R277WvKvQGmkh0uBwyStL2l7Uiezm9oWS+uoetNFRCwBVkraK4/ucSRwSVsjbWYjxpAF6irDE42TdLWku/P/zQrLPDyRmTWFpBcA+wG/LAR/LecltwL7AB8DiIjbgVnAX4DfAMdFxJo2R9naQNL5wBzgZZIWSTqG4aWLDwM/JnVUvAe4or3fxMxGilqafMwEvkvqAV0yHbg2ImZImp7fn1g2PNFWwDWSdsiZV2l4ohuAy0nDEznzMrOqIuLvwAvLwt43yPqnAqe2Ol7WWRFxeIXgnwyyfsV0ERG3ADs3MWrWQyS9DLiwEPQS4LPApsAHgIdz+MmFYRhPAo4B1gDHR8SVbYuwdbUha6irDE90CHB2fn02fUMNeXgiMzMz63oe696aabidEifk9mdExBJJW+TwhocngqGHKGrG0D6dGKZntOzTzMysxzw/1v0gLVKfrzQE7pNUGut+TpviaF2s2aN8NDw8EQw9RFH5sFGVDDW0TyeG6Rkt+zQzM+sxPTvWvSvOBipVvA42vnqzj9lwC9RLJW2Za6e3BJblcA9PZGZmZj2j18e6d8XZQKWK10rj9Jc0e0z14Q6bdylwVH59FH1DDXl4IjMzM+slA8a6j4g1EfEc8CNSsw7wWPc2iFqGzas0PNEMYD9Jd5OGtJoBHp7IzMzMeo7HureGDdnko8rwRJAa8Fda38MTmZmZWdcrjHX/wULw1yTtRmrOsbC0LCJul1SqNFyNx7q3Ak89bmZmZqOSx7q3ZvHU49Zs60r6naQ7JN0u6QTw7JpmZmY2crmG2lphWkT8UdJGwFxJVwNT8eyaZl1lYg1DkAIsnHFwi2NiZtbbXENtzfZsRPwRICJWAneQxun07JpmZmY2IrmG2lpG0kTglcCNtHB2zcEG0V+1ahXTdqmtz0g3DYzfqwP192q8zczMGuECtbWEpA2Bi4CPRsQTgzR/bnh2zcEG0Z89ezbfuP7JmuLc7EHeG9GrA/X3arzNzMwa4SYf1nSS1iUVps+NiF/m4KWlsT09u6aZmZmNJC5QWyv8BLgjIk4rhHl2TTMzMxuR3OTDmm1D4H3AfEnzctjJpNk0Z+WZNu8H3gVDDpT/YWAmMIY0uodH+DAzM7Ou4wK1NduqiKjWYNqza1pdJC0EVgJrgNURMVnSOOBCYCJpFrN3R8Rjef2TgGPy+sdHxJUdiLa1mKSzgLcAyyJi5xxWd7qQtAd9N+2XAyfkUYXMzOriJh9m1u32iYjdImJyfj+dNKb5JODa/J6yMc0PAL4vae1ORNhabibpHBcNJ12UxrqflP/Kt2lmVhMXqM2s19Q1pnn7o2etFhHXAY+WBXusezPrGDf5MLNuFsBVkgL4YR4isd4xzfsZbNzyXjBtl9X93k8YMzCs2Tp1jOoc17wjY903UyfHca81HbUifh6/3kYCF6jNrJvtHRGLc+Hoakl3DrJuTWOXDzZueS+YWjZd+LRdVvON+a3Nyjs1RnuTxjVv6Vj3zdTJcdxPP/eSmtJRK9KCx6+3kcBNPsysa0XE4vx/GXAxqQlHvWOa2+jgse6tbpIWSpovaZ6kW3LYOElXS7o7/9+ssP5JkhZIukvS/p2LuXWbUV9DPbGstqeahTMObnFMzKxI0lhgrYhYmV+/GfgCfWOaz2DgmObnSToN2Io8pnnbI26dUle6iIg1klZK2gu4kTTW/entj7Z1gX0i4pHC+1IH1xmSpuf3J5Z1cN0KuEbSDoWhXq3MaCpjjfoCtZl1rQnAxXna+nWA8yLiN5Jupv4xzW0EkXQ+MAUYL2kR8Dk81r01zyGk9AWpg+ts4EQKHVyB+ySVOj7P6UAcrcu4QG1mXSki7gV2rRC+nDrHNLeRJSIOr7LIY91bvXq+43M3d+qstcN0s+Nf2u9gnW2bvU8XqM3MzGy06vmOz93cqbO8E3U1ze7sWtrvYJ22m71Pd0o0MzOzUckdn61ZXKA2MzOzUUfSWEkblV6TOj7fRl8HVxjYwfUwSetL2h53fLYCN/kwMzOz0cgdn61pXKA2MzOzUccdn62Z3OTDzMzMzKwBrqE2MzMzs44ZCRPAuIbazMzMzKwBDRWoJS2UNF/SPEm35LBxkq6WdHf+v1lh/ZMkLZB0l6T9G428mZmZmVmnNaOGep+I2C0iJuf304FrI2IScG1+j6QdgcOAnYADgO9LWrsJ+zczMzMz65hWtKE+BJiSX58NzAZOzOEXRMTTwH2SFpAGUJ/TgjiYmVmTjIT2jWZmrdRogTqAqyQF8MM83eaEiFgCEBFL8nSekOa7v6Hw2UU5bABJxwLHAkyYMGHAfOu1zA0/1Bztq1atYvbs2W2dZ760z3bqxD7NzMzMRpNGC9R7R8TiXGi+WtKdg6yrCmFRacVcMD8TYPLkyVE+R30tc8MPNUf77NmzmTJlSlvnmS/ts506sU8zMzOz0aShNtQRsTj/XwZcTGrCsVTSlgD5/7K8+iJg28LHtwEWN7J/606SzpK0TNJthbC6O6tK2iN3el0g6TvK01mZmZmZdZNhF6gljZW0Uek18GbgNtJc90fl1Y4CLsmvLwUOk7S+pO2BScBNw92/dbWZpI6nRcPprHoGqenPpPxXvk0zMzOzjmukyccE4OJcabgOcF5E/EbSzcAsSccA9wPvAoiI2yXNAv4CrAaOi4g1DcXeulJEXCdpYllwXZ1VJS0ENo6IOQCSzgEOBa5ocfTNzMzM6jLsAnVE3AvsWiF8ObBvlc+cCpw63H1aT6u3s+qz+XV5+ACDdWJdtWoV03ap7b6tmzpv9mpn0l6Nt40c+WZ8JbAGWB0RkyWNAy4EJgILgXdHxGN5/ZOAY/L6x0fElR2Itpn1OE89bp1WrbNqUzqxzp49m29c/2RNEWlGx9Nm6dXOpM2Mt6RtgXOAFwHPAWdGxLclnQJ8AHg4r3pyRFyeP+PCkUGaH+GRwvtSk7MZkqbn9yeWNTnbCrhG0g5+empm9XKB2tplqaQtc+10LZ1VF+XX5eE2eqwGpkXEH3N/jbmSrs7LvhkRXy+u7MKRDcLzIzSJxyQ3q8wFamuXUmfVGQzsrHqepNNIhaBJwE0RsUbSSkl7ATcCRwKntz/a1im5iVCpmdBKSXdQpdlP5sKRQQvmRxhqboRm6WSTqQljapvjoVb1fI9OfW8/BbNmcoHamk7S+aTaoPGSFgGfIxWk6+2s+mHSiCFjSJ0R3SFxlMqdXF9JurnaG/iIpCOBW0i12I/RZYWjVikv9DS7INSIZh/LYRa0mj4/wlBzIzRLJ5t6nX7uJXxjfvOKBPU0oevg9/ZTsB5T6xOSTnCB2pouIg6vsqiuzqoRcQuwcxOjZj1I0obARcBHI+IJSWcAXyQVfL4IfAM4mi4rHLVK+WRU03ZZ3dSCUCOa3Q9hOAWt4vwIkvrNj1BHkzMbBfwUzJqpO3JhM7MKJK1LKkyfGxG/BIiIpYXlPwIuy297unDUzTUvvSLPibBWLhyV5kf4AnU2OWt7xK3jevkpWCeazMx/8PGa1pu2S4sjMoTBnuA1+5i5QG1mXSnPjPkT4I6IOK0QvmWpPSzwr6QJpcCFI/P8CDYMvf4UrNYnObXctNfambT8SVm3GuwJXrOfqI3YAvVQCWfaLqt7JkGYjVJ7A+8D5kual8NOBg6XtBvpQrYQ+CC4cGSeH8HqN5qegllrjdgCtZn1toi4nso1QpcP8hkXjsy6QDNrQ1vFT8GsmVygNjMzs9HIT8GsaVygNjMzs1HHT8GsmdbqdATMzMzMzHqZC9RmZmZmZg1wkw8zMzMz83j4DXANtZmZmZlZA1xDXaNa79pqHQao2dszMzMzs85wDbWZmZmZWQNcQ21mZk3hJ29mNlq5htrMzMzMrAGuoR5FXHtkZmZm1nwuUDfZYIXWabusZqqHpDEzM7Mmmf/g4y5bdAEXqM3MzKztShVQQ1U2+amp9QK3oTYzMzMza4BrqG0At7U2M+tuzqfNuosL1GZmLeSpfM3MRr62F6glHQB8G1gb+HFEzGh3HKx3OL1YvZxmul+tNxkzDxjb4ph0X3rxDVj367Y0Y92hrQVqSWsD3wP2AxYBN0u6NCL+0s54WG9werF6Oc1YPZxeekM3NW9xmrFq2l1DvSewICLuBZB0AXAI4IRolbQ1vTSzZsjtFjum4TTjGsJRpavymGm7rMYtMbte1+Ux03Zp6uZsmNr9y90aeKDwfhHw6vKVJB0LHJvfrpJ0V7MjcjyMBx5p9nabvU99teHdtux7Vonbdk3cRTPSS9vPM3T3eWuxeuPdzPQCNaSZduQv7dSJvKxd9vnqgO/W9vQC7UszrTiXdeRFHUtHzfrebbgmQRfmMSM5D2jUYMem2eml3QVqVQiLAQERZwJntjQi0i0RMbmV+xit+2yihtNLr35/x3v4UagQ1i/NtCN/aacuOOYt04bv1jXXJOjsuRyt+x6Grstjeuz4tVU7j027x6FeBGxbeL8NsLjNcbDe4fRi9XKasXo4vVi9nGasonYXqG8GJknaXtJ6wGHApW2Og/UOpxerl9OM1cPpxerlNGMVtbXJR0SslvQR4ErScDNnRcTt7YxDQSce+Y6WfTZFk9JLr35/x3sYuiyPaZdeTSu1aOl368L00slzOVr3XZcuTDPQQ8evA9rX9CZiQHMxMzMzMzOrUbubfJiZmZmZjSguUJuZmZmZNWBUFKglLZQ0X9I8SbfksHGSrpZ0d/6/WYP7OEvSMkm3FcKq7kPSSZIWSLpL0v5N3Ocpkh7M33WepIOauc9eIumA/F0XSJrepn02JR1I2iOn2QWSviNJOXx9SRfm8BslTSx85qi8j7slHVVnvLeV9DtJd0i6XdIJvRL30axS3taL6v3d9LJqv7WydaZIeryQj3+2ifsfNM0o+U7+nd4qafcm7PNlhe8yT9ITkj5atk7LvnMvqvKb2FXSnHz+/kfSxoVldeXHvaod16phi4gR/wcsBMaXhX0NmJ5fTwe+2uA+Xg/sDtw21D6AHYE/A+sD2wP3AGs3aZ+nAB+vsG5T9tkrf6TOIvcALwHWy999xzbstynpALgJeA1pzNMrgANz+L8DP8ivDwMuzK/HAffm/5vl15vVEe8tgd3z642Av+b4dX3cR/NfpbytF//q+d30+l+131rZOlOAyzqRZoCD8u9WwF7AjU3e/9rAQ8B27frOvfhX5TdxM/CG/Ppo4Iv5dd35ca/+teNaNdy/UVFDXcUhwNn59dnAoY1sLCKuAx6tcR+HABdExNMRcR+wgDSdaTP2WU1T9tlDnp8eNiKeAUrTw7ZUM9KBpC2BjSNiTqRf/Tllnylt6xfAvvmuen/g6oh4NCIeA64GDqgj3ksi4o/59UrgDtKMYF0fd+t9df5uetogv7VucQhwTiQ3AJvm33Wz7AvcExF/a+I2R5wqv4mXAdfl11cD78ivh5Mf96Q2XauGZbQUqAO4StJcpSlBASZExBJIJwjYogX7rbaPSlOXDjdDvR4YWxb2kfyo7qzCY49K+3yzpEXVNixppqQvDTNendbMY9yoetPB1vl1v3BJU4HXlT4TEauBx4EXDrKtuuWmGK8EbmxW3Ms/06q4j0JjgYVledsA+XF61d96l2pHHt1RZb+1cq+R9GdJV0jaqYm7rXQ9LGr17/Ew4Pwqy1r1nUeK24C35dfvom+CmeHkx4OStErSSxqKbYu18Fo1LD1foJZ0rqSzysLeIGl54a5674jYHTgQOE7S6+vcxxRJz+UEtjK3w/m3RqJdIaxZ4xeeAXwe2AXYFPhGG/bZjdr+fSV9JLdJvIvafpgCvinpTYWw8aTHelNyelsF/DeDxz3ytpB0iKR5wKeAUyRdmzOdUvv6Z0vbzX+fLPsOGwIXAR+NiCeGiHvVeFQIH+5nRhyltuQ/kfS3nJ/8SdKBw9zcqcA8+vK2kPRk4fyuqCNer5P0h9yO9VFJ/yfpVXnZVElrytLOd4cZZ2PI39ofSU0idgVOB37VxF0PdT2s9Hu8tCyfGkDSDyR9Zoh11iMVCH9eYXErv/NIcTTpnM0lNXd4JoeX8v/DJN0IHAn8BJgJbFPWNvj5vHWwSrOI2DAi7q01YjmPCEnvrucLDVeLr1XD0vMFauB44CBJ+wFI2gD4ETCtcLeyOP9fBlxMag6wtFTgzv+XVdq4pNLkN4sjYkNgY+BjwI8kvWyIuFXbR8umLo2IpaQf06OkAnWpWUelfT7SjH12qU5MD7sY+BIDLxaDpYPi5ErbAEvz6wU5Q9sQ+Ax9cX+G/L1y2tyEdK4XAzuRHltNIz3y+g/g+8BzhX1cWNpu/vtaaYGkdUkZ1LkR8csa4l7p+C7Kr8vD+32mLO6jbSrfdUg1Jm8gHYPPALNU6KRZhxXQL28D2LVwfjcdagOS1lHq3HQZqSAzjnRD+Hng6cKqc8rSzkeGEd961JRH9wqlzoBvyq8r/daeFxFPRMSq/PpyYF1J4wfZ9ja5cml5vqG6SYUO6WXbrnQ9LKr0e1xT2FfFG/OI+FBEfHGIw3AgqeC8rqSLJD2Sb+DmA2+PiFX5d/Br4J8K2//zENsdFSLizoh4c0TsQarlvycvWgQcDnwb+C/g96Rmcx8jtTleL6/3fN4qae0mR+8oUn4+aKfyQplq2NpwrRqWni9QR8RyUsHhTEljgc+REtmdubZlhVIvzil5+ZtJCWw86VHpvcD3gEug79GopBMlPUSqHSzuL3IG9yjwz/kzaymNIvF74OWSZkkaR5qO9KOSAvgOsKWkx4ANgH/L8XqC1PHjpsK2Pp1rr5ZJOkfSJqX9S3pfXrZc0qfKj4ekyaQL9bH5/9150aXA4Xl7jwP7ABuWffaVkv6Ya80uzPHsVW2fHjYifhkRvwIeK1t0NfDbXFt4D/ACSWuROkNsCvyPpCeByaTOEwArJe2VaxaOJKdP+mdYzwJ/I3XK+DLwRuB+0gXrzcAlEXFRRNw/VNzzfn4C3BERpxUWXVrY31GFeFwKHKZU27o9MAm4Kd/EVot7cVvvBH6b265dSWp+tJlSE6U357ARKSKejIhTImJhRDwXEZcB9wF7FPKfafn3v0SFp2GSXijpUqVREm4BXpHDS3lbTXLh7kRJtwJPAjvkuJ0fEWsi4qmIuCoibm3md69TtbTX0wb5rRXXeVFeD0l7kq7Vy6usO47U9O8Z0k31eOCbwAWSDi1bd6ykjUqvSWnmNvq7FDhSyV6kpllrytapemM+hMNJBcGfkm4qtyM1+zoSeKb0nbNFwEZ5+7vWuP0RTdIW+f9awKeBH+RFvyUVoI8H5pI6498UEVeTrg+vlDQT+Cqwe77e7DPEvkLSS3Ne/lCxAC7pX3PeUXq/HX3ljv0lTSgsG1CmKpWZJN2TyzKlMlPpMz/P+3xc0nUqNP9p07VqeKILem0244/UyelSUqazXf5/EPBPpELMauBO0qPwg4E9gGtJP9o1wJS8nSl53a+SeoWOyWGL8vK1SI+sngNemcM+SqrtXUoq5Kwitel5IfB/pMcIi0gF+TcD/wD+QuptfQ+plukN0ddzdwHpB7Eh8Evgp9HXW3UVqffv+vn7RI7vIuAY0uPfvwO3Ak8Anysco98DT5EK2e8jZaSl77UeqXD2MWBdUoHnWeBLnT63DaSJg0iZyT3Ap9q0z/OBlTl9lM7JN/Pru0kZ30Hw/Cylj5Huiu8i1d5MzOf01fn83AN8l/R4ampOTz/PaSRIF9JxOZ1+Mu93RU6/G5bF7RTgZ1Xi/bq8vVtzGpqX4/lC0u/k7vx/XOEzn8rxu4tC72jSjUG/uOfwDQpxvwl4SeEzpXS/APi3TqedNqfTCaQ84eX05T9fyL/Dg/LvebO87gXALFLb6QPoy29uz+cjgJdW2MeU0m89v1+Yz/G2Oe1sTMozz87pcLOyz08Frm/x72ZJ/j6l303VtNeLf/mYv6nst/Zn4OF87Ffk77k+8BHSjc5C4AbgQ/kzB+VtvQmYl19/Mf/e1irb34mkEXNEX74yKe/zz3n7v8zrfpp0PVlOupbdRbrJm59/zwuBN+V1T6FCPkJqXvClYnojPS1bls/tB/P2N8lpdrf8vT6UP/ORnI7/kuP6L50+Zx1OL5V+EyeQrml/BWbQl7ceQCrHDJYfP0F64rQ3qRyzQfGcVdj/83lJ3u5+hWU/J4+okd9/hlRIJaeZ/ywsm8LAMtVHc7reJof9EDi/8JmjSU1a1ge+VUrreVnLr1XDPmedTjRNTHwT8o/0BFJG8tOy5VcCR1X57K+AEwon/xlgg7IEUSqoPJ0T7kcLy+8A9i283zL/CNahLyPburB8OfD/Cu9L7YDICeHfC8teVtjWZ0m9VUvLxua4vqkQdndhWycBfy4suxc4oPD+WPoK1K8nFexUWP4HerhA3cG0+CVgZuH9F0h3vpUKOgvLzl8pvawo/H08L5tKoVCT13tj2fb2IhW4HiYV0maSC9akC+EzZdveqtPHazT/kQrN1wA/zO+nkG561ymssyyf17VzXvDywrIvV0gTTxTO73cK2y0vUB9dFpdX5PSyiHQBvJTU0aeU9laXpZ29On38eumv/Leew75AKlhsAWye89wvFpadnl+fTLrof7Ww7Nv59Q3A5yvsb3v6CtGlfKWYrmYD78+vXwrsRyrAbE4aSeJbleJO7QXqwW4MryFVDhwGvLhsOwPi6r8h09Z7gYfKwv6Qf6dPka7vM0mjt1Q8ZxW2WSxQfwk4K7/eiHQztl1h3cHKHVMYWKaqWmaqEI9Nc1w26fRxHuqv55t8lERqO/wI6Q53O+BdubnHivyo/XWkk4akAyXdoNTxZgXpx15sn/ZwRPyjbBeLI7VH3JjUfOONhWXbARcX9nUHqdA9obDO0sLrpyq8LzW/2IpUU1zyN1JhekJe9nxv1Yh4ksJjQEl7kzLRC3LQecAuknYrbLvY27W4n62AByOn4ArLbfj+i1TzepWke1XbJDPjI2LT/Pf1QdYrnk8i4oaIeHdEbA78CykjLTYNmlXY7qaR21Na++XHtj8lXWyK7ZGXRxoFpeTvpPxhc/raX5dU+o3uXji/xw8ShfK0c0dETI2IbYCdSXnCtwqr3FCWdm4Y4iva0I4AvhARyyLiYVK79fflZb8nPUaH9Dv+SuH9G/JySNeuJRW2XQrbfKhIRMSCiLg60tBiDwOnFfZVybuL11dJW1VY59n83Z6N1ExyFamCCNIIFf9Lqtm8T2kil1eVff6RwvY/PtR3GOWWA+NVaJ8cEa/NZZbl9DXvfaDCZ2txHvB2SesDbwf+GHnYwxrKHTCwTFW1zCRpbUkzcnOQJ0g3c9C/jNaVRkyBuswDpBrqYuY/NiJm5ARxEfB1Uu3LpsDl9O/xGQM3mRdEPE2qAd+l0D7tAdJjhOL+NoiIB4cR98WkxFbyYtKd/lJSBvl843pJLyA95ig5Kn+PebmtUmkopiPz/36fz9umsGzrsjZsxeU2TBGxMiKmRcRLgLcC/ylp39LiRjc/yH5vJjUZ2rnBfViTFdoBTgDeERHP1vCxh0l5QbXfcL0GSzt3kmqvnHZaq1IFSqlwOgfYIbdH3Y3U4Xhbpc6Je9I3HvEj5MqiMqWwh4eKhKQtJF2gNMvuE8DPGLwAU8uNebUbQyLisYiYHhE7kX4D84BflV1/aq1UsJRWnmbouRaGdb2JiL+Q0uaBwHtIheaSocodlfY7WJnpPfl7vInUPGhi/kylUTm6ykgtUP8MeKuk/fPdzga5Yfw2pLbC65MvTkrDVdXcmQcg0kQh3yA1wYDUMeDU3DAfSZtLGiphV3M+8DGlznQbkh7pXpgzpl8Ab1Ea3mo90uO0tfI+NwDeTWrGsVvh7z+AI/Kd6yzgJKXOX9vkZSVzSBfr45V6/b+dkT3xS9Pl47YB6dF8Kd2tI+ktuXOHSI/j19DXyWcpqb18M/b/OkkfKHRceTmpvb9rErvPGaQmFm+NiKdq+UBErCHdIJ0i6QWSdmSIHvW1kvRypY6Q2+T325I6kDnttFalCpTSKBx/J3UwO4E0W94zpMf4/0maGKU0StM1wDvyE4+id5Oa79xDekQP8ILC8hcVXn+FVOj554jYmNSEoC0FmPw9vk66kRg3xOpWQUSsID3d+L6kd0raMHf8242B81SUK12rSn/rVVnvPFKnx9eTR7KqsdxRyWBlpo1INwfLSen1y0PEv2uMyAJ1RDxAusM5mVRwfgD4BKnTxkpSophF6hD2HoY3+sNZwIslvZU0VM2lpEf6K0kXoVcPM/pnkR4DX0fqFPIPcsE3Im4HjiMl7CU5/qWByQ8lNR05JyIeKv2RasHWJnVa+DzpLvM+4Kq8H/K2nyE9ypmat/v/SBdvq92nSedgOumC9FQOm0S66K0i3bh8PyJm5898Bfh0kx5rriAVoOcrjV/9G9KwWLX2wLc2yBeRD5IuPA+pb2iwI2r4+EdItXwPkWqQ/7tJ0VpJyrNuVBoB4AZSZ51pTdq+JesWCy+kCpRP5wLFeFIlzc8K6/+edM5LzTtml72H1Ol5Y+AnSqODbCDpcFJzis9FGknmYeBB4L25kuloUof9ko1I+dMKSVuTrpctI+mrknbOFQ4bAR8mDRVacSQTG1qkkVb+k9Q5fRmpsuaHpCfqfxjko9NJ16rS32+rrHc+qT30bws3c4cydLmjksHKTOeQyikPkjqo9sxNfamHqJmZmbWIpIX0r42G9KRzPVKbYkg1f58stTeVtD/pxnhKRPxe0s6kURQOi4gLC9t+MWkUhf1JhesgdTg8u7DOgaRx6TcjFXgmk5pG/lhpWLJzSG2cF5AqWz6W29OX4v7+iLhG0imkzmrvLft+M0kdXz8taQqp4+I2heXFbZxOKmxtSSqQ3Qh8IiLuUBqH+j5g3bImI2ZdzQVqMzOzEUJpkp7/Ay6OiM8Otb6ZNceIbPJhZmY2GkWahvkgYI2kFw21vpk1hwvUZmbWM3Ib4Zsk/VnS7ZI+n8PHSbpa0t35/2aFz5wkaYGku3IzilL4Hkoz1i6Q9J2yUSZ6VkQ8EBGfz+1ZzawNXKA2M7Ne8jRpQqNdSR07D1CaIns6cG1ETCJNkDUdII+GchhpWu4DSCMhlKZRPoM0QsGk/FetE5WZ2aCqDWnSNcaPHx8TJ07sF/bkk08yduxQI8F0VrfHsVXxmzt37iN5UpGOqJReukW3p4mSdsazG9NLr5ynakZy/AvpZVUOWjf/BWlkpyk5/GzSiBgn5vAL8hwC90laAOyZO8ltHBFzACSdQxq14IrB4jeS0sxoiHc35jGd1I3nvJvi1Eh66foC9cSJE7nlllv6hc2ePZspU6Z0JkI16vY4tip+kjo6u2Kl9NItuj1NlLQznt2YXnrlPFUzkuNfSi+5hnkuacrs70XEjZImRMQSgIhYUhqPHdia/kNvLcphz9I37GgxvNJ+jyXVZDNhwgS+/vX+84ysWrWKDTfcsNJHu9poiPc+++zTdXlMJ3Vj/tBNcWrkmtT1BWrrPZLOAt4CLIuInXPYKcAH6Ju16+Q8HS2STgKOIU12cnxEXJnD9yCNtTuGNJvlCeFhacxGvTzJzW6SNiVNYTzYjI6V2kXHIOGV9ncmcCbA5MmTo/zi300Fgno43mbN4zbU1gozqdwW8ZsRsVv+KxWm3b7RzIYlzxA3m5Q3LJW0JUD+vyyvtoj+07VvQ5qNcFF+XR5uZlY311DbABOn/7qm9RbOOLhieERclwfnr0VT2zc2otHvbSPD/AcfZ2oNacHpoDMkbQ48GxErJI0B3kSa1ORS0lTsM/L/S/JHLgXOk3QaaXrrScBNEbFG0srcofFG4Ejg9OHEyWnGWsHXpN7iArW100ckHQncAkyLiMdoQfvG2bNnDyty03apbVKu4W5/1apVw/5sO/VKPG3U2hI4Oz/JWguYFRGXSZoDzJJ0DHA/efbBiLhd0izSNMargeNykxFIU17PJDUru4IW3rCb2cjmArW1yxnAF0ltFL9ImnL3aNrQvrFWtdQwASw8Ynjb75V2f70STxudIuJW4JUVwpcD+1b5zKnAqRXCbwEGa39tZlYTt6G2toiIpRGxJiKeA34E7JkXuX2jmZmZ9TQXqK0tSp2Fsn8FbsuvLwUOk7S+pO3pa9+4BFgpaa88e9mR9LWJNDMzM+sabvJhTSfpfNIEC+MlLQI+B0yRtBup2cZC4IPg9o1mZmbW+1ygtqaLiMMrBP9kkPXdvnEU87jlZmbD59FAuoObfJhZp83E45abmVkPc4HazDoqIq4DHq1x9efHLY+I+4DSuOVbksctz7XSpXHLzczMWs5NPsysW3Vk3PIJY2obk7xbx+ru9XHEez3+1n2qNCsbB1wITCT163l3zmPcrMyGxQVqM+tGHRu3/PRzL+Eb84fOGoc7Hnmr9fo44r0ef+tKM4Hvkp5clUwHro2IGZKm5/cnljUr2wq4RtIOubN8qVnZDaQC9QG4s7xlbvJhZl3H45abWbNUaVZ2CHB2fn02fU3E3KzMhsU11GbWdSRtmccih4Hjlp8n6TRS7VFp3PI1klZK2gu4kTRu+entjreZ9YwJpTwmIpZI2iKHt7xZWa1qaXpWj9mzZ3dlk6pujNNwuEBtZh3lccvNrIu0vFlZrabWOBxerRYeMaUrm1R1Y5yGo6ECtaRNgR+TxgoOUhvHu6izob+ZjV4et9zMOmBp6UlYbs6xLIe7WZkNS6NtqL8N/CYiXg7sCtxBX0P/ScC1+f1Q48eamZmZtculwFH59VHAJYXwwyStL2l7+pqVLQFWStpLkkjNyi4p36iNXsMuUEvaGHg9uSYpIp6JiBXU2dB/uPs3MzMzG0puVjYHeJmkRZKOAWYA+0m6G9gvvycibgdKzcp+w8BmZT8mlV/uwc3KrKCRJh8vIU0L/N+SdgXmAidQf0P/AYZq0N8LDdi7PY6Dxa/WjhDd/P3MzMygarMygH2rrO9mZVa3RgrU6wC7A/8RETdK+ja5eUcVTWvQ3wsN2Ls9joPFr9aOEN06Dq+ZmZlZOzXShnoRsCgibszvf0EqYC/NDfypsaG/mZmZmVnPGnaBOiIeAh6Q9LIctC+pzVFdDf2Hu38zMzMzs27Q6DjU/wGcK2k94F7g30iF9Fm50f/9wLtgyPFjzczMzMx6UkMF6oiYB0yusKiuhv5mZmZmZr2q0XGozczM2kbStpJ+J+kOSbdLOiGHj5N0taS78//NCp85SdICSXdJ2r8Qvoek+XnZd/L4wmZmdXOB2szMeslqYFpEvALYCzguTxw2nEnFziAN0Top/x3Qzi9iZiOHC9RmZtYzImJJRPwxv15JmqF3a+qcVCyPQrVxRMyJiADOKXzGzKwujXZKNBtA0lnAW4BlEbFzDhsHXAhMBBYC746Ix/Kyk4BjgDXA8RFxZQ7fA5gJjAEuB07IFz4zMyRNBF4J3Ej9k4o9m1+Xh1faz6CTjU0YU9uEWN02GVa3T0BWTa/G20Y2F6itFWYC3yXV+JSUHsfOkDQ9vz+x7HHsVsA1knbII8CUHsfeQCpQH4CnejUzQNKGwEXARyPiiUGaP1ebVKxpk42dfu4lfGP+0JfTbpsMq9snIKumV+NtI5ubfFjTRcR1wKNlwX4ca2ZNIWldUmH63Ij4ZQ6ud1KxRfl1ebiZWd1cQ23t0rHHsbWq5ZEtDP+xba88puyVeNrolEfi+AlwR0ScVlhUmlRsBgMnFTtP0mmkp2CTgJsiYo2klZL2IjUZORI4vU1fw8xGGBeordNa/ji2VlOn/7qm9Yb72LZXHlP2Sjxt1NobeB8wX9K8HHYyqSBd76RiH6avn8YVuEmZmQ2TC9SjyMRCgXHaLqtrLkA2yVJJW+baaT+Otee5E6vVIyKup/INN9Q5qVhE3ALs3LzYmdlo1ZMF6vkPPj5kYXDhjIPbFBurkR/HWjUzcSdWMzPrYe6UaE0n6XxgDvAySYvyI9gZwH6S7gb2y++JiNuB0uPY3zDwceyPSR0V78GFoxHJnVjNzKzX9WQNtXW3iDi8yiI/jrVaeUzhYer1TqW9Hn8zG51coDazXuIxhYfQ651Kez3+ZjY6NdzkQ9Lakv4k6bL8fpykqyXdnf9vVlj3JEkLJN0laf9G921mI5bHFDYzs57RjDbUJwB3FN6XOhNNAq7N7ynrTHQA8H1Jazdh/2Y28pQ6scLATqyHSVpf0vb0dWJdAqyUtFcep/jIwmfMzMxaqqECtaRtgINJHcdK6upM1Mj+zaz3uROrmZn1ukbbUH8L+CSwUSGs3s5EAzSj01CnO7V0Y8ea4jGrtePVYLrt+1lvcidWMzPrdcMuUEsqTcQwV9KUWj5SIaxlnYY63WGoGzvWTC2b2KWWjleD6fQxNjMzM+sGjZSo9gbeJukgYANgY0k/o/4Z8czMzMzMetaw21BHxEkRsU1ETCR1NvxtRLyXOjsTDTvmZmZmZmZdoBXjUM8AZuWORfcD74LUmUhSqTPRavp3JjLrGROHmPYeYOGMg9sQEzMzM+sGTSlQR8RsYHZ+vZw6OxOZmZmZmfWqZoxDbWZmZtZzJC2UNF/SPEm35DBPUGd1c4HazMzMRrN9ImK3iJic33uCOqubC9RmZmZmfTxBndWtFZ0SzczMzHpBAFdJCuCHeR6MhiaoG2pyulo1OvlaudmzZ3flpHPdGKfhcIHazMzMRqu9I2JxLjRfLenOQdataYK6oSanq9XUGkaUqsfCI6Z05aRz3Rin4XCTDzMzMxuVImJx/r8MuJjUhGNpnpgOT1BntXIN9QhQy7jIZmZm1kfSWGCtiFiZX78Z+AJ9E9TNYOAEdedJOg3YCk9QZwWuoTYzs54i6SxJyyTdVgire6gzSXvkIdMWSPqOpEqP9G3kmgBcL+nPpILxryPiN6SC9H6S7gb2y++JiNuB0gR1v8ET1FmBC9TWVh7z08yaYCZp2LKi4Qx1dgap89ik/Fe+TRvBIuLeiNg1/+2UJ58jIpZHxL4RMSn/f7TwmVMj4p8i4mURcUXnYm/dxgVq6wSP+WlmwxYR1wGPlgXXNdRZbhu7cUTMiYgAzil8xsysLm5Dbd3gEGBKfn02aRr7EylcCIH7JJXG/JzTgTiaWXerd6izZ/Pr8vABhhoGbcKY2oY467ahwXp1uLJejbeNbC5QW7uNijE/K8WhVy4C3RRPSQuBlcAaYHVETJY0DrgQmAgsBN4dEY/l9U8CjsnrHx8RV3Yg2tZdqg11VtMQaDD0MGinn3sJ35g/9OV04RFThlynnXp1uLJejbeNbC5QW7uNijE/K104e+Ui0IXx3CciHim8LzURmiFpen5/YlkToa2AayTt4E5Do8ZSSVvmm/JahjpblF+Xh5uZ1W3YBWpJ25LanL0IeA44MyK+7dojG0xxzE9J/cb8rONCWBcPKzjiuImQVVLXUGcRsUbSSkl7ATcCRwKntz/aZjYSNFJDvRqYFhF/lLQRMFfS1cBUXHtkFXjMTxuGtjcR6tX2sCXd1GRnOGqJv6TzSTdV4yUtAj5Hyj9mSToGuB94F6ShziSVhjpbTf+hzj5MGjFkDHBF/jMbkSZO/zXTdlk96NPYhTMObmOMRpZhF6jzBa10UVsp6Q7Sxcu1R1bNBODiPNTrOsB5EfEbSTdT/4XQRoe2NxHq1fawJV3YZKcutcQ/Ig6vsmjfKuufCpxaIfwWYOc6o2hmNkBT2lBLmgi8kvTYrKHao7y9hmuQOlVDM//Bx4EUx9PPvaTqertsvUnT9jmcznS11sINpt5jHBH3ArtWCF9OnRdCGx060UTIzMysXg0XqCVtCFwEfDQinhhkoqm29qhudu1R7e1wU7ym7bJ60Dg2M37D6Uw3VPxq0a01dDYyuImQmZn1ioZKVJLWJRWmz42IX+Zg1x6ZWTO4iZCZmfWERkb5EPAT4I6IOK2wyLVHZtaw0dZEqNanYO40ZGbWfRqpod4beB8wX9K8HHYyw+tp3XQeKs3MzMzM2qGRUT6up3K7aBiBtUdmZmZmZpWs1ekImJmZmZn1MheozczMzMwa4AK1mZmZmVkDmjKxi5mZVdbsDtJDbW/aLqufn6rWzLqPB00YmVyg7nL+4ZmZmZl1Nzf5MDMzMzNrgAvUZmZmZmYNcJOPDnFTDjMzM7ORwQVqsxaodMM0bZfVTC0L9zTSZmbWLWqt7PO1ayA3+TAzMzMza4AL1GZmZmZmDXCTDzOzEcaPbc3M2ss11GZmZmZmDXANtZnZMIyEkXpck21m1hxtr6GWdICkuyQtkDS93fu33uL0YvVymrF6OL1YvZxmrJK21lBLWhv4HrAfsAi4WdKlEfGXdsbDesNoSC+uIWyu0ZBmrHmcXqxeTjNWTbubfOwJLIiIewEkXQAcAjghWiVOL1Yvp5kWGME3fk4vVi+nGUZ0njBs7S5Qbw08UHi/CHh1+UqSjgWOzW9XSbqrbJXxwCMtiWGTHN/lcWxG/PTVisHbNbLNMs1KL12hkWNe5Vi3SjvTbjPTC9SQZkZC/jKYTuY9TUqng8W/7ekFmpdm2vw7rkWvpvV64t2NeUzHtDt/qDHNd1M6HHZ6aXeBWhXCYkBAxJnAmVU3It0SEZObGbFm6/Y4dnv8sqakl27RI8e8Z+JZxZBpZiTkL4Nx/OvbXYWwEXlNqsTxHt7uK4TVlcd0Ujee826M03C0u1PiImDbwvttgMVtjoP1DqcXq5fTjNXD6cXq5TRjFbW7QH0zMEnS9pLWAw4DLm1zHKx3OL1YvZxmrB5OL1YvpxmrqK1NPiJitaSPAFcCawNnRcTtw9hUVz5KKdPtcez2+DUzvXSLrj/mWa/Ec4AmpZme/f6Z41+jUXZNqsTxrtMIuC514znvxjjVTREDmouZmZmZmVmNPPW4mZmZmVkDXKA2MzMzM2tAVxSoJZ0laZmk2wphu0qaI2m+pP+RtHEOnyjpKUnz8t8PCp/ZI6+/QNJ3JFUa3qYdcTyiEL95kp6TtFteNjtPWVpatkWT4retpN9JukPS7ZJOyOHjJF0t6e78f7PCZ07Kx+ouSfsXwlt2HEeSXjrmktaW9CdJl3VrHLuBunBK4Sp5T8+cv176ndSrG9NLkaSF+XjNk3RLDqv7uLchnj2dxjupm39fo+66ExEd/wNeD+wO3FYIuxl4Q359NPDF/Hpicb2y7dwEvIY0TuQVwIGdiGPZ53YB7i28nw1MbsEx3BLYPb/eCPgrsCPwNWB6Dp8OfDW/3hH4M7A+sD1wD7B2q4/jSPrrpWMO/CdwHnBZft91cez0H6mD0T3AS4D18nHYsQviVSnv6Znz10u/k5GQXsriuBAYXxZW93FvQzx7Oo13+Bx37e+LUXbd6Yoa6oi4Dni0LPhlwHX59dXAOwbbhqQtgY0jYk6ks3AOcGgXxPFw4PxmxaOaiFgSEX/Mr1cCd5BmdDoEODuvdjZ9x+QQ4IKIeDoi7gMWAHu2+jiOJL1yzCVtAxwM/LgQ3FVx7BLPTykcEc8ApSmFO6pK3tMz569XfifD0JXppQZ1Hfd2RKjX03gndevvazRed7qiQF3FbcDb8ut30X8g9e3zY4TfS/qXHLY1acD1kkU5rJ1xfLGkkLQOpOYdwPsZWKD+7/wI7jONPL7Ij/PeVCF8IvBK4EZgQkQsgfTDA0pNTCpNn7o1nTmOPa+BY34E6a57Ud7O3qS7+GMkHdqk6H0L+CTwHPBCSYvqjONoSRfVvntT5TzipQ1upuXnT9JUSdc3GM/ybU5k5ORNTUkvkl4saZWktYfx2VMk/WyQVQK4StJcpemwof7jXm3fMyV9qd4416HX00fbddnv61vAK3J8Stoep2rlpFbo5gL10cBxkuaSHmM8k8OXAC+OiFeSHycotV2uaQrZeuQT8VTO7FYBt9N/7O7yOD5btomNgGci4rZ8cVoDvIr0SGMTUu31+2qMS02Zl6QNgYuAj0bEE4OtWiEsBgm3KiT9DbiKwjGvUhip5dh+AfglcEVE/Eqpzf0/chp8XNJ1knapI24B/CMi5tb6kSpxHA3poup3LMsLHpP0a0nbVli/0+o+f7lQFpKaWhspabKky/LxWiHpDmAO8KkRkjfVFZ/yC7ukwyQ9BmwfERtGxJocPlvS+5sUx70jYnfgQNK16vWDrFvx++T4PCZp/SbFKe0sff8bJT0paRlwMTCuhkqmXkkfdSmVM/Lfc8Wyh6QjqnxmSq4gKV775wDLgU3y7+4Pkl5T/FiFTQ37+Ekam+N4eSHsLcAy+sptQ26mQtjapArJ1+Q08iDwX8D4GrfZdl1boI6IOyPizRGxB6mG954c/nRELM+v5+bwHUh3LtsUNtGs6UDfmjO7DYGdgNWDxPFvZZ/dgtT+p2RORIzN23oHqWB9UBPiCICkdUk/qHMj4pc5eGl+bFJqFrMsh1ebPrVVx3FEysd8C+Da4jEn3TDVcsxXAE/Td8y3A1bR/5h/JKeZF5La4P+0zmjuK2kh6ZH0K4HNcLqoZKgphd+az8OWpHN8erMjUEctZVPOXy68vI/0uP2oBqLej6TXktLq/wEvBzbPcbyVvpqoXk+Dw56CWtJRwPeAgyPi9y2IGwARsTj/LxVY96S+4/4c8C+kgtXbaBJJ04BvkwpILwImAJ8CXkBqj06d8ezG9FGXUjkj5zH3Uyh7RMS5g322eO0nNfm4kNSWemfgd3lZq47fO0nXsDeXzhewNym9bEM6r2/MT1LqOacfIbWdfph0zdo+f5exVY5BWycqrKiWhtbt+KOssyGwRf6/FqndzNH5/eb0NVZ/CfAgMC6/vxnYi77G6wc1GKeFwJvK4vhMKYxUkDoF+FmO4ydIGc86Od5P09cAfypwPbmDCLAu6SL2k8L2fw48BDxOapu9Uw4/llT7/QypsPU/hfh9nHSRejy/P73sO/wX/TsBfC2/3on+nQDuLRzXph7HkfqXj885wBNl6eS/8rm8Ph/z35Nu/J4E/kFqHlQ65v+W17uZlKk8B6wBnsrnZjbw/sK2dyQ99Si935NUI7GC9PTmu8B6edl1OT0+mdPN5/O6i0gZ06r8mZ87XQT5d3tv/t6lTmal3+DCsnN8EPDX/Hp94Ouki+BS4AfAmMK6n8jHeTHpqVYAL83LZgJnAJfn8/Qm0mPS2fmc3k66ME0kNTHbJKe5vwOPAZ8GTiI1E5oK/JF0AVqR4/NgTmMPkPKQLxTPH6kz2FPAe0m1WusV4j2VVCA+nZS/3Ansm5cdBtxSdvw+BlyaX19Pzovo+518q2z9y/Nx/Wb+Pn/opTQ4WHqpsv7CfH6PBR4hd07P57Z03TiV9Pv/B+n3+d3CMbmadM1YCpycw08BZuXjuzKnl9J2xwKTSIWph/M2zyBfE/Jnb83paiWp3epfy47753IaOI3csazwfWaS0vrV+fO/B7bLy34AfL1s/UtIT5U3IaX1d5Qtn0j/MsBtwA05nTwDXNhL6aPBtLWQvnLG+qTmE4vz37dy2FjSb/c5+soHW9FXJimd5x1z+ir9HqfmdU/K6XA18HZSfvAP0m/9ZPryiD2BW0jXuaXAaWVx/S0p3f4R+HiF73FmTh+PAfOBT+dly4CLys7pI8BbSPnlU6SCddVzmrd/IikdP036Db2PVLm5nFSYf/5Ytvy8dTrh5INyfj6Az5Iu9scAJ5B+3H8FZsDzszq+g5Rp/DmfwLcWtjM5/wjvIRUs1MREXYpjkDKnUhyX54Q2g/4Z45Qc/v5CIv4DMDef/HtyAnh5YX9Hk5qJlH5A8wrLZgJfqhC/m0g/ogPzvhcB8/LfQaRazWuBu/P/cYXPfyrH4y4KPWebfRxH6h/wunzMnyFdjIrH/C85Q7iWVKDZinSTdQEpA1yQz9lUUuGjdMyfBX5VSO+zC2loPVLGdV0hDnuQMpt1cvq7g9T0pLS8WHibQipQryZltr8lFbjWkB47j/p0kc/fX/N3/FQhfCF9ecELSB1qzsnvvwVcCozLv9//Ab6Slx1AugjtTLoAnsfAAvXjpBqdtfLnF5AuaOsBb8xpYln+/yTwJ9KTjP/Lae8ved9T87m9KMd/ef7c90h5ynH5XN9bOn/AT0gFsnXz+m8vfOfS9j6Wl/+/HNdx+RisBCYV1r+ZVNAem/czpex3civ986bjSL+FZTktbtVrabBaeqmy7sJ8bpYCuxbCJ+bjs075bz6/34h07ZkGbJDfvzovO4VUCDqI9Ij8K8ANedk/kW5UHspp5Ov53L+TlC8tz+fp3YXP3l887qS0+O+kfOZZUhvYUrxm5jTw+py+vg1cn5e9nnQTV8rHNiPlh1uRfhOrS983L69UBjg/r/dAju+WvZY+GkhXC+nLb75AurHYglSh+Af6Rj2bkn8/xd/XQ6Tf0wvz/0dJ+cTmhc+syeF35fP2MClvej2prPAc6SZNpGvG+/JnNwT2KsTzxXndHXP6vLXC97gPuIaUb9yY39+dz9HPC+ueneN5FylPmj3UOc3bn0eq3R6T47GqkCZPy2lo9BSou/Uvn6xVpNqeFaSCzkL611SdAvwsv55IlYyRvovTirzNINX8VPzBA5vmdTbJ72dSuUD93sL7rwE/6PRxG21/FdLJCtKF7Poq688DDimki+vLtlVMX7PztlbkzOZxci1hlW1/FLi48P75wlt+P4V0YStezJZRyCT9N+Q5Xk2qKdqFdMF5EvinwrqvAe7Lr88CZhSW7cDAAvU5heX/QrogrlUIOz/nM2uTbsJ3LCz7IH0XnqnA3YVlu+R9FQtBy4Hd8usXkG76D83vfwhcUlh3av6exQvYTfRdXH8GfDa/nkQqXL2AVKsU9K8s+Fo+dk/SV0M1Fbi/0+e2zWnoCVJNbfH8TmTwAvXhwJ+qbPMU4JrC+x2Bp/LrV5cfX1Kt5H8P9dn8/nWkAm7pqeqdwMcKy2eSRmYovd+QVFDblvS7uB94fV72AeC3+fV7gYfK4vWHnD6eKnxmJoXfxmj6o3+B+h7618ruDyzMr6cAiyqkiWfy8VxD+s1PKSyfko9zqVZ/o5z+Xl1YZy59+cJ1pKeb4yvE89Pkij/SzdIa4JVl3+NDhfcHAffk1y8l5xn5/bn05Sc/Lktb4/L3eZzUJ6i4/aML7z9b9rmxFFoVtPqva9tQd5FDI2LT/Hdog9u6IW9nQ1K7sZ2AL8PzA6DPkHSPpCdICQWGboD/UOH130mZmrVfMZ1sSqrVAUDSkUqjuqyQtIJUW1lPx4rj8zY3ID0O+4Wkf87b3iF3/Hoop5sv17Dt5RGxuvDe6aY2h+bzsD6pfd/vSYWHFwBzC+f3N6SaJEgXmWLv9fJ+FpQt3wp4ICKeK/vM1qTzul7ZNkrLSpYWXj8FEBHlYaVz/a+km4NSZ6JzgQMlbV5Y/8HIV6bC/rbKr88jFfYA3gP8KiJKTVGeI7U1J8fhk/nYXUz/jt3F7z4afIh0U/XjGjrflWxL7kNURfk1YIPcnnQ7YKtSusxp82RSe+WhPgupTf1VEfFIfn8eA9vZP3/+ImIVqdZzq5xmLqB/+ii1A14OjC+2eY2I1+b0sZz+fbtGW/qoZCsG/ua3qrJuyax8PCeQanf3KFu+PHInWHI+wcC8o5RPHENKs3dKujl3OCw5knxeI7XX/z2DpJFi3CNiAemJ6lslvYDUtO28Uvzon388mr/PHqT8t9r2++W3EfFk3lZbuEBdvydJF9CSFw1nI/kidxHw1hz0HtJYjG8itTGbmMNLmW7xomY9QtJ2wI9IBbAX5kzhNir3ah5URDwXEf9Legz75hx8BqnmaFJEbEy6YA57KEYbWkSsidQBdQ2puc1TpLazpRuqTfJNM6TH2MXONi+utMnC68XAtpKKefOLSU1zHiHVGG5XYdlwHEW6aN4v6SFSW/p16SsEAWxdVvB7MX0dla4iFYx2y585D56/iN1Iapc5lNGWry0D9iU9ifh+lXXKj8kDpOYb9XqA9KRk08LfRhExZEd4SWNITUHekG/WHyI1/dlV0q6FVbctfGZDUk1iKX2cD7wz54GvJl3vIDUheJraxuwebemjksUM/M2XjvGgxyffDH0QOKXQYbAuEXF3RBxOanLyVVKFztjc8XgScFIhjbwaOLysg2B5/lfs6Hg+Ke84BPhLLmRDauLzKqWxrIeMYuF1v/w2F9RfWMv3bAYXqOs3DzhM0rqSJpPao9VN0gtJNUS356CNSJnMclKB/ctlH1lK6oRpvWUsfe3ukfRvpBrqYcnDH+1I/3TzBLBK0suBD5d9xOmmyZQcQmoXejvphumbkrbIy7dW39S5s4CpknbMmfvnhtj8jaSb9k/mPGYK6ab7glyjNAs4VdJGuaDyn6SmF/V+h61JBbu3ALvlv11JF8xiDdMWwPE5Lu8idZi8HCA/5fgFqT3+OFLntJJPAkdLml44LtuQOpGNarkm743AAZK+WWGV8t/sZcCLJH1U0vr53L+6hl3dBDwh6URJY/JT0J0lvaqGzx5KumHckb708Qrgf0m1kiUHSXqdpPWALwI3RsQD+Xv+iZTv/Ri4MiJW5PAVpCYE35f0TkkbSlor35hVHMFhlDsf+LSkzSWNJzVrKP3ml5LmFtik2ocj4k7gStJvsm6S3itp8/zUbEUOXkPKJ66mfxrZmVR+ObCwieMkbSNpHKnC58LCsgtIlUMfpq92moi4itRx/leSXi1pvTySyV5DRPcXwFsKafILtLGc6wJ1/T5Dqi14jJQpnDf46v28Rn1jWt9Bymz+Iy87h/Q45EFSB5Ibyj77E2DH/OjuV8OPvrVTRPwF+AapVmYpqV3r/9W5me8W0s1PSW1Qr8jLPk56urGSVLC7sOyzpwBn53Tz7uF9C8v+J5+DJ0idQ4+KiNtJvcwXADfkZjfXkGZRJZ+nb5E6By3I/6uKNOPe20gXpEdItZhH5osipPziSVLnsutJ+c9Zw/gu7yO1fbwqIh4q/QHfAf5ZUumm70ZSLdQj+Tu/M/Kwpdl5pKdqPy82I4qI60mFxtcDfy00hZlNC4Yb7DW50PlGUoXMV8oWf5tUs/uYpO9Emv1uP9KN1UOkDl371LCPNfkzu5E6gj1CKtxWLXwVHEVqa31/Wfr4LnBEoQbyPNJN4qOkx/Hl4yWfT0of/a6TEfE10s3gJ0m19ktJbfhPJLWntj5fIo2ycStplIw/5rBSYfl84N6cx1drCvJfwLGlm9s6HQDcnvO+b5M6HkN6gnF6MX1EmuXwp/S/KT+P9DTr3vz3/HwakSZ3mQO8loHXrreTbiZ/RirI30dKXwdUi2jOj4/L+1xCKqctqv8rD0+pB66ZmZmZmQ2Da6jNzMzMzBrgArWZmZmZWQNcoDYzMzMza4AL1GZmZmZmDVhn6FU6a/z48TFx4sR+YU8++SRjx/b26Doj9TvMnTv3kYjYvMpHWs7ppXs5vXS3XvjenU4v4DRTTbceg06nmUrppZW69Tx0Y7yafk1qx3SMjfztscceUe53v/vdgLBeM1K/A3BLOL003Uj9Dk4v3aMXvnen00s4zVTVrceANOTcWaTh+W6LfB5JQ4o+SJpbYh79p/c+iTTM5V3A/oXwPUhD1y0gDTGpGEZ6aaVuPQ/dGK9mX5Pc5MPMzMxGsplUHr/4mxGxW/67HEDSjqSxlnfKn/m+pLXz+mcAx5LGZp9UZZs2Sg1ZoJZ0lqRlkm4rhJ0i6UFJ8/LfQYVlJ0laIOmuwmxhSNpD0vy87Dtl09mamZmZNV1EXEeafKYWh5BmJn060kQlC4A989TdG0fEnFyTeQ5pRkkzoLY21DNJsyOdUxb+zYj4ejGg7M5uK+AaSTtEmrGpdGd3A2nq2gOAKxil5j/4OFOn/3rI9RbOOLgNsRnZfKytF0ysIY2C06klTi9N8RFJR5KahUyLiMeArek/U/GiHPYs/WfdK4UPIOlYUnmHCRMmMHv27ObHvIpVq1ZV3d/8Bx8f8vO7bF3LRJr1GyxendLsOA1ZoI6I6yRNrHF7z9/ZAfdJKt3ZLSTf2QFIKt3ZjdoCtZmZmXXMGcAXgcj/vwEcDVR6eh6DhA8MjDgTOBNg8uTJMWXKlCZEtzazZ8+m2v5qqlg6ovJnGzVYvDql2XFqZJSPltzZwdB3d914p1OvCWNg2i6rh1yvm7/nSDgP1nmSzgLeAiyLiJ1z2CnAB4CH82onF9o4ngQcA6wBjo+IK3P4HqQnamNIT8FOyI9mzcz6iYilpdeSfgRclt8uArYtrLoNsDiHb1Mh3AwYfoG6ZXd2MPTdXTfe6dTr9HMv4Rvzhz78rbpbbIaRcB6sK8zEzcrMrI0kbRkRS/LbfwVK/cQuBc6TdBopj5kE3BQRayStlLQXcCNwJHB6u+Nt3WtYBWrf2ZlZs7hZmZm1kqTzgSnAeEmLgM8BUyTtRqrcWwh8ECAibpc0C/gLsBo4Lt+wA3yYvqdgV+D8xQqGVaD2nZ2ZtUFHOgx1qilTLU3AoHXNwNyEy0aqiDi8QvBPBln/VODUCuG3ADs3MWo2ggxZoPadnZl1QMc6DHWqKVMtHYZgdHUaMjPrFbWM8uE7OzNrKzcrMzOzXuKZEs2s6+RJFErKm5UdJml9SdvT16xsCbBS0l550qgjgUvaGmkzMxu1Ghk2z8ysYW5WZmZmvc4FajPrKDcrMzOzXucmH2ZmZmZmDRj1NdQTa+1ZP+PgFsfEzMzMzHqRa6it6SSdJWmZpNsKYadIelDSvPx3UGHZSZIWSLpL0v6F8D0kzc/LvpM7m5mZmZl1FReorRVmkqZ9LvfNiNgt/10OA6aSPgD4vqS18/qlqaQn5b9K2zQzMzPrKBeoreki4jrg0RpXf34q6Yi4DyhNJb0leSrpiAigNJW0mZmZWVcZ9W2ora06MpX0hDG1TevczdMuj4RpoUfCdzAzM6vEBWprl45NJX36uZfwjflDJ/VWTencDCNhWuiR8B3MzMwqcZMPa4uIWBoRayLiOeBHwJ55kaeSNjMzs57mArW1haeSNjMzs5HKTT6s6TyVtJmZmY0mLlBb03kqaTNrFUnbkkb9eRHwHHBmRHxb0jjgQmAi6ab93bnjM5JOAo4B1gDHR8SVOXwP+m7aLwdOyKMKmZnVxU0+zMysl6wmjRL0CmAv4Lg8nv104NqImARcm997rHszawsXqM3MrGdExJKI+GN+vRK4gzSk5iHA2Xm1s+kbt95j3ZtZy7nJh5mZ9SRJE4FXAjcCE3JnZiJiiaQt8motH+u+E2Os1zK2PrRvfH2PM2+jnQvUZmbWcyRtCFwEfDQinkiDAVVetUJYU8e678QY61On/7qm9do1vn43jzMv6SzgLcCyiNg5h7nNvTXVkE0+JJ0laZmk2wph4yRdLenu/H+zwrKTJC2QdJek/Qvhe0ian5d9R4PkfmZmZtVIWpdUmD43In6Zg5eWhufM/5flcI91bzMZ2D7ebe6tqWppQz0TJ0QzM+sCuTLmJ8AdEXFaYdGlwFH59VH0jVvvse5HuYi4Dni0LNht7q2phmzyERHX5XZqRYeQxhmGlBBnAydSSIjAfZJKCXEhOSECSColRI8rbGZm9dgbeB8wX9K8HHYyMAOYJekY4H7gXeCx7q2qjrW5b6XB2rLX0u6+VXHtxjb2zY7TcNtQtywhQns7gHSqY8eEMZ1N3M3QjT8Q6z1u32j1iIjrqdz+GWDfKp/xWPdWq5a3uW+lwdqy19LuvlVt7ruxjX2z49TsTokNJ0RobweQTnXsOP3cS/jG/KEPf7s6lAxHN/5ArCfNBL5LeoRaUmpWNkPS9Pz+xLJmZVsB10jaIdc4lpqV3UAqUB+AaxzNrLKlkrbMlYJuc28NG+441O78YWZN4faNZtYBbnNvTTXcGupSQpzBwIR4nqTTSLVHpYS4RtJKSXuRxgs9Eji9oZib2Ug2qsYUhs6PK+wmXDZSSTqf1O9rvKRFwOdwm3trsiEL1E6IZtZFRuSYwtD5cYXdhMtGqog4vMoit7m3pqlllA8nRDNrN7dvNDOznjHcNtRmVXkyIGsCt280M7Oe4anHrRVm4lEbmmr+g4/XNuTRjIPbEJvmcrMyMzPrdS5QW9N5MiCrh5uVmZlZr3OB2tqlY6M2jIRJdEbCd/AoEmZmNlK5QG2d1vJRG0bCJDoj4Tt4FAkzMxup3CnR2sWTAZmZmdmI5AK1tYtHbTAzM7MRyU0+rOk8aoOZmZmNJi5QW9N51AYzMzMbTdzkw8zMzMysAa6hNjNroYk1TMhjZma9zTXUZmZmZmYNcIHazMzMzKwBLlCbmZmZmTXABWozMzMzswa4QG1mZmZm1gCP8mFmZj1F0lnAW4BlEbFzDhsHXAhMBBYC746Ix/Kyk4BjgDXA8RFxZQ7fg77Joy4HToiIaOd3MWtUcSShabusZqpHFuoI11CbmVmvmQkcUBY2Hbg2IiYB1+b3SNoROAzYKX/m+5LWzp85AzgWmJT/yrdpZlYTF6jNzKynRMR1wKNlwYcAZ+fXZwOHFsIviIinI+I+YAGwp6QtgY0jYk6ulT6n8BkbJSQtlDRf0jxJt+SwcZKulnR3/r9ZYf2TJC2QdJek/TsXc+s2DTX5kLQQWEl6jLY6IiYP57GbmZlZgyZExBKAiFgiaYscvjVwQ2G9RTns2fy6PHwASceSarKZMGECs2fP7rd81apVA8Jabdouq2tar13x6sQxaKJ9IuKRwvvS044Zkqbn9yeWPe3YCrhG0g4Rsab9UbZu04w21E6IZtYSvmm3JlCFsBgkfGBgxJnAmQCTJ0+OKVOm9Fs+e/ZsysNardZ2sguPmNLaiGSdOAYtdAgwJb8+G5gNnEjhaQdwn6QFwJ7AnA7E0bpMKzolOiGaWTP5pt1qsVTSlrl2ektgWQ5fBGxbWG8bYHEO36ZCuI0uAVwlKYAf5punep929DPUE41mKz6tmDCm9qcXlbQqrt34BKPZcWq0QN30hAjtfbzWqcdmtSb6bkuARd34A7FRwTftVsmlwFHAjPz/kkL4eZJOI91oTQJuiog1klZK2gu4ETgSOL390bYO2zsiFueyytWS7hxk3Zqeagz1RKPZppaN8vGN+cMv2rXqiUY3PsFodpwaLVA3PSFCex+vdeqx2ennXlJTom/X47rhGM558CN8q1Pba4+afaPYSG1RJaOpBqkaSeeTbqrGS1oEfI5UkJ4l6RjgfuBdABFxu6RZwF+A1cBxhacWH6Zv2Lwr8p+NIhGxOP9fJuli0k14vU87zBorUDsh2jD5Eb7Vqu21R82utWj2mLCjqQapmog4vMqifausfypwaoXwW4Cdmxg16yGSxgJrRcTK/PrNwBeo82lH2yNuXWnYw+ZJGitpo9JrUkK8jb6ECAMT4mGS1pe0PU6I1qeu4a7aHz3rlOJNO9Dvph3AN+1m1oAJwPWS/kwqj/w6In5DKkjvJ+luYL/8noi4HSg97fgN/Z922CjXSA31BOBiSaXtnBcRv5F0M/U/drPRo+2P8EdCe/WR8B3qbVLg2iMza6WIuBfYtUL4cup82mE27AK1E6INU9sf4Y+E9uoj4TsMo0mBb9rNzKwntGLYPLOq3O7eauWb9uGbWGtn6xkHtzgmZmajgwvU1jZ+hG9mZta9fDM+fC5QWzv5Eb6ZmZmNOC5QW9v4Eb6ZmZmNRMMeNs/MzMzMzFygNjMzMzNriAvUZmZmZmYNcIHazMzMzKwBLlCbmZmZmTXABWozMzMzswZ42DwzMzOzLlPrJCvWHVxDbWZmZmbWABeozczMzMwa4CYfZmZmZlazWpujLJxxcItj0j1cQ21mZmZm1gDXUJuZDYM7DJmZDa6UT07bZTVTB8kzR0JNtmuozczMzMwa4BrqEcBtmczMrB2qXW/KayB9vbHRpu0FakkHAN8G1gZ+HBEz2h0H6x1OL1Yvp5naFQtHgz2SHcmFI6cXq5fTjFXS1gK1pLWB7wH7AYuAmyVdGhF/aWc8rDc4vVi9nGasHk4vVq9mpBn3vxiZ2l1DvSewICLuBZB0AXAIUFfmNf/Bxwdt3A4ju0ZlFGlKerHWqvXiMPOAsS2OCdCENFNL/jLajOBmZc5jrF5OMy0wEvKYdheotwYeKLxfBLy6fCVJxwLH5rerJN1Vtsp44JHBdqSvNhDLNmyPGr5Ds/fbpu+wXRO337b0Ai05Ps3U899hn6+2PL1ADWmmWemlU1p1jo9vwvduQ/pre3qB3k4z7coTytNPF+VF3ZjHtEwzfset0Kx4NTldNfWa1O4CtSqExYCAiDOBM6tuRLolIiY3M2Lt5u9Q2y4qhDm99Kg2fYch08xoSC/DMUq/t/OYJhlFx6DhPKaVuvU8dGO8mh2ndg+btwjYtvB+G2Bxm+NgvcPpxerlNGP1cHqxejnNWEXtLlDfDEyStL2k9YDDgEvbHAfrHU4vVi+nGauH04vVy2nGKmprk4+IWC3pI8CVpOFmzoqI24exqY48Smkyf4chOL304+9QgyalmZFwrIdj1H1v5zFNNSqOQRPTTKt063noxng1NU6KGNBczMzMzMzMauSpx83MzMzMGuACtZmZmZlZA3qqQC3pAEl3SVogaXqn41MvSdtK+p2kOyTdLumETsdpuCStLelPki7rdFyq6fX0AiDpLEnLJN3W6bgMVy+l+5GQZuolaaGk+ZLmSbql0/HpJaMxvZTrpd/3SNYtv+NK1yxJ4yRdLenu/H+zLonXKZIezMdsnqSDGtpHr7ShztN9/pXCdJ/A4b00RaykLYEtI+KPkjYC5gKH9tJ3KJH0n8BkYOOIeEun41NuJKQXAEmvB1YB50TEzp2Oz3D0SrofKWmmXpIWApMjousmg+hmozW9lOuV3/dI1y2/40rXLElfAx6NiBn5xnOziDixC+J1CrAqIr7ejH30Ug3189N9RsQzQGm6z54REUsi4o/59UrgDtKsSz1F0jbAwcCPOx2XQfR8egGIiOuARzsdj0b0ULofEWnG2sbphZ76fVsbVLlmHQKcnV+fDRzazjhBe66lvVSgrjTdZ8t+tJJWSXpJi7a9UNIRwCuBG1uxjxb7FvBJ4LkOx2MwbU0vjZIUkl7ahv2cIulnrd7PIPufSPem+55KM00UwFWS5uYpk/uRNFPSlzoQr27XkfQiaYqkRa3eT9k+a0oDzfx9tytPHEEG/R132ISIWALpBgzYYqgPtPFa9RFJt+YmIQ01RemlAnVNU8QOa8OpgPtULkSvkrQK2CEi7m3G9ivtEvgc8NGIeKJF+2gJSW8BlkXE3E7HZQjDSi+STpJ0eVnY3VXCDmswjtXiMFPSM5JWSlpJGu90gqRNWrG/wn43zZnKQ3nff5V0YmF5SHqy8DtZUef2NwQuonvT/bDzGElTc/vFv+fjd4akTZsbvYr7LeZdSyX9dz7O9dg7InYHDgSOy49G64nDIbn94ROSHpF0bS5YlS6KzxbzVkmfrDN+3aqm9FLp+iLpu22IX0vkAv1z+XusVGpD/m898PsesXLB8wXAS4FNgc+UfseSTpZ0Xz5fiyRd2IT9zZb0j7zNRyT9Mjf96TVnAP8E7AYsAb7RyMZ6qUDd6uk+3xoRGxb+qm47t50bFknrku7Oro2IXw53Ox20N/C23F7rAuCNnazxHMRw08t1wN6lcyzpRcC6wO5lYS/N67bK1yJiI2Bz4BPAGOD/JI1t4T6/CWwIvALYBHgbcE/ZOrsWfiOb1rrhnO4vAs7t4nQ/rDQjaRrwVdJ52gTYC9gOuFppJrVWe2tEbAjsDrwK+HSdn18GEBHLgItJTRlqkmsQzwGmkb779sD36f/06sKyvPVrdcavW9WTXsqvLx9pffRaanFOcxsDJwI/An5DHb9vSW2dWG6E+wrw4ojYmNQcczPgXyUdBbwPeFM+X5OBa5u0z4/kbe5AKsR/c5B1l5YK3Pn/MiUdLYNGxNKIWBMRz5HScM15XyW9VKBu63SfxcdNucbwDEmXS3oS2EfSVpIukvRwvvs7vvDZUyT9QtKF+Q7+j5J2lSTgJ8CzpMIFkvaUNEfSCklLJH23eBGWtJNSr9hHcw3UyTl8LUnTJd0jabmkWZLG5WUbSPpZDl8h6WZJE5pxXCLipIjYJiImks7BbyPivc3YdpMNN73cTCpA75bfvx74HXBXWdg9AJIuzedmgaQPlDYiaX1J35K0OP99S9L6heWfyOd7saSjq0UmIv4B3ArcD7wQ+LfCNo5W6ln/mKQrJW1XWFYx3RRJWlfS+Tkdr0cqjJ0XEY9FxHMRcWdE/KKGYzaoQrq/IyJOa3R7LVR3mpG0MfB54D8i4jcR8WxELATeTSpUv7daflDYxlB5ySxJ5+TP3i5pcqW4RMSDwBVAqcPN2/L6K5RqlF5R2O5CSSdKmg88KWkdSW8C/hM4RdIDkqYWNr+ZpF/nONwo6Z9y+G7AfRFxbSQrI+KiiLi/huPd6xq6Jik91bhe0tfzb/g+SQcWlo9TeuKwOC//VZXtvCKf3xX5fL+tsOwgSX/J5+1BSR8vLHuL0pOFFZL+IOmfC8temdPpSqUazQ0q7TvSqAaXAKuBFcD3quV7yk1Vcrp7CPhvpdGiTs7XsZVKzRWKNylvUnoa+Jik7+W8xAZaCJTKDRvk138n5elXRsQ9ABHxUEQ8PztgToP35mN/n1JT1CHTZlFEPEoqz5TyndeS0sQrlMoeryX9Lo6SNBs4Fxib4/eSIa5V69WS9w2X+teq/yvQ2GhaEdEzf8BBpF7V9wCfauJ2F5Lu4IphAbw0v54JPE6qnV2L9GhlLvBZUsJ9CXAvsH9e/xRSofmdpMLZx4H7gDfk7T4DLADmAceTarTWASaSOnR8NG9nI9JjiGmkH8lGwKvzso8CN5BqRdYHfgicn5d9EPifHM+1gT1Io3E0+3xMAS7rdLpodnohFaA/ll9/FzgaOLUs7Czg96TauA1IBYuHgX3zOl/I52cLUi3zH4Av5mUHAEtJGdBY4LwK6e1L+fX5OQ08CzwJ3JTDD81p6BU57Xwa+EMN6eYU4GekGu9f532tnZf9GLidVGifVOG4PB/HOs/D6/Jnb81pfh5wUKfTRzPSTD6Xq4F1Kiw7O5+/U6icH6xLyk+Gykv+keO1Nqkm6obCPhaS8y5SbentwBdJtUZPkkagWJfU52EBsF7hc/NIedqtwF+ANcCFef0XArsV0uOjpNqbdUgXxAvyspfk+H0T2AfYsOwYnAL8rNPntZPphQrXlxw+NaeLD+Rz+2FSDXdp9K1f5/OxWT4nb8jhU4BF+fW6+byenNPPG4GVwMvy8iXAv+TXmwG759e7k55MvDrv+6gcz/Xzdv4GfCxv/505nl+qsP+18r6DVOnwUE53hzMw35tC+q18Ne9nDOmpznzgZaQmNLsCL8zrB3AZqfbzxaT89YBOn/Nu/Mu/w0dIT4Yip6MNgffm3+4nSLXTaxc+MxZ4opBWtgR2qjFtzgben1+PB34L/BQYRyrfrMifX57Tw0tJNeN/J+UXryHlJUNdq6rmfcM4RsVr6SLgmBzn+aQ88FLSaDXDPw+dTgjd8JczklU5EawAfsXAAs45hfVfDdxfto2TgP8uJITiRW8t+mdsC6mQweZlHwUuzq8PB/5UZb07yIW3wo/h2ZxIjyZlZP/c6WPbi3/5/JXOwZ+BSaSCUzHsKFIBZKPC574CzMyv76FQaAT2Bxbm12cBMwrLdqiQ3r5UIV4zgKvz6yuAY8rS2N9JtaKDpZtTcsbxe+A75AwyLxtDujjOzWlpAXBgYXmQMuDS7+Q7nT5Xnf4jXbAeqrJsBnD1YPlBjXnJNYVlOwJPFd4vpC/v+hvpBm8M8BlgVtk+HwSmFD53dNk+L67yPWYCPy68Pwi4s/B+L2AWqcDzj7z+hoX4ly6wpb+tOn3e2pxGiueo9PcBUqFlQWG9F+Tf2ItI+flzpOHFyrc3hb4C7b+QCrFrFZafD5ySX99PqmDZuGwbZ5ALuoWwu0iVPq+nUHjKy/5A/wL1c/l7PEq6MTssLxss35uS08IGZfs8pMpxC+B1hfezgOmdPp/d/EcqeL6OVMGybg47AriGVLBdXjqGpAL1CuAdwJiy7VRNm/n9bNL1ZgUpXzmXdAP1PnKlT+Gzc4Cphc99obBsqGtV1byvG/96qclHqx0aEZvmv0MrLC/25t4O2Co/Kluh1DnrZGBCpfUjtc9ZBGxVvlFJO0i6TKkj0xPAl0l3fJBqnMrbsBbjcHFh/3eQCngTSHddVwIX5MduX1Nqw2q1uQ54nVKP380j4m7SBeW1OWxn4E7SuJorC5/7G329/LfK74vLtiose6BsWS22pm/Yn+2AbxfO/6OkGp6tGTzdQCoA/TOpUB+lwIh4KiK+HBF7kGooZwE/V25KlO1e+J0cjz0CjFfl9qBb5uVQPT+oJS95qPD678AGZfsr5V3bRcS/R8RTlKW/vM8H6D8KRTENDpVmyuPwfMfHiLghIt4dEZuTCnivBz5VWH9WIc1sGoP0TxnBDi07Bj/K4c8f14j4e365Iel8PBoRjw2x3a2AB/L5LSnmQ+8g3QD9TdLvJb0mh28HTCtLd9vm7W0FPFjMGxiYRy3O32NcROwWERcU4lMt3wN4OFIztpJhpzsbKFJ74OtJT64/nMPOjYg3kWr6PwR8QdL+EfEk8P9y2JLcpOvlhc1VS5slx+c0sHVEHBERDzPw/EP/9AiN5TvleV9XcYG6dsXM5QFSu8FiBrlRRBRn2Xm+HZhSw/tqHVbOIBXOJkXqUHAyfb3HHyD1QK3kAVLtYTEOG0TEg5HacX4+InYEXgu8BThyGN95tJpD6mB1LPB/AJF6rS/OYYvz3ziliQxKXky6Wycv365sWen8L6F/Z6YXDxUhpR70bwL+Nwc9AHyw7PyPiYg/MHi6AbiKVJt+raq0rc/f98ukWozth4rfKDYHeBp4ezFQqfPogfR1AKqWH9SSlwxHv/SX255uS1/6hIF52mBppiYRcTPwS3J7Shu2B0j5y6ZDrLcY2Fb9O3c9nw9FxM0RcQip6dmvSDfJpe2fWpbuXhARpcfiW5e1Vx4yjyrEp1q+BwNHQWlKurMB1qHsuOZywc9JzRt2zmFXRsR+pJv/O0kd8xpRfv6h/3URWpDvdAsXqIfnJuCJ3LliTO5YsbOkVxXW2UPS2/Pd1EdJF90bKmxrI9Jj9FX57vDDhWWXAS+S9FGlTm4bSXp1XvYD4FTljmiSNpd0SH69j6RdlEaleIL0+H5N0779CJdr+G4hddD638Ki63PYdRHxAKnW+itKnUD/mdQm69y87vnAp/N5GU9qI1saDWUWMFXSjpJeQBpCsaJ83vcgXQwfA/47L/oBcJKknfJ6m0h6V142WLopfcevkdpuX5vjh6TPSHqVpPUkbQCcQHqkd1eNh27UiYjHSZ0ST1eahnpdpSHjfk6qhf5pXrVaflBLXjIcs4CDJe2bn05Ny/v8Q5X1zyV1AHu3UgfFF0rabaidSHqdpA9I2iK/fzlpdJhKeZ3VKNJYvVcA35e0WU5XlYYzvJH0KP+TeZ0pwFtJTyfXk3SEpE0i4lnStaB0HfgR8CFJr1YyVtLBuYJgDqmt8/E5Lbyd2kc/GCzfq+THwBclTcrx+GdJL6xxXwZI2kLSYZI2zPnH/qSmFL9V6lx4cL4GrKXUsXAn4EZJE5Q6Lo8l5Q2raLyccDmwg6T35LTz/0hNNS6rsv6Q16pe4gL1METEGlKmtRupc9EjpIxhk8Jql5AepzxGalf09pyplfs48B5SR5IfkTqhlPazktSp6K2kRx93kzr+AHyb1Bb2KqWxim8gtceE1AbvF6QM9A5Se9luHNqum/2eVKtzfSHsf3NYabi8w0kdSReThhv7XERcnZd9iVQov5XU6eGPOYyIuII0Oc5vSe2Uf1th/5/M5/VR0rBkc4HX5sd0RMTFpM49Fyg1FbqNVCM6VLp5XkR8kVRQv0apWUeQCuyP5O+0H3BwRKwa8miNYvnm5GTg66Tf3I2kmpd9I+LpvFrF/KDGvGQ4cbqL1L779LzNt5KGbnumyvr3k5oGTKOvXeyuNexqBakAPV9p/P7fkH4LI2VovGb5H/Ufh/riGj7zPlJlyJ2kDoQfLV8hn8+3kX77j5Da0B8ZEXcWtrEw5xEfIqUJIuIWUjvu75LS5AJSu9nSNt+e3z9GSre1DnVZNd+r4jTSzd9VpN/OT0h9AKx2QaqIW0Q6X18nDWxwCemYnkxqS7+C9Lv8cG4Wshbp976Y9Jt/A/DvDUUkYjnpifg0UnvtTwJviSrTodd6reoVpR6b1kRK88O/NLpzODkzayPnB2ZmI59rqM3MzMzMGuACtZmZmZlZA9zkw8zMzEas3Mn6OtKEMusAv4iIz+W+IxeS+sIsBN5dGqpQ0kmkjuZrSEPEXZnD9yCNtT6G1AnvhHBBynANtZmZmY1sTwNvjIhdSR2AD5C0FzAduDYiJpGGuJwOIGlH0lTyO5Em9fp+HjUL0lC3x5Im/CpN+mVG1w6QXTJ+/PiYOHFiv7Ann3ySsWPHdiZCTTJSv8PcuXMfJfXwfhFpNq0zI+Lb7aoJGKnppdm65ZjMnTv3kTwhSEc4vQyu247F3LlznwDmRETHCjEjMc30evyh+nco5DGl0YrWzX8BHEKawRHgbNJMfifm8AvyKD33SVoA7ClpIWnWyTkAks4BDiUNcVhRr6WX0R63Rq5JXV+gnjhxIrfccku/sNmzZzNlypTORKhJRup3kLQImBYRf8xjms6VdDVpCKZrI2KGpOmkmoATy2oCtiIN4bZDHk6sVBNwA6lAfQCDZFwwctNLs3XLMZFU6yyRLeH0MrhuOxaS7u5kYRpGZprp9fhD9e9QymNyDfNc4KXA9yLiRkkT8pjfRMSS0njqpJn9imOpL8phz+bX5eHl+zyWdO1iwoQJfP3rX++3fNWqVWy4YXdO+jja47bPPvsM+5rU9QVq6znPRsQfIY0xKekOUobT8poAMzOzSnIlzW5Ks09eLGmw2TxVISwGCS/f15nAmQCTJ0+O8oJ+N9/AOG7D5wK1tUyeMe6VpIkuWlITkPfTrzZg9uzZ/ZavWrVqQNho52NiZqNRRKyQNJv0xHOppC3zNWlL0gQ6kK432xY+tg1pApRF+XV5uFlvFqjnP/g4U6f/etB1Fs44uE2xsUokbQhcRJqx6Qmp0o19WrVCWM01ATB0bcDp517CN65/csg4j6Y00+13+p1US/4Coyu92OCcZrqbpM1JT09XSBoDvIk00+ylwFHAjPz/kvyRS4HzJJ1Gaoo4CbgpItZIWpk7NN4IHEmajbQuTi8jU08WqK27SVqXVJg+NyJKU9a6JsDMzDphS+Ds3I56LWBWRFwmaQ4wS9IxpOm53wUQEbdLmgX8BVgNHJebjECa5nsmqbP8FbgZomUuUFsr/AS4IyJOK4R1pCbAzMxGt4i4ldT8sDx8ObBvlc+cCpxaIfwWYLD21zZKuUBtzbYh8D5gvqR5OexkUkHaNQFmZmY24rhAbc22KiKqNZh2TYCZmZmNOJ4p0czMzMysAS5Qm1lHSdpW0u8k3SHpdkkn5PBxkq6WdHf+v1nhMydJWiDpLkn7F8L3kDQ/L/uOBhlexszMrFlcoDazTltNml3zFcBewHF5Bs3ppNk1JwHX5veUza55APD93Hsf+mbXnJT/OjqrnpmZjQ4uUJtZR0XEkuLsmkBxds2z82pnk2bKhMLsmhFxH1CaXXNL8uyaERHAOYXPmJmZtcyo75Q4sYbB1cEDrJu1Qztm1xxqZs0JY2DaLquHjOtomGnSM2qamdVm1Beozaw7tGt2zZpm1pw/dNa48IgpQ67T6zyjpplZbdzkw8w6brDZNfNyz65pZmZdywVqM+uoPBLHYLNrwsDZNQ+TtL6k7embXXMJsFLSXnmbRxY+Y2Zm1jJu8mFmnbY3nl3TzMx6mAvUZtZREXE9lds/g2fXNDOzHuAmH2ZmZmZmDXCB2szMzMysAS5Qm5lZz/BU9WbWjVygNjOzXuKp6s2s67hAbWZmPcNT1ZtZN/IoH2Zm1pPaMVV93s+Inq5+JEwxPxK+g/U2F6jNzKzntGuqehj509WPhCnmR8J3sN42ZJMPSWdJWibptkKYO3+YmVlHeKp6M+s2tbShnsnAjhru/GFmZm3nqeqtXh4ZxtphyAJ1RFwHPFoW7M4fZmbWCaWp6t8oaV7+O4g0Vf1+ku4G9svviYjbgdJU9b9h4FT1PyZdq+7BU9WPVB4ZxlpuuG2oW9b5A5rTAaTWzgm1dCSpZ3u1GgkdKEbCdzCz3uKp6q1eubxSKrOslFQcGWZKXu1sYDZwIoXKQeA+SaXKwYXkykEASaXKQd+IWdM7JTbc+QOa0wGk1s4fU6f/uqb1mt2ZZCR0oBgJ38HMzEaPdowM08ujwnRzRVk3xw2GX6BeKmnLnADd+cPMzMy6WrtGhunlUWG6uaKsm+MGw5/YxZ0/zMzMrCd4ZBhrtVqGzTsfmAO8TNIiScfgzh9mZmbWAzwyjLXDkM8cIuLwKovc+cPMzMy6XWlkmPmS5uWwk0mVgbNyReH9wLsgVQ5KKlUOrmZg5eBMYAypYtCVgwZ4pkQzMzMbwTwyjLXDcNtQm5mZmZkZLlCbmZmZmTXEBWozMzMzswa4QG1mZmZm1gAXqM3MzMzMGuACtZmZmZlZA1ygNjMzMzNrgAvU1nSSzpK0TNJthbBxkq6WdHf+v1lh2UmSFki6S9L+hfA9JM3Py76TZ6YyMzMz6youUFsrzAQOKAubDlwbEZOAa/N7JO0IHAbslD/zfUlr58+cARxLmvZ1UoVtmpmZmXWcC9TWdBFxHfBoWfAhwNn59dnAoYXwCyLi6Yi4D1gA7ClpS2DjiJgTEQGcU/iMmZmZWdfw1OPWLhMiYglARCyRtEUO3xq4obDeohz2bH5dHj6ApGNJNdlMmDCB2bNn99/xGJi2y+ohI1j+uZFs1apVo+r7mpmZtZIL1NZpldpFxyDhAwMjzgTOBJg8eXJMmTKl3/LTz72Eb8wfOqkvPGLKkOuMFLNnz6b8OJmZmdnwuMmHtcvS3IyD/H9ZDl8EbFtYbxtgcQ7fpkK4jTDuxGpmZr3OBWprl0uBo/Lro4BLCuGHSVpf0vakzoc35eYhKyXtlQtGRxY+YyPLTNyJ1czMepgL1NZ0ks4H5gAvk7RI0jHADGA/SXcD++X3RMTtwCzgL8BvgOMiYk3e1IeBH5M6Kt4DXNHWL2Jt4U6sZmbW69yG2pouIg6vsmjfKuufCpxaIfwWYOcmRs16hzuxdgF3XjUzq40L1GbWS9yJtY3cedXMrDZu8mFm3cidWK0qd2Q1s27jArWZdSN3YrXBzMQdWc2sizRUoJa0MN/dz5N0Sw6ru5bAzEYvd2K1erkjq5l1m2a0od4nIh4pvC/VEsyQND2/P7GslmAr4BpJOxQuhmY2CrkTqzWJO7IO00jofDrYd5B0FvAWYFlE7JzDxgEXAhOBhcC7I+KxvOwk4BhgDXB8RFyZw/cgPR0ZA1wOnJBvxsxa0inxEGBKfn02MBs4kUItAXCfpAXAnqSaKTMzs1ZwR9YhjITOp0N8h5nAd0lPIUqGU/lXaiJ0A6lAfQB+EmZZowXqAK6SFMAPc6ZTby3BAM2oDaj1bruWWoV6tlerkV4j0IsmTv91TestnHFwi2NiZsOwVNKW+brjjqz2vIi4TtLEsuC6Kv8kLSQ3EQKQVGoi5AK1AY0XqPeOiMW50Hy1pDsHWbettQG11gRMrbUQ1eSahVFQI2Bm1k6ljqwzGNiR9TxJp5FqHEsdWddIWilpL+BGUkfW09sfbesQNxGqoJsryro5btBggToiFuf/yyRdTGrCUW8tgZmZWc1yR9YpwHhJi4DPkQrSs3Kn1vuBd0HqyCqp1JF1NQM7ss4ktYm9Atc22ihvItTNFWXdHDdooEAtaSywVkSszK/fDHyBOmsJGoi7mZmNQu7Iak3gJkLWVI0MmzcBuF7Sn0kF419HxG8Y3nBXZmZmZu3ise6tqYZdQx0R9wK7VghfTp21BGZmZmat4CZC1g6tGDbPzMzMrCu4iZC1g6ceNzMzMzNrgAvUZmZmZmYNcIHazMzMzKwBLlCbmZmZmTXABWozMzMzswa4QG1mZmZm1gAPm2dmNgwTp/+6pvUWzji4xTExM7NOcw21mZmZmVkDXKA2MzMzM2uAC9RmZmZmZg1wG+oOmf/g40ytoQ2m21+amZmZdTfXUJuZmZmZNcAFajMzMzOzBrhAbWZmZmbWABeozczMzMwa4AK1mZmZmVkDPMqHWZ1qmSHPo7OYWTnnHWYjlwvUZmYt5CnKzcxGPjf5MDMzMzNrgAvUZmZmZmYNaHuTD0kHAN8G1gZ+HBEz2h0H6x1OL1YvpxmrR7elFzcR6n7dlmasO7S1QC1pbeB7wH7AIuBmSZdGxF/aGQ/rDb2cXnxR7AynGatHL6cX6wynGaum3TXUewILIuJeAEkXAIcATogNGMEX4hGfXkbwuesUpxmcXuow4tOLNV3Pppla8o6ZB4xtQ0xGpnYXqLcGHii8XwS8unwlSccCx+a3qyTdVbbKeOCRwXakrzYQyzZsjxq+Q7P326bvsF0Tt9+29NLtOpX+2qCZ6QVqSDNOL3XptmMxSdJvIuKAJm2vZ/OYJucJ3Xaeh6Pad+jZPKYF+f6Q9vlqV6eFdsRt2Oml3QVqVQiLAQERZwJnVt2IdEtETG5mxNrN36G2XVQIG5XppdlG8DEZMs04vdRuFBwL5zH0fvyhrd9hROcxjtvwtXuUj0XAtoX32wCL2xwH6x1OL1Yvpxmrh9OL1ctpxipqd4H6ZtIju+0lrQccBlza5jhY73B6sXo5zVg9nF6sXk4zVlFbm3xExGpJHwGuJA03c1ZE3D6MTVV9lNJD/B2G4PTSUiPymDQpzYzIYzNMI/pYOI95Xq/HH9r0HUZBHuO4DZMiBjQXMzMzMzOzGnmmRDMzMzOzBrhAbWZmZmbWgJ4qUEs6QNJdkhZImt7p+NRL0raSfifpDkm3Szqh03EaLklrS/qTpMs6HZdqej291EPSWZKWSbqtEDZO0tWS7s7/NyssOykfl7sk7V8I30PS/LzsO5IqDRE1Yo2mNAMgaWE+3/Mk3ZLD6k43o1UvpZdeO9cjNU/rZJqpVgbplnRQXq7olnjVLCJ64o/U+P8e4CXAesCfgR07Ha86v8OWwO759UbAX3vtOxS+y38C5wGXdTouIzW91Pl9Xw/sDtxWCPsaMD2/ng58Nb/eMR+P9YHt83FaOy+7CXgNaazVK4ADO/3dnGZa+p0XAuPLwupON6Pxr9fSS6+d65GYp3U6zVQrg3RLOqCsXNEt8ar1r5dqqJ+f7jMingFK0332jIhYEhF/zK9XAneQZl3qKZK2AQ4GftzpuAyi59NLPSLiOuDRsuBDgLPz67OBQwvhF0TE0xFxH7AA2FPSlsDGETEnUq51TuEzo8GoSjODqCvdtD96XWMkpJeuPdcjNE/raJoZpAzS8XRQpVzR8XjVo5cK1JWm++y5wmiJpInAK4Eb27jPUyT9rAmb+hbwSeC5JmyrVXo2vUiaKelLTdjUhIhYAikjBbbI4dWOzdb5dXn4aNG1aUbSDyR9pgWbDuAqSXOVpkuGgenmxTnf6Nrj0yG9djxqOddD5RFD5k+SQtJLmx774cW32/K0rkkzZWWQutNBDdufLen91fad00lx6OZvMbBc0fR4tVIvFahrmiK26oel10n6g6THJT0q6f8kvaqJ8auZpA2Bi4CPRsQTOWy2pH9IWiXpEUm/zHfXXUXSW4BlETG303EZQkPppa4dpbaJT+Vzt1TSf+dz3Mx9bC/pOUnfb8bmKoTFIOGjRUe+f04/z0gaXxY+L190JkbEhyLii8Pc/mskPSlpowqLVwFnAQcCx0l6/WCbqhA2mtJHuY4dj1rSTIWP7R0Ru5PO9UckXQBsnPOt+yR9s7ipCp/v5nPdK3laR+Mj6dzcNv35MgipUL1xlfLG+sAHJD0kaSXwTlpQoz6MckW3nVegtwrUw57uU9LGwGXA6cA40p3M54Gna9152Z3UsElal5SQz42IX5Yt/khEbAjsAGwKfJM6KGn1Od0beJukhaTHVW9sUq13s7V7eti35nO3O/Aq4NNN3v6RwGPAYZLWr/EzS0uZZP6/LIdXOzaL8uvy8NGik1MK3wccXnojaRdgTDM2HBFzSN/tHcVwSTuT8przI2IZcDHpsWl5unkyf8RTLvfX6eNRV5qJiMX5/zJgOSmfuheYBOyTXw+VR3Rar+dpnT6uxwMHAbOBc4HLgR8BS0srlI5rLvO8EtgMeAWwCTCf1Eyk2aqVK+o93x3VSwXqRqb73AEgIs6PiDUR8VREXBURtwJI+oBSr9eVkv4iafccvlDSiZJuBZ6UtI6kvXJN9wpJf5Y0pbQTSZtI+omkJZIelPQlSWvnZVMlXQ/MA94A/IekAytFNiIeJRW6d86ffa2km3Pt+s2SXlvY52xJp0r6P+DvwEsk7aTUI/bRXGN6cmHz60k6J3/X2yVNrvEYluJ2UkRsExETSefgtxHx3nq20SYdmR42Ih4kdXzZWdLb8jFekc/TK0rrSXpFDluR13nbEJs+klRIfxZ4a3FBrpE6DvgdOa3nO/7NgHsl/QE4Ebgkf2Rz4JScBu4GdgVuyo/UVuY0rrzPSxg9Ojml8E9Jx7vkKFJ7T6D/Y3ZJ4yVdltPOo5L+t3QjrdSL/5eSHpa0XNJ38ybOLts+wDHAlRGxXNL3gJNIFQ2bAJ8rxOOu/PpS8g2dpO1JBbGbmvT9e1Gnp6AeKs1skvP6hyXdL+kLktaSNJb0m7+adBN1VEQsBMbS93u/DfhUTmN/zetXPNeSPpGveYslHd3sL1nmUtL3JP+/pBA+IG12YZ7W6TTzKOn3PAn4Iel3fg/wM+Cnkn5BKmRPBKaS8oKNSGWL7YCtgK+WNjZY2aRIafSOrys9fb+X1Fb6eYOUK+o638M/LE3S6V6R9fyR7qz+SkoAn6rjcxuT7sjPJj3u2qyw7F3Ag6S7dQEvBbbLyxaSCsDbku78t87bOYh0M7Jffr95Xv9XpEQ6ltTW5ybgg3nZVGA16bHEraT2P88CB+Xls4H359fjgd+SMsxxpJrJ95Gmij88v39h4XP3Azvl5RsBS4BpwAb5/avzuqcA/8jxXxv4CnBDA+djCl06ykcj6WUY+1kIvCm/3ha4HTifVLO3H7AuqW3YAlLP7nXz65Pz+zcCK4GX5W3MBL5U2P6/kJ6mbEZ6ynJp2f4DeCj/PUuqbXgi7/vaHP4U8KJCmp+Rj8vinCa2zMsmky6m9wDfJc+mOlr+2pVmKqUf0oXuFfm3+QDpAhaki9vzaSL/bn+Q09G6OX0of+7PpCdbY/Pv/3WFdPks8OL8fq2cT9yXP7MI+FLOQz6T09uCnH6+Cvwsf+5T+djcxSgaAaab0ksdaeYcUgFko0Ie8gApf7qadN34BHADcHc+1+Poy5+uyt/rAVKBakD+BByQ85udc5o7L+//pU34jufnNPpsTp/HAC/M8Xw+voX1K6bNbsvTOpVm8r5fl8/PCuBxUpnkqHxc783L/pzfjyF1EFxKqhm+t+y41lI2KZVpPgTcScqHxpEqfwJYp0Icp9A3ykfd57uj57bTEWhjQnpFzggW5UR0KTABuBI4ocpnFgJHF96fCPy0bJ0rc4KcQMqwxhSWHQ78Lr+eSurdW1r2gpygSoWc2aRMawWpgH8uqSbxfaQ77eI+5wBTC5/7Qtk+/1Tl+5wCXFN4vyPwVKfPTa//5XSyKp+7vwHfJxVKZhXWWSuf1ymki9tDwFqF5ecDp+TXM+lfoP4x8Kv8+jWkC8wWheUBvLHw/gzgi2VxvAt4Q5X4zwMO6fRxHK1/9BWOPk0qLB9AKvCsQ+UC9RdIBaWXlm3nNcDDVLhI5eXXACfn1/sBjwDrVln3MWDX/PoUcoHaf93xV0Oa+SfS9WjHwmc+CMzOr9cGjgP+L6+3mFRTTT35E6n9/YzCejvQpAK1/1qafibka9YJhbBTgOvK1htDqviZm687C8iFV2orm5QK1L8FPlRY781UKVD38l8vNfloSETcERFTI2Ib0t30VqRepduS7nKqKfYk3Q54V34MtkLSCtId35Z52brAksKyH9LXKxVSJlWKz9/zy2LnteMjYtOI2DoijoiIh3M8/1YWp7/Rv0drMY5DfZ+HCq//DmygJrUPH+UOzeduu4j4d8rOW0Q8RzpPW+dlD+SwkvJzCoCkMaQa5XPzduaQapbeU7ZqeTqdVpZOt837RdKRSp2XSst2Jj0Vsc76Kem8TqXw6L6C/yLXIEq6V32TQ2wL/C0iVlf5XLHZx/uA8yLiWQBJ05SavT2e08QmOE30gmppZjzp6Vfx2vF8HhOp6eP3ImJvUn+dU4GzcrO0mvOn0rpl61mXi4ilpBvq28sWPVC23lMR8eWI2INUWzwL+LmkcdRWNikZFelk1BSoiyLiTtJd9s6kk/xPg61eeP0AqYZ608Lf2IiYkZc9TRo4v7Rs44jYqcHoLiYVkIpeTKrtrBbHwb6PtUe/85bb721LOm+LgW3VvwNp+Tkt+VdSk6XvK/W0foiUYZW3hy1PA6eWpdMXRMT5krYjdUL5COnR3Kakx6GjakbEbhQRfyM1wTgIKO+wXFxvZURMi4iXkNrT/6ekfUnn/cWD3CD/Etha0j7/v737j5arqu8+/v40/GwgVURjJKkXa2wbZRUkRfrQx15LKRFQ7A8tthZoWWVJqcbVdEli19PHrpY2dglL/NkVlRIqFiPaQlGwCN7log2hCSIxxJggqUYjEWprLm2RxG//2PuSuZOZuXPunDtzzszntdasO7Nnzrl73/nOnu89Z++zgV8lJ2CS/i/p7NsbSMPhnkU6HeyYqLgOMfM46Yhi43dHyz4mJ00fIJ2VWEax/mkv0yeH/fgsmmHVEW2fSFck+wvS0J6T6S43mTIScTISCbWkn8pHYBbnx0tIQyPuI51O/yOl5Ukl6cU56WjlY8BrJJ2bB9kfI2lc0uJIkx/+CbhG0oI8+eMnJP1Cj9X/LPASSb+pNCnyN0idXrslv28Hni/pbXnA/vGSXtFjHay4DcD5ks5WurLLKtI/XP9Cuu7nk8DbJR2pNLH1NaTZzc0uIZ1WPQU4Nd/OAk5VmtXfyoeBN0t6RY7p+ZLOV7ps2nxSp/ldAEm/Q578apVwGWn4zpPtXiDpgtxPiTRW/mC+3U/64lqb3/NjJJ01tV3e5y3A35COZG/OTx1PGgb3XeAISX9C+ifO6qFVzBwk9UFX5++AF5JWofsYQP5+GJd0bP5euYQUB1+iWP+0AbhU0jJJP8qhyaw2BCT9P0k/K+koSccAK0lDG3dQLDfZALxV0mKl5cP7uuR6v4xEQk2a8PUKYJOkJ0mJ9FeAVRHxSdLpro/n1/0DadD8YSLim6RrML6D9OXzTdKkjqm/48Wk02wPk/7bv4U0HGTWIuIJ4AJSQvYEaXLbBRHxeJvX7yeNj3wNaXjHTtIlkayPImIH8CbSJMLHSe/HayLiB5FWyHotaYLs46Qx1xfnMyfPkHQScDbwnoj4TsNtC3Anh2Y/N//uzcDvkSbgfI80PODS/NzDwDWksW6PkRL1fy6x6daDiHikIdFtZylpPPQk6X38YERMRMRBUpy9mDQsaA/wG03bricdVWocHvA50pVpvkY6Ffs/NJ36terqEDNvISXGXwfuJX3HXZ+f+29SP/AdUh90JfBrcWgFvxn7p/y77yANnbyH1M/cU17LrAKC9A/446Qj0ucA50fEZMHc5MOkfubLwAN0OANXZ4poe4TfzMzMzMxmMCpHqM3MzMzM5oQTajMzMzOzHjihNrOBypPn7ldaeXSbpD/N5Scorfi5M/98dsM2ayTtkrRD0rkN5adL2pqfe2+euGdmZjannFBbqZwc2Sw8RbpKwc+QrmKyQtKZpJngd0fEUtIqWasBJC0jLU/7UtKCFh+UNC/v60PA5aSJe0vz82ZmZnOq8gt6nHjiiTE2Njat7Mknn2T+/PmDqVABdaknlFrXx4GTI2IyXy7uXkl3kK57e3dErFVaiGI1cFVTcvQC4POSXpKvWDCVHN1HukTPCtLVCNqqc7yUqS5t3rJly+MR8VzSFSvg0HLaQbqiznguX09aeeuqXH5zRDwFPCppF3CGpN3Agrz4DZJuBF5Hh5gZ5XipYzu3bNnyfWBjRAzsH6VWMVM1dXtv57K+DX3MQAxrHzOsbeglXiqfUI+NjbF58/QrAk1MTDA+Pj6YChVQl3pCeXWV9G8RMZDkCOodL2WqS5sl/Vv+OY+0vO2LgQ9ExCZJC/P13YmIvZKmVh09ifRP1pQ9uezpfL+5vPl3Xk76R42FCxfy7ne/e9rzk5OTHHfccc2bDZ06tvNVr3rVzkEm09C6j6maunz+p8xlfaf6mEEZ1u+kYW1DL/FS+YTa6qefyVH+fdMSpImJiWnPT05OHlY27OrW5nxG4lRJzwL+XlKnxWZaDf2JDuXNv2sdsA5g+fLl0dyhDsMXRTdGpZ1mZv3ghNpK18/kKP8+J0hN6trmiPgPSROk4T2PSVqU/wFbBOzLL9vD9GVsF5MWHdiT7zeXm5mZzalaJtRbv/WfXLr6Mx1fs3vt+X2qjbVTleSom3gBx8ygSHou8HSOl2OBXwLeBdxGWg1ybf55a97kNuDjkq4ljbtfCtwfEQcl7c8TGjeRVi59X9H6OF5smIx1EcvgeK4zv8fV4Kt8WNmOyEemaUiOvsqh5AgOT44uknS0pJM5lBztBfZLOjNf3ePihm1suCwCviDpIeBfgbsi4nZSIn2OpJ2kJW/XAkTENmAD8DBpCfYr81kRgCuAj5CWQX6EGcbcm5mZlaGWR6it0o4kJUfzSP+wbYiI2yVtBDZIugz4BvB6SMmRpKnk6ACHJ0c3AMeSEiMnR0MoIh4CTmtR/gRwdpttrgaublG+Geg0xMjMzKx0TqitbP8dEcubC50cmZmZ2bDykA8zMzMzsx44oTYzMzMz64GHfJiZmZnZwAzDlUp8hNrMzMzMrAdOqM3MzGwkSXqWpFskfVXSdkk/J+kESXdJ2pl/Prvh9Wsk7ZK0Q9K5g6y7VYuHfJiZmdmoug64MyJ+XdJRwI8C7wDujoi1klYDq4GrJC0DLgJeSlpU6vOSXtJwqdeuDMPiUcPQhrI5oTYzMxtxwzCGtShJC4BXApcCRMQPgB9IuhAYzy9bD0wAVwEXAjdHxFPAo5J2AWcAG/tacaskJ9RmZmY2il4EfBf4G0k/A2wBVgIL82q9RMReSc/Lrz8JuK9h+z25bBpJlwOXAyxcuJCJiYlpzy88FladcmDGyjVv1043+yqyv24MQxsmJydL3Z8TajMzMxtFRwAvB94SEZskXUca3tGOWpTFYQUR64B1AMuXL4/x8fFpz7/vplu5ZuvM6dfu3xqf8TVAV0MviuyvG8PQhomJCZrfm154UqKZmZmNoj3AnojYlB/fQkqwH5O0CCD/3Nfw+iUN2y8Gvt2nulrFOaE2M7OhIWmepC9Juj0/9hUbrKWI+A7wTUk/mYvOBh4GbgMuyWWXALfm+7cBF0k6WtLJwFLg/j5W2SrMQz7MzGyYrAS2Awvy49XM4RUbrPbeAtyUr/DxdeB3SAcbN0i6DPgG8HqAiNgmaQMp6T4AXOl4sSlOqM3MbChIWgycD1wN/GEu9hUbrK2IeBBY3uKps9u8/mpSfJlN44TazMyGxXuAtwPHN5T1dMUGmPmqDVXTePWCbq+e0K25aHvZV1swG4QZE2pJS4AbgecDPwTWRcR1kk4APgGMAbuBN0TE9/I2a4DLgIPAWyPic7n8dOAG4Fjgs8DKiDhshqyZmVkRki4A9kXEFknj3WzSoqzl99FMV20YhE7XjV51ykGuuffJ/Kjc42ZlXmVhStlXWzAbhG4mJR4AVkXETwNnAlfmsWdT49KWAnfnxzSNS1sBfFDSvLyvD5H+y1+abytKbIuZmY2us4DXStoN3Az8oqSP4Ss2mFkfzJhQR8TeiHgg399PmuxxEmn82fr8svXA6/L9Z8alRcSjwC7gjNyRLYiIjfmo9I0N25iZmc1aRKyJiMURMUY6qHNPRLwJX7HBzPqg0LkgSWPAacAmio9Lezrfby5v9Xt6XmWoCuOx6jQurE51NTMrYC2+YoOZzbGuE2pJxwGfAt4WEd+XWg0/Sy9tURYdyg8vLGGVobkY51VUncaF1amuZmadRMQE6WoeRMQT+IoNZjbHulrYRdKRpGT6poj4dC4uOi5tT77fXG7D5UhJX5C0XdI2SSthdosrSDpd0tb83HvV4b84qy9JSxwzZmZWZzMm1PkL6aPA9oi4tuGpQuPS8vCQ/ZLOzPu8uGEbGy6exGpFeOKzmZnVWjdHqM8Cfps0Y/rBfDuPNC7tHEk7gXPyYyJiGzA1Lu1Opo9LuwL4CGmi4iPAHWU2xirhaU9itSI88dnMzOpuxjHUEXEvrcc/Q8FxaRGxGXhZkQpafdVpEitUYyJrWeo6ybQfMeN4SeoaI2ZmVeSVEm1O1G0SK1RjImtZ6jjJtF8x43hJ6hgjZmZV1dWkRLMiPInVinLMmJlZnTmhtrngSazWNU98NjOzuvOQDyvbcaRJrFslPZjL3sHsFle4ArgBOJY0gdWTWIfT1MRnx4yZmdWSE2or22REeBKrdc0Tn83MrO485MPMzMzMrAdOqM3MzGxkSZon6UuSbs+PC6/SauaE2szMzEbZStKCUlNms0qrjTgn1GZmZjaSJC0Gziet4jyl0CqtfaqqVZwnJZqZmdmoeg/wduD4hrKiq7RO0+/VWLvZV5H9dWMY2lD2arFOqM3MzCpibPVnBl2FkSHpAmBfRGyRNN7NJi3KBr4a66VdxkyZq7sOQxvKXi3WCbWZmZmNorOA10o6DzgGWCDpY+RVWvPR6W5WaTXzGGozMzMbPRGxJiIWR8QYabLhPRHxJgqu0trnaltF+Qi1mZmZ2SGzWaXVRpwTajMzsx50O+5599rz57gmNlsRMQFM5PtPUHCVVjMP+TAzMzMz64GPUJuZmVll+QyAFdVNzNywYn6pv9NHqM3MzMzMeuAj1GZmZn0wDNeY9tFis9Z8hNrMzMzMrAdOqM3MzMzMeuCE2szMhoKkJZK+IGm7pG2SVubyEyTdJWln/vnshm3WSNolaYekcwdXezOrsxkTaknXS9on6SsNZYU7J0mnS9qan3uvJJXfHDMzG2EHgFUR8dPAmcCVkpYBq4G7I2IpcHd+TH7uIuClwArgg5LmDaTmZlZr3RyhvoHU0TSaTef0IeBy0lKdS1vs08zMbNYiYm9EPJDv7we2AycBFwLr88vWA6/L9y8Ebo6IpyLiUWAXcEZfK21mQ2HGq3xExBcljTUVXwiM5/vrSasLXUVD5wQ8KmkXcIak3cCCiNgIIOlGUod2R88tMDMza5K/t04DNgELI2IvpKRb0vPyy04C7mvYbE8ua97X5aQDQixcuJCJiYlpz6865UDJte/NwmMHX6fmv1Enk5OTHV/fbVuK/E6zss32snlFO6en8/3m8pZm6ry66Syq8MGaqZOokjLrKul64AJgX0S8LJedAHwCGAN2A2+IiO/l59YAlwEHgbdGxOdy+emkMyTHAp8FVkZElFJJqwzHi5VN0nHAp4C3RcT3O4wwbPXEYTETEeuAdQDLly+P8fHxac9fWrHL4a065QDXbB3sVXF3/9Z416+dmJig+W/aqNu/b5HfaVa2sj9x7TqnrjqtZ56YofN63023zthZVOGDNVMnUSUl1/UG4P3AjQ1lU8OE1kpanR9f1TRM6AXA5yW9JCIOcmiY0H2kBGkFPqsxjG7A8WIlkXQkKZm+KSI+nYsfk7QoHwBaBOzL5XuAJQ2bLwa+3b/amtmwmO1VPh7LnRJddk578v3mchtCEfFF4N+biguNYcxxtSAiNuajjDc2bGNDxPFiZcmT3T8KbI+Iaxueug24JN+/BLi1ofwiSUdLOpk0v+f+ftXXzIbHbI9QT3VOazm8c/q4pGtJR4+WAvdHxEFJ+yWdSRrPdjHwvp5qbnUzZ8OEyhgiBNUYJlSWOg03asPxMseGIEZaOQv4bWCrpAdz2TtI31UbJF0GfAN4PUBEbJO0AXiYdIWQK/PZDuuDqVUXV51yoHLDZsyKmjGhlvR3pAmIJ0raA/x/Ztc5XcGh8Y134FOxlvQ8TKiMIUJQjWFCZanTcKOCHC8lGcYYiYh7aR0LAGe32eZq4Oo5q5SZjYRurvLxxjZPFeqcImIz8LJCtbNhUnQMo4cJjTbHi5nNKUlLSMPDng/8EFgXEdfNZlK02WCnAdso8TAhK8LxYlZjY/UYwjG1ENADko4Htki6C7iU4pOibcR56XErXR4mtBH4SUl78tCgtcA5knYC5+THRMQ2YGqY0J0cPkzoI6SJZ4/gYUJDyfFiZoPghYCsTD5CbaXzMCErwvFiZoPWz4WAyp74PIiFb6rehm72V/bEbCfUZmZmNrL6vRBQ2ROfB7HwTdXb0M3+blgxv9SJ2R7yYWZmZiOp00JA+XkvBGRdcUJtZmZmI8cLAVmZPOTDzMzMRpEXArLSOKE2MzOzkeOFgKxMHvJhZmZmZtYDJ9RmZmZmZj1wQm1mZmZm1gMn1GZmZmZmPXBCbWZmZmbWAyfUZmZmZmY9cEJtZmZmZtYDJ9RmZmZmZj1wQm1mZmZm1gMn1GZmZmZmPXBCbWZmZmbWAyfUZmZmZmY9cEJtZmZmZtYDJ9RmZmZmZj1wQm1mZmZm1oMj+v0LJa0ArgPmAR+JiLX9rkOjsdWfKXV/u9eeX+r+Rl3V4sWqzzFjRTherCjHjLXS1yPUkuYBHwBeDSwD3ihpWT/rYPXheLGiHDNWhOPFinLMWDv9PkJ9BrArIr4OIOlm4ELg4bJ/UdlHnmfze1edcoBL29TDR7K70rd4saFRuT7Gn/VKcx9jRTlmrKV+J9QnAd9seLwHeEXziyRdDlyeH05K2tH0khOBx+ekhiV6a4d66l19rszMyvqbvrCEfUzpa7xU8D3pRS0+I5QbL9BFzPS7f6lwXNUlRhotlXRnRKwoaX9l9TGV0um7p4rKqm+bz1pt+5iy+46S91f7NrzqXS3bMOt46XdCrRZlcVhBxDpgXdudSJsjYnmZFZsLdaknVLauIxUvZRrFNmczxozjJRmVds6glD6maur23tasvu5jcBta6fdVPvYASxoeLwa+3ec6WH04Xqwox4wV4Xixohwz1lK/E+p/JZ2yO1nSUcBFwG19roPVh+PFinLMWBGOFyvKMWMt9XXIR0QckPQHwOdIl5u5PiK2zWJXdTn1Vpd6QgXrOoLxUqZRbHNZMTMqf7tRaWdbJfYxVVO397Y29XUf8wy3oYkiDhsuZmZmZmZmXfJKiWZmZmZmPXBCbWZmZmbWg1ol1JJWSNohaZek1QOuyxJJX5C0XdI2SStz+TslfUvSg/l2XsM2a3Ldd0g6t8/13S1pa67T5lx2gqS7JO3MP59dhbqWpUrxMhdG8T2da3WLGUnXS9on6SsNZYVjQNLpOZZ2SXqvJOXyoyV9IpdvkjTW1wZaIa36hKopGrN10CEfmM1n8ShJ6yR9TdJXJf1aDdvwxhyHD0m6U9KJVWyDpOfk109Ken/Tvlr2iR1FRC1upMH/jwAvAo4CvgwsG2B9FgEvz/ePB75GWob0ncAftXj9slzno4GTc1vm9bG+u4ETm8r+Clid768G3lWFug5jvPg9rf6tjjEDvBJ4OfCVXmIAuB/4OdI1du8AXp3Lfx/463z/IuATg26zbx3j4bA+oWq3IjFbl1uHfGA2n8U/Bf483/+Rfr2fZbWBdLGLfVP1ztu/s6JtmA/8PPBm4P1N+2rZJ3a61ekI9TPLfUbED4Cp5T4HIiL2RsQD+f5+YDtpBaV2LgRujoinIuJRYBepTYN0IbA+318PvK6hvGp1LapS8dJHw/yezrXaxUxEfBH496biQjEgaRGwICI2RvomubFpm6l93QKc3dWRGrM2CsZsLXTIB2bTH/8u8Jd5Xz+MiL6seFliG5Rv83NfsYA+Xae7aBsi4smIuBf4n8b9zNAntlWnhLrVcp+dEti+yadBTwM25aI/yKc6rm84PTLo+gfwT5K2KC2LCrAwIvZCCkTgebl80HUtwzC0YSaj9p7OtWH5GxWNgZPy/ebyadtExAHgP4HnzFnNrVet+oQ6aBeztdOUDxT6LEp6Vn78Z5IekPRJSQv7UvEGvbQhIp4GrgC2khLpZcBH+1PzQ7psQzud+sS26pRQd7VEbL9JOg74FPC2iPg+8CHgJ4BTgb3ANVMvbbF5P+t/VkS8HHg1cKWkV3Z47aDrWoZhaMNMRu09nWvD/jdq175O7R72v8mwKdInWMla5ANtX9qiLEjDJRYD/5zfx43Au0uvaKeK9dgGSUeSEurTgBcADwFrSq9op4p134a2u2hRNmO/V6eEunLLfebA+RRwU0R8GiAiHouIgxHxQ+DDHDqNM9D6R8S38899wN/nej2WT21MneLYV4W6lmQY2tDRCL6nc21Y/kZFY2BPvt9cPm0bSUcAP8bhp+utItr0CXXQLmZro1U+QPHP4hPAf5HeO4BPksab90VJbTgVICIeycMlNgD/Z+5rnxRsQzud+sS26pRQV2q5zzw26KPA9oi4tqF8UcPLfgWYmsl8G3CR0qz5k4GlpEHv/ajrfEnHT90HfjnX6zbgkvyyS4BbB13XElUqXso2ou/pXBuWmCkUA/kU6H5JZ+Z+7eKmbab29evAPflL0iqmQ59QB+1ithba5QMU/ywG8I/AeH7d2cDDc1x9oLw2AN8Clkl6bn7dOaSxzHNuFm1oaYY+seOGtbkB55FmbT4C/PGA6/LzpFMADwEP5tt5wN+Sxg49lN/ERQ3b/HGu+w66mDFaYl1fRJqN+2Vg29TfjjQW8m5gZ/55wqDrOqzx4ve0Hre6xQzwd6ShZU+TjqpcNpsYAJaTkq9HgPdzaBXdY0hHyXaRvixfNOg2+9Y2Flr2CVW7FY3ZOtw65AOz+Sy+EPhi3tfdwI/XsA1vJiXRD5H+QXhOhduwm3TWbTLH47Jc3rJP7HTz0uNmZmZmZj2o05APMzMzM7PKcUJtZmZmZtYDJ9RmZmZmZj1wQm1mZmZm1gMn1GZmZmZmPXBCbWZmZmbWAyfUZmZmZmY9+F8rhXbY5+B5yAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x720 with 25 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "combined = combined[num_cols + cat_cols]\n",
    "combined.hist(figsize = (12,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "armed-implementation",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation between features\n",
    "train_data = train_data[num_cols + cat_cols]\n",
    "train_data['Target'] = target\n",
    "\n",
    "C_mat = train_data.corr()\n",
    "fig = plt.figure(figsize = (15,15))\n",
    "\n",
    "sb.heatmap(C_mat, vmax = .8, square = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "deluxe-anime",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 45 columns before encoding categorical features\n",
      "There are 149 columns after encoding categorical features\n"
     ]
    }
   ],
   "source": [
    "# We will encode the categorical features using one hot encoding.\n",
    "\n",
    "def oneHotEncode(df,colNames):\n",
    "    for col in colNames:\n",
    "        if( df[col].dtype == np.dtype('object')):\n",
    "            dummies = pd.get_dummies(df[col],prefix=col)\n",
    "            df = pd.concat([df,dummies],axis=1)\n",
    "\n",
    "            #drop the encoded column\n",
    "            df.drop([col],axis = 1 , inplace=True)\n",
    "    return df\n",
    "    \n",
    "\n",
    "print('There were {} columns before encoding categorical features'.format(combined.shape[1]))\n",
    "combined = oneHotEncode(combined, cat_cols)\n",
    "print('There are {} columns after encoding categorical features'.format(combined.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "norwegian-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split back combined dataFrame to training data and test data\n",
    "def split_combined():\n",
    "    global combined\n",
    "    train = combined[:1460]\n",
    "    test = combined[1460:]\n",
    "\n",
    "    return train , test \n",
    "  \n",
    "train, test = split_combined()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cloudy-vietnam",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_18 (Dense)             (None, 128)               19200     \n",
      "_________________________________________________________________\n",
      "dense_19 (Dense)             (None, 256)               33024     \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 184,065\n",
      "Trainable params: 184,065\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Second : Make the Deep Neural Network \n",
    "\n",
    "NN_model = Sequential()\n",
    "\n",
    "# Input Layers:\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layer\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "NN_model.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
    "\n",
    "# Compile the network\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer ='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "built-senate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a checkpoint callback \n",
    "\n",
    "checkpoint_name = 'Weights-{epoch:03d}--{val_loss:.5f}.hdf5' \n",
    "checkpoint = ModelCheckpoint(checkpoint_name, monitor='val_loss', verbose = 1, save_best_only = True, mode ='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "framed-reward",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 14749.6758 - mean_absolute_error: 14749.6758\n",
      "Epoch 00001: val_loss improved from inf to 29630.59180, saving model to Weights-001--29630.59180.hdf5\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 15367.5684 - mean_absolute_error: 15367.5684 - val_loss: 29630.5918 - val_mean_absolute_error: 29630.5918\n",
      "Epoch 2/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 18086.8066 - mean_absolute_error: 18086.8066\n",
      "Epoch 00002: val_loss improved from 29630.59180 to 20489.28516, saving model to Weights-002--20489.28516.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 16059.8457 - mean_absolute_error: 16059.8457 - val_loss: 20489.2852 - val_mean_absolute_error: 20489.2852\n",
      "Epoch 3/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 16727.0488 - mean_absolute_error: 16727.0488\n",
      "Epoch 00003: val_loss did not improve from 20489.28516\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 17437.1875 - mean_absolute_error: 17437.1875 - val_loss: 20550.6328 - val_mean_absolute_error: 20550.6328\n",
      "Epoch 4/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14198.2383 - mean_absolute_error: 14198.2383\n",
      "Epoch 00004: val_loss did not improve from 20489.28516\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14400.4473 - mean_absolute_error: 14400.4473 - val_loss: 23849.6758 - val_mean_absolute_error: 23849.6758\n",
      "Epoch 5/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 16934.1348 - mean_absolute_error: 16934.1348\n",
      "Epoch 00005: val_loss did not improve from 20489.28516\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15319.0664 - mean_absolute_error: 15319.0664 - val_loss: 20760.0410 - val_mean_absolute_error: 20760.0410\n",
      "Epoch 6/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12864.6289 - mean_absolute_error: 12864.6289\n",
      "Epoch 00006: val_loss did not improve from 20489.28516\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13734.7998 - mean_absolute_error: 13734.7998 - val_loss: 21263.2754 - val_mean_absolute_error: 21263.2754\n",
      "Epoch 7/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 15190.7783 - mean_absolute_error: 15190.7783\n",
      "Epoch 00007: val_loss improved from 20489.28516 to 20097.79492, saving model to Weights-007--20097.79492.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14272.3057 - mean_absolute_error: 14272.3057 - val_loss: 20097.7949 - val_mean_absolute_error: 20097.7949\n",
      "Epoch 8/500\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 13310.5674 - mean_absolute_error: 13310.5674\n",
      "Epoch 00008: val_loss did not improve from 20097.79492\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13552.2168 - mean_absolute_error: 13552.2168 - val_loss: 20753.3965 - val_mean_absolute_error: 20753.3965\n",
      "Epoch 9/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 13426.4268 - mean_absolute_error: 13426.4268\n",
      "Epoch 00009: val_loss did not improve from 20097.79492\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 13426.4268 - mean_absolute_error: 13426.4268 - val_loss: 20443.3672 - val_mean_absolute_error: 20443.3672\n",
      "Epoch 10/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13934.1191 - mean_absolute_error: 13934.1191\n",
      "Epoch 00010: val_loss did not improve from 20097.79492\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13542.2568 - mean_absolute_error: 13542.2568 - val_loss: 20399.5312 - val_mean_absolute_error: 20399.5312\n",
      "Epoch 11/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 14717.3027 - mean_absolute_error: 14717.3027\n",
      "Epoch 00011: val_loss did not improve from 20097.79492\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14717.3027 - mean_absolute_error: 14717.3027 - val_loss: 21324.3613 - val_mean_absolute_error: 21324.3613\n",
      "Epoch 12/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 18023.4980 - mean_absolute_error: 18023.4980\n",
      "Epoch 00012: val_loss did not improve from 20097.79492\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 16493.0469 - mean_absolute_error: 16493.0469 - val_loss: 20151.9219 - val_mean_absolute_error: 20151.9219\n",
      "Epoch 13/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 14452.0693 - mean_absolute_error: 14452.0693\n",
      "Epoch 00013: val_loss improved from 20097.79492 to 20081.39648, saving model to Weights-013--20081.39648.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13940.2051 - mean_absolute_error: 13940.2051 - val_loss: 20081.3965 - val_mean_absolute_error: 20081.3965\n",
      "Epoch 14/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 14580.4014 - mean_absolute_error: 14580.4014\n",
      "Epoch 00014: val_loss did not improve from 20081.39648\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13929.3154 - mean_absolute_error: 13929.3154 - val_loss: 20146.7109 - val_mean_absolute_error: 20146.7109\n",
      "Epoch 15/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13953.3516 - mean_absolute_error: 13953.3516\n",
      "Epoch 00015: val_loss did not improve from 20081.39648\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14935.0039 - mean_absolute_error: 14935.0039 - val_loss: 23222.8848 - val_mean_absolute_error: 23222.8848\n",
      "Epoch 16/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13704.8350 - mean_absolute_error: 13704.8350\n",
      "Epoch 00016: val_loss did not improve from 20081.39648\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14597.5293 - mean_absolute_error: 14597.5293 - val_loss: 20496.6348 - val_mean_absolute_error: 20496.6348\n",
      "Epoch 17/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 14465.8730 - mean_absolute_error: 14465.8730\n",
      "Epoch 00017: val_loss improved from 20081.39648 to 20021.92383, saving model to Weights-017--20021.92383.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14382.2910 - mean_absolute_error: 14382.2910 - val_loss: 20021.9238 - val_mean_absolute_error: 20021.9238\n",
      "Epoch 18/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 14345.4385 - mean_absolute_error: 14345.4385\n",
      "Epoch 00018: val_loss did not improve from 20021.92383\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14345.4385 - mean_absolute_error: 14345.4385 - val_loss: 20275.8262 - val_mean_absolute_error: 20275.8262\n",
      "Epoch 19/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13943.4941 - mean_absolute_error: 13943.4941\n",
      "Epoch 00019: val_loss improved from 20021.92383 to 19631.83789, saving model to Weights-019--19631.83789.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13703.4014 - mean_absolute_error: 13703.4014 - val_loss: 19631.8379 - val_mean_absolute_error: 19631.8379\n",
      "Epoch 20/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13327.3291 - mean_absolute_error: 13327.3291\n",
      "Epoch 00020: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13746.2549 - mean_absolute_error: 13746.2549 - val_loss: 20545.7148 - val_mean_absolute_error: 20545.7148\n",
      "Epoch 21/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14224.5098 - mean_absolute_error: 14224.5098\n",
      "Epoch 00021: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14361.2627 - mean_absolute_error: 14361.2627 - val_loss: 19892.1270 - val_mean_absolute_error: 19892.1270\n",
      "Epoch 22/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 13061.9473 - mean_absolute_error: 13061.9473\n",
      "Epoch 00022: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 13710.3467 - mean_absolute_error: 13710.3467 - val_loss: 20443.1035 - val_mean_absolute_error: 20443.1035\n",
      "Epoch 23/500\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 13896.6592 - mean_absolute_error: 13896.6592\n",
      "Epoch 00023: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13775.3574 - mean_absolute_error: 13775.3574 - val_loss: 22462.9570 - val_mean_absolute_error: 22462.9570\n",
      "Epoch 24/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14040.8320 - mean_absolute_error: 14040.8320\n",
      "Epoch 00024: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14001.6230 - mean_absolute_error: 14001.6230 - val_loss: 22685.7012 - val_mean_absolute_error: 22685.7012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/500\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 15420.9502 - mean_absolute_error: 15420.9502\n",
      "Epoch 00025: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 15305.5068 - mean_absolute_error: 15305.5068 - val_loss: 23402.4844 - val_mean_absolute_error: 23402.4844\n",
      "Epoch 26/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 15315.2725 - mean_absolute_error: 15315.2725\n",
      "Epoch 00026: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14906.0049 - mean_absolute_error: 14906.0049 - val_loss: 23570.7578 - val_mean_absolute_error: 23570.7578\n",
      "Epoch 27/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 15994.2949 - mean_absolute_error: 15994.2949\n",
      "Epoch 00027: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 15994.2949 - mean_absolute_error: 15994.2949 - val_loss: 20466.7637 - val_mean_absolute_error: 20466.7637\n",
      "Epoch 28/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14080.9629 - mean_absolute_error: 14080.9629\n",
      "Epoch 00028: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13899.3906 - mean_absolute_error: 13899.3906 - val_loss: 22498.4648 - val_mean_absolute_error: 22498.4648\n",
      "Epoch 29/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13492.4590 - mean_absolute_error: 13492.4590\n",
      "Epoch 00029: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13482.1396 - mean_absolute_error: 13482.1396 - val_loss: 22209.5684 - val_mean_absolute_error: 22209.5684\n",
      "Epoch 30/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 14787.3877 - mean_absolute_error: 14787.3877\n",
      "Epoch 00030: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14858.7207 - mean_absolute_error: 14858.7207 - val_loss: 21043.9707 - val_mean_absolute_error: 21043.9707\n",
      "Epoch 31/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13219.6357 - mean_absolute_error: 13219.6357\n",
      "Epoch 00031: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13838.3574 - mean_absolute_error: 13838.3574 - val_loss: 20572.2441 - val_mean_absolute_error: 20572.2441\n",
      "Epoch 32/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14932.2197 - mean_absolute_error: 14932.2197\n",
      "Epoch 00032: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14892.4346 - mean_absolute_error: 14892.4346 - val_loss: 20498.0664 - val_mean_absolute_error: 20498.0664\n",
      "Epoch 33/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 12907.4863 - mean_absolute_error: 12907.4863\n",
      "Epoch 00033: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15633.2432 - mean_absolute_error: 15633.2432 - val_loss: 27619.2539 - val_mean_absolute_error: 27619.2539\n",
      "Epoch 34/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 16517.0742 - mean_absolute_error: 16517.0742\n",
      "Epoch 00034: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15321.0449 - mean_absolute_error: 15321.0449 - val_loss: 20643.8730 - val_mean_absolute_error: 20643.8730\n",
      "Epoch 35/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13315.9307 - mean_absolute_error: 13315.9307\n",
      "Epoch 00035: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13284.3008 - mean_absolute_error: 13284.3008 - val_loss: 21306.4648 - val_mean_absolute_error: 21306.4648\n",
      "Epoch 36/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13868.6045 - mean_absolute_error: 13868.6045\n",
      "Epoch 00036: val_loss did not improve from 19631.83789\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13838.4053 - mean_absolute_error: 13838.4053 - val_loss: 23523.7500 - val_mean_absolute_error: 23523.7500\n",
      "Epoch 37/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 14777.3047 - mean_absolute_error: 14777.3047\n",
      "Epoch 00037: val_loss improved from 19631.83789 to 19212.57617, saving model to Weights-037--19212.57617.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14724.0088 - mean_absolute_error: 14724.0088 - val_loss: 19212.5762 - val_mean_absolute_error: 19212.5762\n",
      "Epoch 38/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 13876.3936 - mean_absolute_error: 13876.3936\n",
      "Epoch 00038: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13973.6260 - mean_absolute_error: 13973.6260 - val_loss: 28440.1406 - val_mean_absolute_error: 28440.1406\n",
      "Epoch 39/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 15928.9922 - mean_absolute_error: 15928.9922\n",
      "Epoch 00039: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14695.0635 - mean_absolute_error: 14695.0635 - val_loss: 21781.1504 - val_mean_absolute_error: 21781.1504\n",
      "Epoch 40/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 16450.8633 - mean_absolute_error: 16450.8633\n",
      "Epoch 00040: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 16356.1504 - mean_absolute_error: 16356.1504 - val_loss: 23269.0195 - val_mean_absolute_error: 23269.0195\n",
      "Epoch 41/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 14289.1855 - mean_absolute_error: 14289.1855\n",
      "Epoch 00041: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14281.5869 - mean_absolute_error: 14281.5869 - val_loss: 21665.9727 - val_mean_absolute_error: 21665.9727\n",
      "Epoch 42/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13578.5000 - mean_absolute_error: 13578.5000\n",
      "Epoch 00042: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13480.9199 - mean_absolute_error: 13480.9199 - val_loss: 20676.5254 - val_mean_absolute_error: 20676.5254\n",
      "Epoch 43/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11926.7715 - mean_absolute_error: 11926.7715\n",
      "Epoch 00043: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12718.3115 - mean_absolute_error: 12718.3115 - val_loss: 20397.0664 - val_mean_absolute_error: 20397.0664\n",
      "Epoch 44/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12869.3584 - mean_absolute_error: 12869.3584\n",
      "Epoch 00044: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13309.2803 - mean_absolute_error: 13309.2803 - val_loss: 19318.6914 - val_mean_absolute_error: 19318.6914\n",
      "Epoch 45/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14168.1533 - mean_absolute_error: 14168.1533\n",
      "Epoch 00045: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14074.4248 - mean_absolute_error: 14074.4248 - val_loss: 20006.8965 - val_mean_absolute_error: 20006.8965\n",
      "Epoch 46/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 13354.5508 - mean_absolute_error: 13354.5508\n",
      "Epoch 00046: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 13216.1113 - mean_absolute_error: 13216.1113 - val_loss: 20441.6758 - val_mean_absolute_error: 20441.6758\n",
      "Epoch 47/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14611.8438 - mean_absolute_error: 14611.8438\n",
      "Epoch 00047: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14065.2266 - mean_absolute_error: 14065.2266 - val_loss: 19844.3848 - val_mean_absolute_error: 19844.3848\n",
      "Epoch 48/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13752.1504 - mean_absolute_error: 13752.1504\n",
      "Epoch 00048: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13551.3018 - mean_absolute_error: 13551.3018 - val_loss: 21035.9980 - val_mean_absolute_error: 21035.9980\n",
      "Epoch 49/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13473.8584 - mean_absolute_error: 13473.8584\n",
      "Epoch 00049: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13523.6035 - mean_absolute_error: 13523.6035 - val_loss: 20120.4258 - val_mean_absolute_error: 20120.4258\n",
      "Epoch 50/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13018.4482 - mean_absolute_error: 13018.4482\n",
      "Epoch 00050: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13159.4424 - mean_absolute_error: 13159.4424 - val_loss: 19490.3867 - val_mean_absolute_error: 19490.3867\n",
      "Epoch 51/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13332.0254 - mean_absolute_error: 13332.0254\n",
      "Epoch 00051: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13111.2520 - mean_absolute_error: 13111.2520 - val_loss: 20116.2715 - val_mean_absolute_error: 20116.2715\n",
      "Epoch 52/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12288.4521 - mean_absolute_error: 12288.4521\n",
      "Epoch 00052: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13138.0312 - mean_absolute_error: 13138.0312 - val_loss: 22629.5508 - val_mean_absolute_error: 22629.5508\n",
      "Epoch 53/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13939.4844 - mean_absolute_error: 13939.4844\n",
      "Epoch 00053: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14587.3730 - mean_absolute_error: 14587.3730 - val_loss: 22045.5156 - val_mean_absolute_error: 22045.5156\n",
      "Epoch 54/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14003.8994 - mean_absolute_error: 14003.8994\n",
      "Epoch 00054: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14473.8750 - mean_absolute_error: 14473.8750 - val_loss: 20355.8965 - val_mean_absolute_error: 20355.8965\n",
      "Epoch 55/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13379.3721 - mean_absolute_error: 13379.3721\n",
      "Epoch 00055: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13840.6084 - mean_absolute_error: 13840.6084 - val_loss: 20056.6289 - val_mean_absolute_error: 20056.6289\n",
      "Epoch 56/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13752.4160 - mean_absolute_error: 13752.4160\n",
      "Epoch 00056: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13717.6123 - mean_absolute_error: 13717.6123 - val_loss: 22175.3555 - val_mean_absolute_error: 22175.3555\n",
      "Epoch 57/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 15694.3555 - mean_absolute_error: 15694.3555\n",
      "Epoch 00057: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14636.3301 - mean_absolute_error: 14636.3301 - val_loss: 20622.6289 - val_mean_absolute_error: 20622.6289\n",
      "Epoch 58/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13486.2725 - mean_absolute_error: 13486.2725\n",
      "Epoch 00058: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13152.8115 - mean_absolute_error: 13152.8115 - val_loss: 20892.9219 - val_mean_absolute_error: 20892.9219\n",
      "Epoch 59/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12496.6924 - mean_absolute_error: 12496.6924\n",
      "Epoch 00059: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13167.6826 - mean_absolute_error: 13167.6826 - val_loss: 20441.3398 - val_mean_absolute_error: 20441.3398\n",
      "Epoch 60/500\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 14485.3135 - mean_absolute_error: 14485.3135\n",
      "Epoch 00060: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14259.9961 - mean_absolute_error: 14259.9961 - val_loss: 20127.2734 - val_mean_absolute_error: 20127.2734\n",
      "Epoch 61/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 12312.6855 - mean_absolute_error: 12312.6855\n",
      "Epoch 00061: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13019.4297 - mean_absolute_error: 13019.4297 - val_loss: 21330.7832 - val_mean_absolute_error: 21330.7832\n",
      "Epoch 62/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 12657.2900 - mean_absolute_error: 12657.2900\n",
      "Epoch 00062: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13961.2559 - mean_absolute_error: 13961.2559 - val_loss: 21073.8398 - val_mean_absolute_error: 21073.8398\n",
      "Epoch 63/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 13534.8389 - mean_absolute_error: 13534.8389\n",
      "Epoch 00063: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13280.2451 - mean_absolute_error: 13280.2451 - val_loss: 19449.7539 - val_mean_absolute_error: 19449.7539\n",
      "Epoch 64/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 12923.4834 - mean_absolute_error: 12923.4834\n",
      "Epoch 00064: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13503.7852 - mean_absolute_error: 13503.7852 - val_loss: 20658.2734 - val_mean_absolute_error: 20658.2734\n",
      "Epoch 65/500\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14473.5811 - mean_absolute_error: 14473.5811\n",
      "Epoch 00065: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14811.9160 - mean_absolute_error: 14811.9160 - val_loss: 25117.7539 - val_mean_absolute_error: 25117.7539\n",
      "Epoch 66/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 14439.5566 - mean_absolute_error: 14439.5566\n",
      "Epoch 00066: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14595.0459 - mean_absolute_error: 14595.0459 - val_loss: 21940.1074 - val_mean_absolute_error: 21940.1074\n",
      "Epoch 67/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13623.7617 - mean_absolute_error: 13623.7617\n",
      "Epoch 00067: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13707.1514 - mean_absolute_error: 13707.1514 - val_loss: 19805.9746 - val_mean_absolute_error: 19805.9746\n",
      "Epoch 68/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14290.5195 - mean_absolute_error: 14290.5195\n",
      "Epoch 00068: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14608.3252 - mean_absolute_error: 14608.3252 - val_loss: 21022.0762 - val_mean_absolute_error: 21022.0762\n",
      "Epoch 69/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 14746.2441 - mean_absolute_error: 14746.2441\n",
      "Epoch 00069: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14580.4180 - mean_absolute_error: 14580.4180 - val_loss: 19686.8535 - val_mean_absolute_error: 19686.8535\n",
      "Epoch 70/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14312.1611 - mean_absolute_error: 14312.1611\n",
      "Epoch 00070: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13830.0410 - mean_absolute_error: 13830.0410 - val_loss: 19878.6660 - val_mean_absolute_error: 19878.6660\n",
      "Epoch 71/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13415.8818 - mean_absolute_error: 13415.8818\n",
      "Epoch 00071: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14072.8320 - mean_absolute_error: 14072.8320 - val_loss: 20266.9922 - val_mean_absolute_error: 20266.9922\n",
      "Epoch 72/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13494.4795 - mean_absolute_error: 13494.4795\n",
      "Epoch 00072: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13689.1445 - mean_absolute_error: 13689.1445 - val_loss: 21222.5078 - val_mean_absolute_error: 21222.5078\n",
      "Epoch 73/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 14338.3271 - mean_absolute_error: 14338.3271\n",
      "Epoch 00073: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14604.5703 - mean_absolute_error: 14604.5703 - val_loss: 20921.0312 - val_mean_absolute_error: 20921.0312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 13058.0186 - mean_absolute_error: 13058.0186\n",
      "Epoch 00074: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13356.0293 - mean_absolute_error: 13356.0293 - val_loss: 21574.7578 - val_mean_absolute_error: 21574.7578\n",
      "Epoch 75/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14759.4775 - mean_absolute_error: 14759.4775\n",
      "Epoch 00075: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14513.6250 - mean_absolute_error: 14513.6250 - val_loss: 21529.8613 - val_mean_absolute_error: 21529.8613\n",
      "Epoch 76/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 16289.0879 - mean_absolute_error: 16289.087 - ETA: 0s - loss: 14035.2939 - mean_absolute_error: 14035.2939\n",
      "Epoch 00076: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14617.7178 - mean_absolute_error: 14617.7178 - val_loss: 22171.3965 - val_mean_absolute_error: 22171.3965\n",
      "Epoch 77/500\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 15280.7178 - mean_absolute_error: 15280.7178\n",
      "Epoch 00077: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 15168.7432 - mean_absolute_error: 15168.7432 - val_loss: 23319.5957 - val_mean_absolute_error: 23319.5957\n",
      "Epoch 78/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13662.5654 - mean_absolute_error: 13662.5654\n",
      "Epoch 00078: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14001.0732 - mean_absolute_error: 14001.0732 - val_loss: 20382.0137 - val_mean_absolute_error: 20382.0137\n",
      "Epoch 79/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13864.7402 - mean_absolute_error: 13864.7402\n",
      "Epoch 00079: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13991.8252 - mean_absolute_error: 13991.8252 - val_loss: 19752.0684 - val_mean_absolute_error: 19752.0684\n",
      "Epoch 80/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13700.0176 - mean_absolute_error: 13700.0176\n",
      "Epoch 00080: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13647.3789 - mean_absolute_error: 13647.3789 - val_loss: 21950.4453 - val_mean_absolute_error: 21950.4453\n",
      "Epoch 81/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13950.0615 - mean_absolute_error: 13950.0615\n",
      "Epoch 00081: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13962.4688 - mean_absolute_error: 13962.4688 - val_loss: 20577.8398 - val_mean_absolute_error: 20577.8398\n",
      "Epoch 82/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 13717.7402 - mean_absolute_error: 13717.7402\n",
      "Epoch 00082: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 13342.3965 - mean_absolute_error: 13342.3965 - val_loss: 20404.1230 - val_mean_absolute_error: 20404.1230\n",
      "Epoch 83/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13128.1758 - mean_absolute_error: 13128.1758\n",
      "Epoch 00083: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12586.6279 - mean_absolute_error: 12586.6279 - val_loss: 19788.6641 - val_mean_absolute_error: 19788.6641\n",
      "Epoch 84/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12726.2334 - mean_absolute_error: 12726.2334\n",
      "Epoch 00084: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13450.4961 - mean_absolute_error: 13450.4961 - val_loss: 21852.1211 - val_mean_absolute_error: 21852.1211\n",
      "Epoch 85/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 13468.5928 - mean_absolute_error: 13468.5928\n",
      "Epoch 00085: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13325.0615 - mean_absolute_error: 13325.0615 - val_loss: 21154.8457 - val_mean_absolute_error: 21154.8457\n",
      "Epoch 86/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 17167.3594 - mean_absolute_error: 17167.3594\n",
      "Epoch 00086: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 17548.6328 - mean_absolute_error: 17548.6328 - val_loss: 23732.1309 - val_mean_absolute_error: 23732.1309\n",
      "Epoch 87/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13476.3398 - mean_absolute_error: 13476.3398\n",
      "Epoch 00087: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13817.7021 - mean_absolute_error: 13817.7021 - val_loss: 26180.1914 - val_mean_absolute_error: 26180.1914\n",
      "Epoch 88/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 16191.9473 - mean_absolute_error: 16191.9473\n",
      "Epoch 00088: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15133.5703 - mean_absolute_error: 15133.5703 - val_loss: 23156.8477 - val_mean_absolute_error: 23156.8477\n",
      "Epoch 89/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13508.7842 - mean_absolute_error: 13508.7842\n",
      "Epoch 00089: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13176.7949 - mean_absolute_error: 13176.7949 - val_loss: 20666.2637 - val_mean_absolute_error: 20666.2637\n",
      "Epoch 90/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12142.0869 - mean_absolute_error: 12142.0869\n",
      "Epoch 00090: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12869.9121 - mean_absolute_error: 12869.9121 - val_loss: 22526.0078 - val_mean_absolute_error: 22526.0078\n",
      "Epoch 91/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13815.2402 - mean_absolute_error: 13815.2402\n",
      "Epoch 00091: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14403.6318 - mean_absolute_error: 14403.6318 - val_loss: 20169.8125 - val_mean_absolute_error: 20169.8125\n",
      "Epoch 92/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12995.5469 - mean_absolute_error: 12995.5469\n",
      "Epoch 00092: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12973.9795 - mean_absolute_error: 12973.9795 - val_loss: 21945.9863 - val_mean_absolute_error: 21945.9863\n",
      "Epoch 93/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12494.2354 - mean_absolute_error: 12494.2354\n",
      "Epoch 00093: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12977.8203 - mean_absolute_error: 12977.8203 - val_loss: 21876.3965 - val_mean_absolute_error: 21876.3965\n",
      "Epoch 94/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13219.5146 - mean_absolute_error: 13219.5146\n",
      "Epoch 00094: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13070.7363 - mean_absolute_error: 13070.7363 - val_loss: 20522.7676 - val_mean_absolute_error: 20522.7676\n",
      "Epoch 95/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12885.8428 - mean_absolute_error: 12885.8428\n",
      "Epoch 00095: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12737.0312 - mean_absolute_error: 12737.0312 - val_loss: 20536.9980 - val_mean_absolute_error: 20536.9980\n",
      "Epoch 96/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13456.1865 - mean_absolute_error: 13456.1865\n",
      "Epoch 00096: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14646.5273 - mean_absolute_error: 14646.5273 - val_loss: 20198.8262 - val_mean_absolute_error: 20198.8262\n",
      "Epoch 97/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 15454.2578 - mean_absolute_error: 15454.2578\n",
      "Epoch 00097: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14936.7207 - mean_absolute_error: 14936.7207 - val_loss: 20404.2070 - val_mean_absolute_error: 20404.2070\n",
      "Epoch 98/500\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 15288.9072 - mean_absolute_error: 15288.9072\n",
      "Epoch 00098: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14991.3018 - mean_absolute_error: 14991.3018 - val_loss: 21066.3965 - val_mean_absolute_error: 21066.3965\n",
      "Epoch 99/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 14072.6416 - mean_absolute_error: 14072.6416\n",
      "Epoch 00099: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14070.6367 - mean_absolute_error: 14070.6367 - val_loss: 20347.1309 - val_mean_absolute_error: 20347.1309\n",
      "Epoch 100/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13952.9092 - mean_absolute_error: 13952.9092\n",
      "Epoch 00100: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13988.7168 - mean_absolute_error: 13988.7168 - val_loss: 24417.3535 - val_mean_absolute_error: 24417.3535\n",
      "Epoch 101/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13567.8818 - mean_absolute_error: 13567.8818\n",
      "Epoch 00101: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13477.5312 - mean_absolute_error: 13477.5312 - val_loss: 20460.4355 - val_mean_absolute_error: 20460.4355\n",
      "Epoch 102/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13047.2090 - mean_absolute_error: 13047.2090\n",
      "Epoch 00102: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13726.3789 - mean_absolute_error: 13726.3789 - val_loss: 22624.5215 - val_mean_absolute_error: 22624.5215\n",
      "Epoch 103/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 20079.6094 - mean_absolute_error: 20079.6094\n",
      "Epoch 00103: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 18101.3438 - mean_absolute_error: 18101.3438 - val_loss: 21512.7480 - val_mean_absolute_error: 21512.7480\n",
      "Epoch 104/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11744.7812 - mean_absolute_error: 11744.7812\n",
      "Epoch 00104: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12529.0391 - mean_absolute_error: 12529.0391 - val_loss: 20459.1836 - val_mean_absolute_error: 20459.1836\n",
      "Epoch 105/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13733.4287 - mean_absolute_error: 13733.4287\n",
      "Epoch 00105: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14232.7773 - mean_absolute_error: 14232.7773 - val_loss: 20090.2539 - val_mean_absolute_error: 20090.2539\n",
      "Epoch 106/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 12370.9502 - mean_absolute_error: 12370.9502\n",
      "Epoch 00106: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12631.8350 - mean_absolute_error: 12631.8350 - val_loss: 20708.9375 - val_mean_absolute_error: 20708.9375\n",
      "Epoch 107/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 17517.1074 - mean_absolute_error: 17517.1074\n",
      "Epoch 00107: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 17178.8184 - mean_absolute_error: 17178.8184 - val_loss: 21525.8066 - val_mean_absolute_error: 21525.8066\n",
      "Epoch 108/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13959.0176 - mean_absolute_error: 13959.0176\n",
      "Epoch 00108: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14504.6475 - mean_absolute_error: 14504.6475 - val_loss: 19862.1074 - val_mean_absolute_error: 19862.1074\n",
      "Epoch 109/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13448.6357 - mean_absolute_error: 13448.6357\n",
      "Epoch 00109: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13691.3633 - mean_absolute_error: 13691.3633 - val_loss: 20915.0840 - val_mean_absolute_error: 20915.0840\n",
      "Epoch 110/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13435.2920 - mean_absolute_error: 13435.2920\n",
      "Epoch 00110: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13434.9395 - mean_absolute_error: 13434.9395 - val_loss: 19942.0918 - val_mean_absolute_error: 19942.0918\n",
      "Epoch 111/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12684.8271 - mean_absolute_error: 12684.8271\n",
      "Epoch 00111: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12556.8291 - mean_absolute_error: 12556.8291 - val_loss: 20355.6973 - val_mean_absolute_error: 20355.6973\n",
      "Epoch 112/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 13289.2168 - mean_absolute_error: 13289.2168\n",
      "Epoch 00112: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14563.1357 - mean_absolute_error: 14563.1357 - val_loss: 21586.6680 - val_mean_absolute_error: 21586.6680\n",
      "Epoch 113/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12234.9893 - mean_absolute_error: 12234.9893\n",
      "Epoch 00113: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12734.2246 - mean_absolute_error: 12734.2246 - val_loss: 20730.4238 - val_mean_absolute_error: 20730.4238\n",
      "Epoch 114/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12499.7432 - mean_absolute_error: 12499.7432\n",
      "Epoch 00114: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13331.5166 - mean_absolute_error: 13331.5166 - val_loss: 19938.8828 - val_mean_absolute_error: 19938.8828\n",
      "Epoch 115/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 14651.0547 - mean_absolute_error: 14651.0547\n",
      "Epoch 00115: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14200.0889 - mean_absolute_error: 14200.0889 - val_loss: 22053.9277 - val_mean_absolute_error: 22053.9277\n",
      "Epoch 116/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 15772.6523 - mean_absolute_error: 15772.6523\n",
      "Epoch 00116: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15129.3936 - mean_absolute_error: 15129.3936 - val_loss: 20697.0645 - val_mean_absolute_error: 20697.0645\n",
      "Epoch 117/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12912.8691 - mean_absolute_error: 12912.8691\n",
      "Epoch 00117: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13683.4385 - mean_absolute_error: 13683.4385 - val_loss: 20039.8535 - val_mean_absolute_error: 20039.8535\n",
      "Epoch 118/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13358.1787 - mean_absolute_error: 13358.1787\n",
      "Epoch 00118: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13014.7227 - mean_absolute_error: 13014.7227 - val_loss: 20334.4941 - val_mean_absolute_error: 20334.4941\n",
      "Epoch 119/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12311.4658 - mean_absolute_error: 12311.4658\n",
      "Epoch 00119: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13144.1016 - mean_absolute_error: 13144.1016 - val_loss: 20585.7480 - val_mean_absolute_error: 20585.7480\n",
      "Epoch 120/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13016.0107 - mean_absolute_error: 13016.0107\n",
      "Epoch 00120: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13577.4043 - mean_absolute_error: 13577.4043 - val_loss: 20344.3184 - val_mean_absolute_error: 20344.3184\n",
      "Epoch 121/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12736.6328 - mean_absolute_error: 12736.6328\n",
      "Epoch 00121: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13108.1357 - mean_absolute_error: 13108.1357 - val_loss: 19782.6250 - val_mean_absolute_error: 19782.6250\n",
      "Epoch 122/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/37 [==================>...........] - ETA: 0s - loss: 12507.7539 - mean_absolute_error: 12507.7539\n",
      "Epoch 00122: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12657.3545 - mean_absolute_error: 12657.3545 - val_loss: 21393.6504 - val_mean_absolute_error: 21393.6504\n",
      "Epoch 123/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12976.0947 - mean_absolute_error: 12976.0947\n",
      "Epoch 00123: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12577.9824 - mean_absolute_error: 12577.9824 - val_loss: 20905.7285 - val_mean_absolute_error: 20905.7285\n",
      "Epoch 124/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13148.9688 - mean_absolute_error: 13148.9688\n",
      "Epoch 00124: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13407.4775 - mean_absolute_error: 13407.4775 - val_loss: 21057.7715 - val_mean_absolute_error: 21057.7715\n",
      "Epoch 125/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13774.0303 - mean_absolute_error: 13774.0303\n",
      "Epoch 00125: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13358.0850 - mean_absolute_error: 13358.0850 - val_loss: 20443.5762 - val_mean_absolute_error: 20443.5762\n",
      "Epoch 126/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13512.5889 - mean_absolute_error: 13512.5889\n",
      "Epoch 00126: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14061.7812 - mean_absolute_error: 14061.7812 - val_loss: 23415.4336 - val_mean_absolute_error: 23415.4336\n",
      "Epoch 127/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 14713.3887 - mean_absolute_error: 14713.3887\n",
      "Epoch 00127: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14329.8906 - mean_absolute_error: 14329.8906 - val_loss: 20837.8203 - val_mean_absolute_error: 20837.8203\n",
      "Epoch 128/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12370.0342 - mean_absolute_error: 12370.0342\n",
      "Epoch 00128: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12707.8574 - mean_absolute_error: 12707.8574 - val_loss: 20438.1113 - val_mean_absolute_error: 20438.1113\n",
      "Epoch 129/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12846.0537 - mean_absolute_error: 12846.0537\n",
      "Epoch 00129: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12903.1826 - mean_absolute_error: 12903.1826 - val_loss: 20349.0879 - val_mean_absolute_error: 20349.0879\n",
      "Epoch 130/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 12193.0947 - mean_absolute_error: 12193.0947\n",
      "Epoch 00130: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12711.6230 - mean_absolute_error: 12711.6230 - val_loss: 20340.1719 - val_mean_absolute_error: 20340.1719\n",
      "Epoch 131/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 14301.7100 - mean_absolute_error: 14301.7100\n",
      "Epoch 00131: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15191.7480 - mean_absolute_error: 15191.7480 - val_loss: 20044.6875 - val_mean_absolute_error: 20044.6875\n",
      "Epoch 132/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13298.6279 - mean_absolute_error: 13298.6279\n",
      "Epoch 00132: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13894.5039 - mean_absolute_error: 13894.5039 - val_loss: 20427.0762 - val_mean_absolute_error: 20427.0762\n",
      "Epoch 133/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 15066.3105 - mean_absolute_error: 15066.3105\n",
      "Epoch 00133: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14082.9805 - mean_absolute_error: 14082.9805 - val_loss: 20349.7832 - val_mean_absolute_error: 20349.7832\n",
      "Epoch 134/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12626.5303 - mean_absolute_error: 12626.5303\n",
      "Epoch 00134: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12853.8740 - mean_absolute_error: 12853.8740 - val_loss: 20783.3242 - val_mean_absolute_error: 20783.3242\n",
      "Epoch 135/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12704.9932 - mean_absolute_error: 12704.9932\n",
      "Epoch 00135: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12755.1084 - mean_absolute_error: 12755.1084 - val_loss: 21099.3301 - val_mean_absolute_error: 21099.3301\n",
      "Epoch 136/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 15449.4805 - mean_absolute_error: 15449.4805\n",
      "Epoch 00136: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14765.4434 - mean_absolute_error: 14765.4434 - val_loss: 20139.9609 - val_mean_absolute_error: 20139.9609\n",
      "Epoch 137/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 13158.9453 - mean_absolute_error: 13158.9453\n",
      "Epoch 00137: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13347.1748 - mean_absolute_error: 13347.1748 - val_loss: 20568.8711 - val_mean_absolute_error: 20568.8711\n",
      "Epoch 138/500\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 13728.3477 - mean_absolute_error: 13728.3477\n",
      "Epoch 00138: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13852.4053 - mean_absolute_error: 13852.4053 - val_loss: 20012.3496 - val_mean_absolute_error: 20012.3496\n",
      "Epoch 139/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13336.3604 - mean_absolute_error: 13336.3604\n",
      "Epoch 00139: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13299.0586 - mean_absolute_error: 13299.0586 - val_loss: 25535.5215 - val_mean_absolute_error: 25535.5215\n",
      "Epoch 140/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 15193.4824 - mean_absolute_error: 15193.4824\n",
      "Epoch 00140: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14575.8711 - mean_absolute_error: 14575.8711 - val_loss: 22056.7227 - val_mean_absolute_error: 22056.7227\n",
      "Epoch 141/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 13422.4717 - mean_absolute_error: 13422.4717\n",
      "Epoch 00141: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12807.7119 - mean_absolute_error: 12807.7119 - val_loss: 21158.3828 - val_mean_absolute_error: 21158.3828\n",
      "Epoch 142/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 15006.6953 - mean_absolute_error: 15006.6953\n",
      "Epoch 00142: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14871.5312 - mean_absolute_error: 14871.5312 - val_loss: 26957.7207 - val_mean_absolute_error: 26957.7207\n",
      "Epoch 143/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 15557.8926 - mean_absolute_error: 15557.8926\n",
      "Epoch 00143: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14720.9541 - mean_absolute_error: 14720.9541 - val_loss: 20490.6797 - val_mean_absolute_error: 20490.6797\n",
      "Epoch 144/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12875.3936 - mean_absolute_error: 12875.3936\n",
      "Epoch 00144: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13344.0127 - mean_absolute_error: 13344.0127 - val_loss: 20447.5996 - val_mean_absolute_error: 20447.5996\n",
      "Epoch 145/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12731.0410 - mean_absolute_error: 12731.0410\n",
      "Epoch 00145: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12693.4531 - mean_absolute_error: 12693.4531 - val_loss: 21492.9609 - val_mean_absolute_error: 21492.9609\n",
      "Epoch 146/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13350.9580 - mean_absolute_error: 13350.9580\n",
      "Epoch 00146: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13945.0713 - mean_absolute_error: 13945.0713 - val_loss: 20169.0391 - val_mean_absolute_error: 20169.0391\n",
      "Epoch 147/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13689.0439 - mean_absolute_error: 13689.0439\n",
      "Epoch 00147: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13412.8174 - mean_absolute_error: 13412.8174 - val_loss: 20362.3223 - val_mean_absolute_error: 20362.3223\n",
      "Epoch 148/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 16201.3477 - mean_absolute_error: 16201.3477\n",
      "Epoch 00148: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15736.6299 - mean_absolute_error: 15736.6299 - val_loss: 24255.8125 - val_mean_absolute_error: 24255.8125\n",
      "Epoch 149/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 16093.8125 - mean_absolute_error: 16093.8125\n",
      "Epoch 00149: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15324.0977 - mean_absolute_error: 15324.0977 - val_loss: 20805.4316 - val_mean_absolute_error: 20805.4316\n",
      "Epoch 150/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 16196.5166 - mean_absolute_error: 16196.5166\n",
      "Epoch 00150: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15116.2754 - mean_absolute_error: 15116.2754 - val_loss: 20772.8340 - val_mean_absolute_error: 20772.8340\n",
      "Epoch 151/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12457.8252 - mean_absolute_error: 12457.8252\n",
      "Epoch 00151: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12464.7510 - mean_absolute_error: 12464.7510 - val_loss: 21059.1621 - val_mean_absolute_error: 21059.1621\n",
      "Epoch 152/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 14594.1934 - mean_absolute_error: 14594.1934\n",
      "Epoch 00152: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13990.0586 - mean_absolute_error: 13990.0586 - val_loss: 23255.1152 - val_mean_absolute_error: 23255.1152\n",
      "Epoch 153/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13773.0938 - mean_absolute_error: 13773.0938\n",
      "Epoch 00153: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13809.1152 - mean_absolute_error: 13809.1152 - val_loss: 19932.2402 - val_mean_absolute_error: 19932.2402\n",
      "Epoch 154/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 12486.8818 - mean_absolute_error: 12486.8818\n",
      "Epoch 00154: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12975.6621 - mean_absolute_error: 12975.6621 - val_loss: 20433.5664 - val_mean_absolute_error: 20433.5664\n",
      "Epoch 155/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 14797.2334 - mean_absolute_error: 14797.233 - ETA: 0s - loss: 13401.7061 - mean_absolute_error: 13401.7061\n",
      "Epoch 00155: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13469.6260 - mean_absolute_error: 13469.6260 - val_loss: 21417.2715 - val_mean_absolute_error: 21417.2715\n",
      "Epoch 156/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14279.1221 - mean_absolute_error: 14279.1221\n",
      "Epoch 00156: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14278.2725 - mean_absolute_error: 14278.2725 - val_loss: 19977.9023 - val_mean_absolute_error: 19977.9023\n",
      "Epoch 157/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13944.0967 - mean_absolute_error: 13944.0967\n",
      "Epoch 00157: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13401.3750 - mean_absolute_error: 13401.3750 - val_loss: 21336.2168 - val_mean_absolute_error: 21336.2168\n",
      "Epoch 158/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12863.5625 - mean_absolute_error: 12863.5625\n",
      "Epoch 00158: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12898.8887 - mean_absolute_error: 12898.8887 - val_loss: 20496.0879 - val_mean_absolute_error: 20496.0879\n",
      "Epoch 159/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11658.4316 - mean_absolute_error: 11658.4316\n",
      "Epoch 00159: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12201.9727 - mean_absolute_error: 12201.9727 - val_loss: 20912.1465 - val_mean_absolute_error: 20912.1465\n",
      "Epoch 160/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14085.1533 - mean_absolute_error: 14085.1533\n",
      "Epoch 00160: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13969.2256 - mean_absolute_error: 13969.2256 - val_loss: 20868.9707 - val_mean_absolute_error: 20868.9707\n",
      "Epoch 161/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13061.8174 - mean_absolute_error: 13061.8174\n",
      "Epoch 00161: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13494.7012 - mean_absolute_error: 13494.7012 - val_loss: 20382.3633 - val_mean_absolute_error: 20382.3633\n",
      "Epoch 162/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12019.2676 - mean_absolute_error: 12019.2676\n",
      "Epoch 00162: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12429.3271 - mean_absolute_error: 12429.3271 - val_loss: 21473.6172 - val_mean_absolute_error: 21473.6172\n",
      "Epoch 163/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12270.7500 - mean_absolute_error: 12270.7500\n",
      "Epoch 00163: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12803.5869 - mean_absolute_error: 12803.5869 - val_loss: 20993.5059 - val_mean_absolute_error: 20993.5059\n",
      "Epoch 164/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12257.1221 - mean_absolute_error: 12257.1221\n",
      "Epoch 00164: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12398.2266 - mean_absolute_error: 12398.2266 - val_loss: 20051.4785 - val_mean_absolute_error: 20051.4785\n",
      "Epoch 165/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13564.9150 - mean_absolute_error: 13564.9150\n",
      "Epoch 00165: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12822.3232 - mean_absolute_error: 12822.3232 - val_loss: 19972.1875 - val_mean_absolute_error: 19972.1875\n",
      "Epoch 166/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13374.8838 - mean_absolute_error: 13374.8838\n",
      "Epoch 00166: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12742.4355 - mean_absolute_error: 12742.4355 - val_loss: 20415.3398 - val_mean_absolute_error: 20415.3398\n",
      "Epoch 167/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11965.9072 - mean_absolute_error: 11965.9072\n",
      "Epoch 00167: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12065.6318 - mean_absolute_error: 12065.6318 - val_loss: 20001.6289 - val_mean_absolute_error: 20001.6289\n",
      "Epoch 168/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12224.9971 - mean_absolute_error: 12224.9971\n",
      "Epoch 00168: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12289.1250 - mean_absolute_error: 12289.1250 - val_loss: 23164.4922 - val_mean_absolute_error: 23164.4922\n",
      "Epoch 169/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12719.3555 - mean_absolute_error: 12719.3555\n",
      "Epoch 00169: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12632.5918 - mean_absolute_error: 12632.5918 - val_loss: 20516.9375 - val_mean_absolute_error: 20516.9375\n",
      "Epoch 170/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/37 [===================>..........] - ETA: 0s - loss: 13380.8213 - mean_absolute_error: 13380.8213\n",
      "Epoch 00170: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13112.3281 - mean_absolute_error: 13112.3281 - val_loss: 20692.7324 - val_mean_absolute_error: 20692.7324\n",
      "Epoch 171/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12574.6484 - mean_absolute_error: 12574.6484\n",
      "Epoch 00171: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13529.2539 - mean_absolute_error: 13529.2539 - val_loss: 21997.5879 - val_mean_absolute_error: 21997.5879\n",
      "Epoch 172/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12615.5938 - mean_absolute_error: 12615.5938\n",
      "Epoch 00172: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12897.2461 - mean_absolute_error: 12897.2461 - val_loss: 25884.1699 - val_mean_absolute_error: 25884.1699\n",
      "Epoch 173/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 16342.2969 - mean_absolute_error: 16342.2969\n",
      "Epoch 00173: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15975.6641 - mean_absolute_error: 15975.6641 - val_loss: 20163.6738 - val_mean_absolute_error: 20163.6738\n",
      "Epoch 174/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11851.9785 - mean_absolute_error: 11851.9785\n",
      "Epoch 00174: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12543.3076 - mean_absolute_error: 12543.3076 - val_loss: 20615.3652 - val_mean_absolute_error: 20615.3652\n",
      "Epoch 175/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13285.3311 - mean_absolute_error: 13285.3311\n",
      "Epoch 00175: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13202.8926 - mean_absolute_error: 13202.8926 - val_loss: 20093.0078 - val_mean_absolute_error: 20093.0078\n",
      "Epoch 176/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12350.2939 - mean_absolute_error: 12350.2939\n",
      "Epoch 00176: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12741.5010 - mean_absolute_error: 12741.5010 - val_loss: 21947.5781 - val_mean_absolute_error: 21947.5781\n",
      "Epoch 177/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 14752.3916 - mean_absolute_error: 14752.3916\n",
      "Epoch 00177: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13808.2090 - mean_absolute_error: 13808.2090 - val_loss: 20433.4746 - val_mean_absolute_error: 20433.4746\n",
      "Epoch 178/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 15069.1709 - mean_absolute_error: 15069.1709\n",
      "Epoch 00178: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14213.7432 - mean_absolute_error: 14213.7432 - val_loss: 21202.5430 - val_mean_absolute_error: 21202.5430\n",
      "Epoch 179/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 14030.0059 - mean_absolute_error: 14030.0059\n",
      "Epoch 00179: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13015.9004 - mean_absolute_error: 13015.9004 - val_loss: 20785.7578 - val_mean_absolute_error: 20785.7578\n",
      "Epoch 180/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12196.5889 - mean_absolute_error: 12196.5889\n",
      "Epoch 00180: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13671.4766 - mean_absolute_error: 13671.4766 - val_loss: 21155.0625 - val_mean_absolute_error: 21155.0625\n",
      "Epoch 181/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 14729.6777 - mean_absolute_error: 14729.6777\n",
      "Epoch 00181: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14824.4951 - mean_absolute_error: 14824.4951 - val_loss: 20624.6152 - val_mean_absolute_error: 20624.6152\n",
      "Epoch 182/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13015.9971 - mean_absolute_error: 13015.9971\n",
      "Epoch 00182: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13595.7773 - mean_absolute_error: 13595.7773 - val_loss: 22925.9805 - val_mean_absolute_error: 22925.9805\n",
      "Epoch 183/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13992.7734 - mean_absolute_error: 13992.7734\n",
      "Epoch 00183: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13476.7197 - mean_absolute_error: 13476.7197 - val_loss: 20797.3184 - val_mean_absolute_error: 20797.3184\n",
      "Epoch 184/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13392.3408 - mean_absolute_error: 13392.3408\n",
      "Epoch 00184: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13719.1436 - mean_absolute_error: 13719.1436 - val_loss: 22860.7930 - val_mean_absolute_error: 22860.7930\n",
      "Epoch 185/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13054.5254 - mean_absolute_error: 13054.5254\n",
      "Epoch 00185: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12847.5010 - mean_absolute_error: 12847.5010 - val_loss: 20805.1328 - val_mean_absolute_error: 20805.1328\n",
      "Epoch 186/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11807.9688 - mean_absolute_error: 11807.9688\n",
      "Epoch 00186: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12352.3965 - mean_absolute_error: 12352.3965 - val_loss: 21888.5371 - val_mean_absolute_error: 21888.5371\n",
      "Epoch 187/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12826.9287 - mean_absolute_error: 12826.9287\n",
      "Epoch 00187: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12766.0879 - mean_absolute_error: 12766.0879 - val_loss: 20376.3926 - val_mean_absolute_error: 20376.3926\n",
      "Epoch 188/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12207.0127 - mean_absolute_error: 12207.0127\n",
      "Epoch 00188: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12206.7686 - mean_absolute_error: 12206.7686 - val_loss: 21777.0137 - val_mean_absolute_error: 21777.0137\n",
      "Epoch 189/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13076.4893 - mean_absolute_error: 13076.4893\n",
      "Epoch 00189: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13183.4336 - mean_absolute_error: 13183.4336 - val_loss: 21113.9746 - val_mean_absolute_error: 21113.9746\n",
      "Epoch 190/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13352.6680 - mean_absolute_error: 13352.6680\n",
      "Epoch 00190: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12976.2129 - mean_absolute_error: 12976.2129 - val_loss: 20527.7812 - val_mean_absolute_error: 20527.7812\n",
      "Epoch 191/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11967.2363 - mean_absolute_error: 11967.2363\n",
      "Epoch 00191: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12619.5967 - mean_absolute_error: 12619.5967 - val_loss: 20979.4941 - val_mean_absolute_error: 20979.4941\n",
      "Epoch 192/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12431.6553 - mean_absolute_error: 12431.6553\n",
      "Epoch 00192: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13975.7178 - mean_absolute_error: 13975.7178 - val_loss: 25260.2715 - val_mean_absolute_error: 25260.2715\n",
      "Epoch 193/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 15355.0742 - mean_absolute_error: 15355.0742\n",
      "Epoch 00193: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14320.4414 - mean_absolute_error: 14320.4414 - val_loss: 20021.4375 - val_mean_absolute_error: 20021.4375\n",
      "Epoch 194/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13321.4766 - mean_absolute_error: 13321.4766\n",
      "Epoch 00194: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12559.9922 - mean_absolute_error: 12559.9922 - val_loss: 20499.7090 - val_mean_absolute_error: 20499.7090\n",
      "Epoch 195/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12603.1797 - mean_absolute_error: 12603.1797\n",
      "Epoch 00195: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13144.9863 - mean_absolute_error: 13144.9863 - val_loss: 23487.5840 - val_mean_absolute_error: 23487.5840\n",
      "Epoch 196/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13063.0840 - mean_absolute_error: 13063.0840\n",
      "Epoch 00196: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13731.7842 - mean_absolute_error: 13731.7842 - val_loss: 20477.8223 - val_mean_absolute_error: 20477.8223\n",
      "Epoch 197/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14199.5381 - mean_absolute_error: 14199.5381\n",
      "Epoch 00197: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13337.6602 - mean_absolute_error: 13337.6602 - val_loss: 19703.0742 - val_mean_absolute_error: 19703.0742\n",
      "Epoch 198/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11760.6484 - mean_absolute_error: 11760.6484\n",
      "Epoch 00198: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11914.4297 - mean_absolute_error: 11914.4297 - val_loss: 20409.8184 - val_mean_absolute_error: 20409.8184\n",
      "Epoch 199/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 12150.6924 - mean_absolute_error: 12150.6924\n",
      "Epoch 00199: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12627.1182 - mean_absolute_error: 12627.1182 - val_loss: 24446.4531 - val_mean_absolute_error: 24446.4531\n",
      "Epoch 200/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14070.0127 - mean_absolute_error: 14070.0127\n",
      "Epoch 00200: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13630.8232 - mean_absolute_error: 13630.8232 - val_loss: 20330.5234 - val_mean_absolute_error: 20330.5234\n",
      "Epoch 201/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12517.1162 - mean_absolute_error: 12517.1162\n",
      "Epoch 00201: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12642.8320 - mean_absolute_error: 12642.8320 - val_loss: 20196.5332 - val_mean_absolute_error: 20196.5332\n",
      "Epoch 202/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13778.0459 - mean_absolute_error: 13778.0459\n",
      "Epoch 00202: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13221.2129 - mean_absolute_error: 13221.2129 - val_loss: 19907.3340 - val_mean_absolute_error: 19907.3340\n",
      "Epoch 203/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12300.4961 - mean_absolute_error: 12300.4961\n",
      "Epoch 00203: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11897.7842 - mean_absolute_error: 11897.7842 - val_loss: 19957.8125 - val_mean_absolute_error: 19957.8125\n",
      "Epoch 204/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12245.5898 - mean_absolute_error: 12245.5898\n",
      "Epoch 00204: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12164.1748 - mean_absolute_error: 12164.1748 - val_loss: 21313.1855 - val_mean_absolute_error: 21313.1855\n",
      "Epoch 205/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13566.0264 - mean_absolute_error: 13566.0264\n",
      "Epoch 00205: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13036.3740 - mean_absolute_error: 13036.3740 - val_loss: 19961.0254 - val_mean_absolute_error: 19961.0254\n",
      "Epoch 206/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 15063.6943 - mean_absolute_error: 15063.6943\n",
      "Epoch 00206: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15228.3027 - mean_absolute_error: 15228.3027 - val_loss: 20401.8613 - val_mean_absolute_error: 20401.8613\n",
      "Epoch 207/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13947.2471 - mean_absolute_error: 13947.2471\n",
      "Epoch 00207: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14678.3789 - mean_absolute_error: 14678.3789 - val_loss: 22321.0605 - val_mean_absolute_error: 22321.0605\n",
      "Epoch 208/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 16656.3281 - mean_absolute_error: 16656.3281\n",
      "Epoch 00208: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 16402.8789 - mean_absolute_error: 16402.8789 - val_loss: 26564.4297 - val_mean_absolute_error: 26564.4297\n",
      "Epoch 209/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12687.8008 - mean_absolute_error: 12687.8008\n",
      "Epoch 00209: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12795.8711 - mean_absolute_error: 12795.8711 - val_loss: 21760.2715 - val_mean_absolute_error: 21760.2715\n",
      "Epoch 210/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11956.1631 - mean_absolute_error: 11956.1631\n",
      "Epoch 00210: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11864.2119 - mean_absolute_error: 11864.2119 - val_loss: 23660.8633 - val_mean_absolute_error: 23660.8633\n",
      "Epoch 211/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12837.3320 - mean_absolute_error: 12837.3320\n",
      "Epoch 00211: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13482.7725 - mean_absolute_error: 13482.7725 - val_loss: 23649.9688 - val_mean_absolute_error: 23649.9688\n",
      "Epoch 212/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12848.0547 - mean_absolute_error: 12848.0547\n",
      "Epoch 00212: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12813.9463 - mean_absolute_error: 12813.9463 - val_loss: 20612.1387 - val_mean_absolute_error: 20612.1387\n",
      "Epoch 213/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13742.5264 - mean_absolute_error: 13742.5264\n",
      "Epoch 00213: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13321.4746 - mean_absolute_error: 13321.4746 - val_loss: 20347.8633 - val_mean_absolute_error: 20347.8633\n",
      "Epoch 214/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12045.1562 - mean_absolute_error: 12045.1562\n",
      "Epoch 00214: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12084.7109 - mean_absolute_error: 12084.7109 - val_loss: 19954.0645 - val_mean_absolute_error: 19954.0645\n",
      "Epoch 215/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12321.4844 - mean_absolute_error: 12321.4844\n",
      "Epoch 00215: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12623.1025 - mean_absolute_error: 12623.1025 - val_loss: 20847.4668 - val_mean_absolute_error: 20847.4668\n",
      "Epoch 216/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12298.8818 - mean_absolute_error: 12298.8818\n",
      "Epoch 00216: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12451.0508 - mean_absolute_error: 12451.0508 - val_loss: 21277.2188 - val_mean_absolute_error: 21277.2188\n",
      "Epoch 217/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11887.3330 - mean_absolute_error: 11887.3330\n",
      "Epoch 00217: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12207.9072 - mean_absolute_error: 12207.9072 - val_loss: 21794.3125 - val_mean_absolute_error: 21794.3125\n",
      "Epoch 218/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25/37 [===================>..........] - ETA: 0s - loss: 14003.4873 - mean_absolute_error: 14003.4873\n",
      "Epoch 00218: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13790.4600 - mean_absolute_error: 13790.4600 - val_loss: 19982.7363 - val_mean_absolute_error: 19982.7363\n",
      "Epoch 219/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11865.1221 - mean_absolute_error: 11865.1221\n",
      "Epoch 00219: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12686.8672 - mean_absolute_error: 12686.8672 - val_loss: 19666.3359 - val_mean_absolute_error: 19666.3359\n",
      "Epoch 220/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12693.6406 - mean_absolute_error: 12693.6406\n",
      "Epoch 00220: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12577.4844 - mean_absolute_error: 12577.4844 - val_loss: 19522.1113 - val_mean_absolute_error: 19522.1113\n",
      "Epoch 221/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13202.3467 - mean_absolute_error: 13202.3467\n",
      "Epoch 00221: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12997.3633 - mean_absolute_error: 12997.3633 - val_loss: 20966.0762 - val_mean_absolute_error: 20966.0762\n",
      "Epoch 222/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 14717.7998 - mean_absolute_error: 14717.7998\n",
      "Epoch 00222: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14233.6016 - mean_absolute_error: 14233.6016 - val_loss: 21083.0039 - val_mean_absolute_error: 21083.0039\n",
      "Epoch 223/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 13819.1973 - mean_absolute_error: 13819.1973\n",
      "Epoch 00223: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13681.7031 - mean_absolute_error: 13681.7031 - val_loss: 19970.0918 - val_mean_absolute_error: 19970.0918\n",
      "Epoch 224/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13929.1162 - mean_absolute_error: 13929.1162\n",
      "Epoch 00224: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13929.5840 - mean_absolute_error: 13929.5840 - val_loss: 20395.7891 - val_mean_absolute_error: 20395.7891\n",
      "Epoch 225/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 14358.4883 - mean_absolute_error: 14358.4883\n",
      "Epoch 00225: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14074.1230 - mean_absolute_error: 14074.1230 - val_loss: 20119.2656 - val_mean_absolute_error: 20119.2656\n",
      "Epoch 226/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12526.2607 - mean_absolute_error: 12526.2607\n",
      "Epoch 00226: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12924.1748 - mean_absolute_error: 12924.1748 - val_loss: 20346.2930 - val_mean_absolute_error: 20346.2930\n",
      "Epoch 227/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 15130.4902 - mean_absolute_error: 15130.4902\n",
      "Epoch 00227: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15995.6709 - mean_absolute_error: 15995.6709 - val_loss: 25464.6211 - val_mean_absolute_error: 25464.6211\n",
      "Epoch 228/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13222.1846 - mean_absolute_error: 13222.1846\n",
      "Epoch 00228: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12735.1699 - mean_absolute_error: 12735.1699 - val_loss: 21250.0859 - val_mean_absolute_error: 21250.0859\n",
      "Epoch 229/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12020.9688 - mean_absolute_error: 12020.9688\n",
      "Epoch 00229: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11953.6455 - mean_absolute_error: 11953.6455 - val_loss: 20001.3418 - val_mean_absolute_error: 20001.3418\n",
      "Epoch 230/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11739.2764 - mean_absolute_error: 11739.2764\n",
      "Epoch 00230: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12492.7441 - mean_absolute_error: 12492.7441 - val_loss: 20420.5410 - val_mean_absolute_error: 20420.5410\n",
      "Epoch 231/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11551.5107 - mean_absolute_error: 11551.5107\n",
      "Epoch 00231: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11910.3857 - mean_absolute_error: 11910.3857 - val_loss: 21560.1934 - val_mean_absolute_error: 21560.1934\n",
      "Epoch 232/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11375.9785 - mean_absolute_error: 11375.9785\n",
      "Epoch 00232: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11654.7422 - mean_absolute_error: 11654.7422 - val_loss: 20488.4395 - val_mean_absolute_error: 20488.4395\n",
      "Epoch 233/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13413.3525 - mean_absolute_error: 13413.3525\n",
      "Epoch 00233: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13117.3906 - mean_absolute_error: 13117.3906 - val_loss: 23675.6504 - val_mean_absolute_error: 23675.6504\n",
      "Epoch 234/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12461.0225 - mean_absolute_error: 12461.0225\n",
      "Epoch 00234: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12077.5664 - mean_absolute_error: 12077.5664 - val_loss: 19687.7988 - val_mean_absolute_error: 19687.7988\n",
      "Epoch 235/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11899.4141 - mean_absolute_error: 11899.4141\n",
      "Epoch 00235: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11731.4766 - mean_absolute_error: 11731.4766 - val_loss: 20923.9707 - val_mean_absolute_error: 20923.9707\n",
      "Epoch 236/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 15104.4473 - mean_absolute_error: 15104.4473\n",
      "Epoch 00236: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15075.1455 - mean_absolute_error: 15075.1455 - val_loss: 19550.4629 - val_mean_absolute_error: 19550.4629\n",
      "Epoch 237/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12597.0811 - mean_absolute_error: 12597.0811\n",
      "Epoch 00237: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12542.4092 - mean_absolute_error: 12542.4092 - val_loss: 20184.2969 - val_mean_absolute_error: 20184.2969\n",
      "Epoch 238/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12158.3438 - mean_absolute_error: 12158.3438\n",
      "Epoch 00238: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12242.3076 - mean_absolute_error: 12242.3076 - val_loss: 20280.0293 - val_mean_absolute_error: 20280.0293\n",
      "Epoch 239/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11846.7871 - mean_absolute_error: 11846.7871\n",
      "Epoch 00239: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12015.8613 - mean_absolute_error: 12015.8613 - val_loss: 20038.6055 - val_mean_absolute_error: 20038.6055\n",
      "Epoch 240/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12075.7783 - mean_absolute_error: 12075.7783\n",
      "Epoch 00240: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12096.6172 - mean_absolute_error: 12096.6172 - val_loss: 21422.1562 - val_mean_absolute_error: 21422.1562\n",
      "Epoch 241/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11696.2393 - mean_absolute_error: 11696.2393\n",
      "Epoch 00241: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12583.8340 - mean_absolute_error: 12583.8340 - val_loss: 20563.6445 - val_mean_absolute_error: 20563.6445\n",
      "Epoch 242/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12644.1221 - mean_absolute_error: 12644.1221\n",
      "Epoch 00242: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12812.7480 - mean_absolute_error: 12812.7480 - val_loss: 21470.7617 - val_mean_absolute_error: 21470.7617\n",
      "Epoch 243/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11023.7158 - mean_absolute_error: 11023.7158\n",
      "Epoch 00243: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11763.4883 - mean_absolute_error: 11763.4883 - val_loss: 20481.3125 - val_mean_absolute_error: 20481.3125\n",
      "Epoch 244/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 12903.3369 - mean_absolute_error: 12903.3369\n",
      "Epoch 00244: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12903.3369 - mean_absolute_error: 12903.3369 - val_loss: 20430.7285 - val_mean_absolute_error: 20430.7285\n",
      "Epoch 245/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 11937.1387 - mean_absolute_error: 11937.1387\n",
      "Epoch 00245: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12630.4746 - mean_absolute_error: 12630.4746 - val_loss: 20119.9004 - val_mean_absolute_error: 20119.9004\n",
      "Epoch 246/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 11378.9111 - mean_absolute_error: 11378.9111\n",
      "Epoch 00246: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12119.1924 - mean_absolute_error: 12119.1924 - val_loss: 22896.1602 - val_mean_absolute_error: 22896.1602\n",
      "Epoch 247/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 11168.8945 - mean_absolute_error: 11168.8945\n",
      "Epoch 00247: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11790.9180 - mean_absolute_error: 11790.9180 - val_loss: 19801.3086 - val_mean_absolute_error: 19801.3086\n",
      "Epoch 248/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12022.9727 - mean_absolute_error: 12022.9727\n",
      "Epoch 00248: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12077.1670 - mean_absolute_error: 12077.1670 - val_loss: 20160.0938 - val_mean_absolute_error: 20160.0938\n",
      "Epoch 249/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12846.9434 - mean_absolute_error: 12846.9434\n",
      "Epoch 00249: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12901.8809 - mean_absolute_error: 12901.8809 - val_loss: 20076.0801 - val_mean_absolute_error: 20076.0801\n",
      "Epoch 250/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13363.6084 - mean_absolute_error: 13363.6084\n",
      "Epoch 00250: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13559.3037 - mean_absolute_error: 13559.3037 - val_loss: 20954.8027 - val_mean_absolute_error: 20954.8027\n",
      "Epoch 251/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13296.8750 - mean_absolute_error: 13296.8750\n",
      "Epoch 00251: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12966.2793 - mean_absolute_error: 12966.2793 - val_loss: 20418.5078 - val_mean_absolute_error: 20418.5078\n",
      "Epoch 252/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12009.6533 - mean_absolute_error: 12009.6533\n",
      "Epoch 00252: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11964.9307 - mean_absolute_error: 11964.9307 - val_loss: 19780.7910 - val_mean_absolute_error: 19780.7910\n",
      "Epoch 253/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12573.4141 - mean_absolute_error: 12573.4141\n",
      "Epoch 00253: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12462.1855 - mean_absolute_error: 12462.1855 - val_loss: 20526.0059 - val_mean_absolute_error: 20526.0059\n",
      "Epoch 254/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12774.1348 - mean_absolute_error: 12774.1348\n",
      "Epoch 00254: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12185.1357 - mean_absolute_error: 12185.1357 - val_loss: 20461.7402 - val_mean_absolute_error: 20461.7402\n",
      "Epoch 255/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12320.7627 - mean_absolute_error: 12320.7627\n",
      "Epoch 00255: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12280.0488 - mean_absolute_error: 12280.0488 - val_loss: 20751.9766 - val_mean_absolute_error: 20751.9766\n",
      "Epoch 256/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12081.9688 - mean_absolute_error: 12081.9688\n",
      "Epoch 00256: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11941.4619 - mean_absolute_error: 11941.4619 - val_loss: 26425.4141 - val_mean_absolute_error: 26425.4141\n",
      "Epoch 257/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13233.8633 - mean_absolute_error: 13233.8633\n",
      "Epoch 00257: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13148.9473 - mean_absolute_error: 13148.9473 - val_loss: 20268.8848 - val_mean_absolute_error: 20268.8848\n",
      "Epoch 258/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12681.4717 - mean_absolute_error: 12681.4717\n",
      "Epoch 00258: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12980.4062 - mean_absolute_error: 12980.4062 - val_loss: 21350.7988 - val_mean_absolute_error: 21350.7988\n",
      "Epoch 259/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11699.5352 - mean_absolute_error: 11699.5352\n",
      "Epoch 00259: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12051.5957 - mean_absolute_error: 12051.5957 - val_loss: 19720.7988 - val_mean_absolute_error: 19720.7988\n",
      "Epoch 260/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12847.4404 - mean_absolute_error: 12847.4404\n",
      "Epoch 00260: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12891.0449 - mean_absolute_error: 12891.0449 - val_loss: 20481.8496 - val_mean_absolute_error: 20481.8496\n",
      "Epoch 261/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13339.1719 - mean_absolute_error: 13339.1719\n",
      "Epoch 00261: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12930.8086 - mean_absolute_error: 12930.8086 - val_loss: 20365.5215 - val_mean_absolute_error: 20365.5215\n",
      "Epoch 262/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11159.7041 - mean_absolute_error: 11159.7041\n",
      "Epoch 00262: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11721.3662 - mean_absolute_error: 11721.3662 - val_loss: 20502.8926 - val_mean_absolute_error: 20502.8926\n",
      "Epoch 263/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12509.3477 - mean_absolute_error: 12509.3477\n",
      "Epoch 00263: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12249.7305 - mean_absolute_error: 12249.7305 - val_loss: 19754.7422 - val_mean_absolute_error: 19754.7422\n",
      "Epoch 264/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12366.5225 - mean_absolute_error: 12366.5225\n",
      "Epoch 00264: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11762.3379 - mean_absolute_error: 11762.3379 - val_loss: 20363.2285 - val_mean_absolute_error: 20363.2285\n",
      "Epoch 265/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13783.0430 - mean_absolute_error: 13783.0430\n",
      "Epoch 00265: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13402.1074 - mean_absolute_error: 13402.1074 - val_loss: 20784.8789 - val_mean_absolute_error: 20784.8789\n",
      "Epoch 266/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/37 [=================>............] - ETA: 0s - loss: 12925.4346 - mean_absolute_error: 12925.4346\n",
      "Epoch 00266: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12704.3096 - mean_absolute_error: 12704.3096 - val_loss: 19657.3965 - val_mean_absolute_error: 19657.3965\n",
      "Epoch 267/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 12398.0605 - mean_absolute_error: 12398.0605\n",
      "Epoch 00267: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12533.7129 - mean_absolute_error: 12533.7129 - val_loss: 20716.4707 - val_mean_absolute_error: 20716.4707\n",
      "Epoch 268/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 14131.9258 - mean_absolute_error: 14131.9258\n",
      "Epoch 00268: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13532.0098 - mean_absolute_error: 13532.0098 - val_loss: 20746.0020 - val_mean_absolute_error: 20746.0020\n",
      "Epoch 269/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12035.0166 - mean_absolute_error: 12035.0166\n",
      "Epoch 00269: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12051.9336 - mean_absolute_error: 12051.9336 - val_loss: 20499.1777 - val_mean_absolute_error: 20499.1777\n",
      "Epoch 270/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11079.5498 - mean_absolute_error: 11079.5498\n",
      "Epoch 00270: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11551.8838 - mean_absolute_error: 11551.8838 - val_loss: 20207.7520 - val_mean_absolute_error: 20207.7520\n",
      "Epoch 271/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14018.6768 - mean_absolute_error: 14018.6768\n",
      "Epoch 00271: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14013.1328 - mean_absolute_error: 14013.1328 - val_loss: 24434.6328 - val_mean_absolute_error: 24434.6328\n",
      "Epoch 272/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13443.6514 - mean_absolute_error: 13443.6514\n",
      "Epoch 00272: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13260.7158 - mean_absolute_error: 13260.7158 - val_loss: 20114.8965 - val_mean_absolute_error: 20114.8965\n",
      "Epoch 273/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11754.2617 - mean_absolute_error: 11754.2617\n",
      "Epoch 00273: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12539.3643 - mean_absolute_error: 12539.3643 - val_loss: 20734.0449 - val_mean_absolute_error: 20734.0449\n",
      "Epoch 274/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12108.1572 - mean_absolute_error: 12108.1572\n",
      "Epoch 00274: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11903.6074 - mean_absolute_error: 11903.6074 - val_loss: 19638.9629 - val_mean_absolute_error: 19638.9629\n",
      "Epoch 275/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 11694.4082 - mean_absolute_error: 11694.4082\n",
      "Epoch 00275: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11934.9512 - mean_absolute_error: 11934.9512 - val_loss: 21030.4512 - val_mean_absolute_error: 21030.4512\n",
      "Epoch 276/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11490.0107 - mean_absolute_error: 11490.0107\n",
      "Epoch 00276: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11441.3545 - mean_absolute_error: 11441.3545 - val_loss: 20225.5195 - val_mean_absolute_error: 20225.5195\n",
      "Epoch 277/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12008.4482 - mean_absolute_error: 12008.4482\n",
      "Epoch 00277: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12390.0605 - mean_absolute_error: 12390.0605 - val_loss: 20454.6543 - val_mean_absolute_error: 20454.6543\n",
      "Epoch 278/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12299.7021 - mean_absolute_error: 12299.7021\n",
      "Epoch 00278: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12243.6797 - mean_absolute_error: 12243.6797 - val_loss: 21028.8867 - val_mean_absolute_error: 21028.8867\n",
      "Epoch 279/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 15694.4854 - mean_absolute_error: 15694.4854\n",
      "Epoch 00279: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15394.2246 - mean_absolute_error: 15394.2246 - val_loss: 24230.6133 - val_mean_absolute_error: 24230.6133\n",
      "Epoch 280/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 13600.8252 - mean_absolute_error: 13600.8252\n",
      "Epoch 00280: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13514.6357 - mean_absolute_error: 13514.6357 - val_loss: 20447.1094 - val_mean_absolute_error: 20447.1094\n",
      "Epoch 281/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11563.7246 - mean_absolute_error: 11563.7246\n",
      "Epoch 00281: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11548.2949 - mean_absolute_error: 11548.2949 - val_loss: 20343.3809 - val_mean_absolute_error: 20343.3809\n",
      "Epoch 282/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12644.8350 - mean_absolute_error: 12644.8350\n",
      "Epoch 00282: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12635.9297 - mean_absolute_error: 12635.9297 - val_loss: 20224.0547 - val_mean_absolute_error: 20224.0547\n",
      "Epoch 283/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12274.0049 - mean_absolute_error: 12274.0049\n",
      "Epoch 00283: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12537.5996 - mean_absolute_error: 12537.5996 - val_loss: 22678.0195 - val_mean_absolute_error: 22678.0195\n",
      "Epoch 284/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12950.1973 - mean_absolute_error: 12950.1973\n",
      "Epoch 00284: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13094.0371 - mean_absolute_error: 13094.0371 - val_loss: 19784.1738 - val_mean_absolute_error: 19784.1738\n",
      "Epoch 285/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12099.4150 - mean_absolute_error: 12099.4150\n",
      "Epoch 00285: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12660.5098 - mean_absolute_error: 12660.5098 - val_loss: 20936.7168 - val_mean_absolute_error: 20936.7168\n",
      "Epoch 286/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12002.4141 - mean_absolute_error: 12002.4141\n",
      "Epoch 00286: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11951.0352 - mean_absolute_error: 11951.0352 - val_loss: 20827.6133 - val_mean_absolute_error: 20827.6133\n",
      "Epoch 287/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11735.4170 - mean_absolute_error: 11735.4170\n",
      "Epoch 00287: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11739.7461 - mean_absolute_error: 11739.7461 - val_loss: 19648.7012 - val_mean_absolute_error: 19648.7012\n",
      "Epoch 288/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12095.2217 - mean_absolute_error: 12095.2217\n",
      "Epoch 00288: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13447.7754 - mean_absolute_error: 13447.7754 - val_loss: 20914.6836 - val_mean_absolute_error: 20914.6836\n",
      "Epoch 289/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12105.1465 - mean_absolute_error: 12105.1465\n",
      "Epoch 00289: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12734.5664 - mean_absolute_error: 12734.5664 - val_loss: 21101.7324 - val_mean_absolute_error: 21101.7324\n",
      "Epoch 290/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 11758.7139 - mean_absolute_error: 11758.7139\n",
      "Epoch 00290: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12335.4824 - mean_absolute_error: 12335.4824 - val_loss: 20321.2891 - val_mean_absolute_error: 20321.2891\n",
      "Epoch 291/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12991.0107 - mean_absolute_error: 12991.0107\n",
      "Epoch 00291: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13097.7812 - mean_absolute_error: 13097.7812 - val_loss: 26373.4004 - val_mean_absolute_error: 26373.4004\n",
      "Epoch 292/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 16063.1504 - mean_absolute_error: 16063.1504\n",
      "Epoch 00292: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14627.7412 - mean_absolute_error: 14627.7412 - val_loss: 20459.9980 - val_mean_absolute_error: 20459.9980\n",
      "Epoch 293/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12250.4736 - mean_absolute_error: 12250.4736\n",
      "Epoch 00293: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11975.5273 - mean_absolute_error: 11975.5273 - val_loss: 22560.4707 - val_mean_absolute_error: 22560.4707\n",
      "Epoch 294/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12168.7578 - mean_absolute_error: 12168.7578\n",
      "Epoch 00294: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12848.3662 - mean_absolute_error: 12848.3662 - val_loss: 23785.9121 - val_mean_absolute_error: 23785.9121\n",
      "Epoch 295/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11305.9844 - mean_absolute_error: 11305.9844\n",
      "Epoch 00295: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11850.0967 - mean_absolute_error: 11850.0967 - val_loss: 21365.4570 - val_mean_absolute_error: 21365.4570\n",
      "Epoch 296/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11858.6416 - mean_absolute_error: 11858.6416\n",
      "Epoch 00296: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12503.0840 - mean_absolute_error: 12503.0840 - val_loss: 22734.8965 - val_mean_absolute_error: 22734.8965\n",
      "Epoch 297/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 12132.5635 - mean_absolute_error: 12132.5635\n",
      "Epoch 00297: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13434.4980 - mean_absolute_error: 13434.4980 - val_loss: 20793.5410 - val_mean_absolute_error: 20793.5410\n",
      "Epoch 298/500\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 11905.7070 - mean_absolute_error: 11905.7070\n",
      "Epoch 00298: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 11907.1123 - mean_absolute_error: 11907.1123 - val_loss: 20940.0430 - val_mean_absolute_error: 20940.0430\n",
      "Epoch 299/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11737.3525 - mean_absolute_error: 11737.3525\n",
      "Epoch 00299: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11889.8252 - mean_absolute_error: 11889.8252 - val_loss: 19947.6172 - val_mean_absolute_error: 19947.6172\n",
      "Epoch 300/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 14582.2832 - mean_absolute_error: 14582.2832\n",
      "Epoch 00300: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14114.5146 - mean_absolute_error: 14114.5146 - val_loss: 20432.1875 - val_mean_absolute_error: 20432.1875\n",
      "Epoch 301/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 16057.4746 - mean_absolute_error: 16057.4746\n",
      "Epoch 00301: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 15913.8633 - mean_absolute_error: 15913.8633 - val_loss: 20641.1816 - val_mean_absolute_error: 20641.1816\n",
      "Epoch 302/500\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 15809.7471 - mean_absolute_error: 15809.7471\n",
      "Epoch 00302: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 15168.3574 - mean_absolute_error: 15168.3574 - val_loss: 21848.4062 - val_mean_absolute_error: 21848.4062\n",
      "Epoch 303/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 12156.3770 - mean_absolute_error: 12156.3770\n",
      "Epoch 00303: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11928.4551 - mean_absolute_error: 11928.4551 - val_loss: 20615.3867 - val_mean_absolute_error: 20615.3867\n",
      "Epoch 304/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11990.7520 - mean_absolute_error: 11990.7520\n",
      "Epoch 00304: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12079.3340 - mean_absolute_error: 12079.3340 - val_loss: 19752.9023 - val_mean_absolute_error: 19752.9023\n",
      "Epoch 305/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11359.5488 - mean_absolute_error: 11359.5488\n",
      "Epoch 00305: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11774.6074 - mean_absolute_error: 11774.6074 - val_loss: 21314.0352 - val_mean_absolute_error: 21314.0352\n",
      "Epoch 306/500\n",
      "18/37 [=============>................] - ETA: 0s - loss: 13300.8389 - mean_absolute_error: 13300.8389\n",
      "Epoch 00306: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12408.3281 - mean_absolute_error: 12408.3281 - val_loss: 20349.9609 - val_mean_absolute_error: 20349.9609\n",
      "Epoch 307/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 13032.5840 - mean_absolute_error: 13032.5840\n",
      "Epoch 00307: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12247.7783 - mean_absolute_error: 12247.7783 - val_loss: 20217.0762 - val_mean_absolute_error: 20217.0762\n",
      "Epoch 308/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13331.1328 - mean_absolute_error: 13331.1328\n",
      "Epoch 00308: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12756.8467 - mean_absolute_error: 12756.8467 - val_loss: 19894.6895 - val_mean_absolute_error: 19894.6895\n",
      "Epoch 309/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 10528.6523 - mean_absolute_error: 10528.6523\n",
      "Epoch 00309: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11196.0303 - mean_absolute_error: 11196.0303 - val_loss: 20247.5820 - val_mean_absolute_error: 20247.5820\n",
      "Epoch 310/500\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 11903.0566 - mean_absolute_error: 11903.0566\n",
      "Epoch 00310: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11750.0117 - mean_absolute_error: 11750.0117 - val_loss: 20127.8887 - val_mean_absolute_error: 20127.8887\n",
      "Epoch 311/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12784.6748 - mean_absolute_error: 12784.6748\n",
      "Epoch 00311: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12233.9141 - mean_absolute_error: 12233.9141 - val_loss: 25177.6152 - val_mean_absolute_error: 25177.6152\n",
      "Epoch 312/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13125.5508 - mean_absolute_error: 13125.5508\n",
      "Epoch 00312: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12573.3926 - mean_absolute_error: 12573.3926 - val_loss: 20928.5137 - val_mean_absolute_error: 20928.5137\n",
      "Epoch 313/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13398.6807 - mean_absolute_error: 13398.6807\n",
      "Epoch 00313: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13221.9805 - mean_absolute_error: 13221.9805 - val_loss: 20306.1387 - val_mean_absolute_error: 20306.1387\n",
      "Epoch 314/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/37 [=============>................] - ETA: 0s - loss: 12803.4648 - mean_absolute_error: 12803.4648\n",
      "Epoch 00314: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11969.3857 - mean_absolute_error: 11969.3857 - val_loss: 19810.5449 - val_mean_absolute_error: 19810.5449\n",
      "Epoch 315/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11588.5791 - mean_absolute_error: 11588.5791\n",
      "Epoch 00315: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12062.2881 - mean_absolute_error: 12062.2881 - val_loss: 23274.4648 - val_mean_absolute_error: 23274.4648\n",
      "Epoch 316/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11507.8535 - mean_absolute_error: 11507.8535\n",
      "Epoch 00316: val_loss did not improve from 19212.57617\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11931.5732 - mean_absolute_error: 11931.5732 - val_loss: 20053.4492 - val_mean_absolute_error: 20053.4492\n",
      "Epoch 317/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 11946.5244 - mean_absolute_error: 11946.5244\n",
      "Epoch 00317: val_loss improved from 19212.57617 to 19168.44141, saving model to Weights-317--19168.44141.hdf5\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11946.5244 - mean_absolute_error: 11946.5244 - val_loss: 19168.4414 - val_mean_absolute_error: 19168.4414\n",
      "Epoch 318/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12095.1416 - mean_absolute_error: 12095.1416\n",
      "Epoch 00318: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12683.0439 - mean_absolute_error: 12683.0439 - val_loss: 19860.9746 - val_mean_absolute_error: 19860.9746\n",
      "Epoch 319/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13120.0820 - mean_absolute_error: 13120.0820\n",
      "Epoch 00319: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13093.4434 - mean_absolute_error: 13093.4434 - val_loss: 21647.4121 - val_mean_absolute_error: 21647.4121\n",
      "Epoch 320/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11890.1289 - mean_absolute_error: 11890.1289\n",
      "Epoch 00320: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11741.4697 - mean_absolute_error: 11741.4697 - val_loss: 20642.4746 - val_mean_absolute_error: 20642.4746\n",
      "Epoch 321/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11363.1963 - mean_absolute_error: 11363.1963\n",
      "Epoch 00321: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11804.0137 - mean_absolute_error: 11804.0137 - val_loss: 20051.1875 - val_mean_absolute_error: 20051.1875\n",
      "Epoch 322/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 11623.9199 - mean_absolute_error: 11623.9199\n",
      "Epoch 00322: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 11623.9199 - mean_absolute_error: 11623.9199 - val_loss: 22739.3340 - val_mean_absolute_error: 22739.3340\n",
      "Epoch 323/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14396.9287 - mean_absolute_error: 14396.9287\n",
      "Epoch 00323: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13914.4824 - mean_absolute_error: 13914.4824 - val_loss: 20705.1309 - val_mean_absolute_error: 20705.1309\n",
      "Epoch 324/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11724.5029 - mean_absolute_error: 11724.5029\n",
      "Epoch 00324: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11522.5381 - mean_absolute_error: 11522.5381 - val_loss: 20444.3477 - val_mean_absolute_error: 20444.3477\n",
      "Epoch 325/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 12981.0781 - mean_absolute_error: 12981.0781\n",
      "Epoch 00325: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 13139.5186 - mean_absolute_error: 13139.5186 - val_loss: 26463.3789 - val_mean_absolute_error: 26463.3789\n",
      "Epoch 326/500\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 14931.6973 - mean_absolute_error: 14931.6973\n",
      "Epoch 00326: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 14873.3203 - mean_absolute_error: 14873.3203 - val_loss: 20681.8672 - val_mean_absolute_error: 20681.8672\n",
      "Epoch 327/500\n",
      "36/37 [============================>.] - ETA: 0s - loss: 12654.8945 - mean_absolute_error: 12654.8945\n",
      "Epoch 00327: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12571.3457 - mean_absolute_error: 12571.3457 - val_loss: 20248.3848 - val_mean_absolute_error: 20248.3848\n",
      "Epoch 328/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11545.9863 - mean_absolute_error: 11545.9863\n",
      "Epoch 00328: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 11855.8906 - mean_absolute_error: 11855.8906 - val_loss: 21097.9102 - val_mean_absolute_error: 21097.9102\n",
      "Epoch 329/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 11093.1592 - mean_absolute_error: 11093.1592\n",
      "Epoch 00329: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11175.9023 - mean_absolute_error: 11175.9023 - val_loss: 20678.5000 - val_mean_absolute_error: 20678.5000\n",
      "Epoch 330/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11944.6182 - mean_absolute_error: 11944.6182\n",
      "Epoch 00330: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11871.4717 - mean_absolute_error: 11871.4717 - val_loss: 20582.4609 - val_mean_absolute_error: 20582.4609\n",
      "Epoch 331/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11670.0479 - mean_absolute_error: 11670.0479\n",
      "Epoch 00331: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11809.6641 - mean_absolute_error: 11809.6641 - val_loss: 21656.6641 - val_mean_absolute_error: 21656.6641\n",
      "Epoch 332/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11240.1533 - mean_absolute_error: 11240.1533\n",
      "Epoch 00332: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11869.5303 - mean_absolute_error: 11869.5303 - val_loss: 20951.7402 - val_mean_absolute_error: 20951.7402\n",
      "Epoch 333/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12220.3330 - mean_absolute_error: 12220.3330\n",
      "Epoch 00333: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11427.1260 - mean_absolute_error: 11427.1260 - val_loss: 20535.0156 - val_mean_absolute_error: 20535.0156\n",
      "Epoch 334/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 10649.0605 - mean_absolute_error: 10649.0605\n",
      "Epoch 00334: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11267.1914 - mean_absolute_error: 11267.1914 - val_loss: 21529.5312 - val_mean_absolute_error: 21529.5312\n",
      "Epoch 335/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 11696.8652 - mean_absolute_error: 11696.8652\n",
      "Epoch 00335: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11415.7549 - mean_absolute_error: 11415.7549 - val_loss: 23081.5938 - val_mean_absolute_error: 23081.5938\n",
      "Epoch 336/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13068.0146 - mean_absolute_error: 13068.0146\n",
      "Epoch 00336: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13449.4492 - mean_absolute_error: 13449.4492 - val_loss: 21104.3828 - val_mean_absolute_error: 21104.3828\n",
      "Epoch 337/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13053.6689 - mean_absolute_error: 13053.6689\n",
      "Epoch 00337: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12459.0244 - mean_absolute_error: 12459.0244 - val_loss: 19954.5117 - val_mean_absolute_error: 19954.5117\n",
      "Epoch 338/500\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11831.3320 - mean_absolute_error: 11831.3320\n",
      "Epoch 00338: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12036.2070 - mean_absolute_error: 12036.2070 - val_loss: 21826.9766 - val_mean_absolute_error: 21826.9766\n",
      "Epoch 339/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12597.3867 - mean_absolute_error: 12597.3867\n",
      "Epoch 00339: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12664.8555 - mean_absolute_error: 12664.8555 - val_loss: 24691.4258 - val_mean_absolute_error: 24691.4258\n",
      "Epoch 340/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11601.6494 - mean_absolute_error: 11601.6494\n",
      "Epoch 00340: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11573.6074 - mean_absolute_error: 11573.6074 - val_loss: 22010.2812 - val_mean_absolute_error: 22010.2812\n",
      "Epoch 341/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 13107.7422 - mean_absolute_error: 13107.7422\n",
      "Epoch 00341: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12781.3779 - mean_absolute_error: 12781.3779 - val_loss: 20358.5215 - val_mean_absolute_error: 20358.5215\n",
      "Epoch 342/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11978.3887 - mean_absolute_error: 11978.3887\n",
      "Epoch 00342: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12026.3223 - mean_absolute_error: 12026.3223 - val_loss: 19512.3379 - val_mean_absolute_error: 19512.3379\n",
      "Epoch 343/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 12306.9463 - mean_absolute_error: 12306.9463\n",
      "Epoch 00343: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11768.8701 - mean_absolute_error: 11768.8701 - val_loss: 19621.8848 - val_mean_absolute_error: 19621.8848\n",
      "Epoch 344/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13488.2041 - mean_absolute_error: 13488.2041\n",
      "Epoch 00344: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13756.5127 - mean_absolute_error: 13756.5127 - val_loss: 20254.9180 - val_mean_absolute_error: 20254.9180\n",
      "Epoch 345/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12797.6465 - mean_absolute_error: 12797.6465\n",
      "Epoch 00345: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12626.7393 - mean_absolute_error: 12626.7393 - val_loss: 21606.3809 - val_mean_absolute_error: 21606.3809\n",
      "Epoch 346/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11822.2373 - mean_absolute_error: 11822.2373\n",
      "Epoch 00346: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11513.3564 - mean_absolute_error: 11513.3564 - val_loss: 20106.9375 - val_mean_absolute_error: 20106.9375\n",
      "Epoch 347/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 10610.5498 - mean_absolute_error: 10610.5498\n",
      "Epoch 00347: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11298.8018 - mean_absolute_error: 11298.8018 - val_loss: 20238.8945 - val_mean_absolute_error: 20238.8945\n",
      "Epoch 348/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11326.7900 - mean_absolute_error: 11326.7900\n",
      "Epoch 00348: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11443.3438 - mean_absolute_error: 11443.3438 - val_loss: 22763.1777 - val_mean_absolute_error: 22763.1777\n",
      "Epoch 349/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12370.0557 - mean_absolute_error: 12370.0557\n",
      "Epoch 00349: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12555.6445 - mean_absolute_error: 12555.6445 - val_loss: 20113.5273 - val_mean_absolute_error: 20113.5273\n",
      "Epoch 350/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12267.7441 - mean_absolute_error: 12267.7441\n",
      "Epoch 00350: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11762.6709 - mean_absolute_error: 11762.6709 - val_loss: 19811.3672 - val_mean_absolute_error: 19811.3672\n",
      "Epoch 351/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11683.6416 - mean_absolute_error: 11683.6416\n",
      "Epoch 00351: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11385.9004 - mean_absolute_error: 11385.9004 - val_loss: 20627.4395 - val_mean_absolute_error: 20627.4395\n",
      "Epoch 352/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12357.0469 - mean_absolute_error: 12357.0469\n",
      "Epoch 00352: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11819.6709 - mean_absolute_error: 11819.6709 - val_loss: 19620.9180 - val_mean_absolute_error: 19620.9180\n",
      "Epoch 353/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 11801.7930 - mean_absolute_error: 11801.7930\n",
      "Epoch 00353: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11733.3057 - mean_absolute_error: 11733.3057 - val_loss: 19856.4473 - val_mean_absolute_error: 19856.4473\n",
      "Epoch 354/500\n",
      "30/37 [=======================>......] - ETA: 0s - loss: 13498.3936 - mean_absolute_error: 13498.3936\n",
      "Epoch 00354: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 13100.7891 - mean_absolute_error: 13100.7891 - val_loss: 20211.3262 - val_mean_absolute_error: 20211.3262\n",
      "Epoch 355/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11983.7773 - mean_absolute_error: 11983.7773\n",
      "Epoch 00355: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12058.6211 - mean_absolute_error: 12058.6211 - val_loss: 23370.8262 - val_mean_absolute_error: 23370.8262\n",
      "Epoch 356/500\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 12079.0234 - mean_absolute_error: 12079.0234\n",
      "Epoch 00356: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12247.8574 - mean_absolute_error: 12247.8574 - val_loss: 20224.2988 - val_mean_absolute_error: 20224.2988\n",
      "Epoch 357/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11194.2041 - mean_absolute_error: 11194.2041\n",
      "Epoch 00357: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11371.7139 - mean_absolute_error: 11371.7139 - val_loss: 20231.7070 - val_mean_absolute_error: 20231.7070\n",
      "Epoch 358/500\n",
      "31/37 [========================>.....] - ETA: 0s - loss: 10705.9824 - mean_absolute_error: 10705.9824\n",
      "Epoch 00358: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 10868.7734 - mean_absolute_error: 10868.7734 - val_loss: 20150.3750 - val_mean_absolute_error: 20150.3750\n",
      "Epoch 359/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12930.0635 - mean_absolute_error: 12930.0635\n",
      "Epoch 00359: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12955.3203 - mean_absolute_error: 12955.3203 - val_loss: 22785.0176 - val_mean_absolute_error: 22785.0176\n",
      "Epoch 360/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 12471.3613 - mean_absolute_error: 12471.3613\n",
      "Epoch 00360: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12811.3926 - mean_absolute_error: 12811.3926 - val_loss: 22609.8691 - val_mean_absolute_error: 22609.8691\n",
      "Epoch 361/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 12721.3623 - mean_absolute_error: 12721.3623\n",
      "Epoch 00361: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11794.2812 - mean_absolute_error: 11794.2812 - val_loss: 20732.3457 - val_mean_absolute_error: 20732.3457\n",
      "Epoch 362/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/37 [==========================>...] - ETA: 0s - loss: 11867.7441 - mean_absolute_error: 11867.7441\n",
      "Epoch 00362: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12104.6406 - mean_absolute_error: 12104.6406 - val_loss: 20366.7715 - val_mean_absolute_error: 20366.7715\n",
      "Epoch 363/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 11870.5303 - mean_absolute_error: 11870.5303\n",
      "Epoch 00363: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11863.6543 - mean_absolute_error: 11863.6543 - val_loss: 19578.8145 - val_mean_absolute_error: 19578.8145\n",
      "Epoch 364/500\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 11647.7236 - mean_absolute_error: 11647.7236\n",
      "Epoch 00364: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 11713.0547 - mean_absolute_error: 11713.0547 - val_loss: 20839.5898 - val_mean_absolute_error: 20839.5898\n",
      "Epoch 365/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12362.8398 - mean_absolute_error: 12362.8398\n",
      "Epoch 00365: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12354.3330 - mean_absolute_error: 12354.3330 - val_loss: 21940.6465 - val_mean_absolute_error: 21940.6465\n",
      "Epoch 366/500\n",
      "18/37 [=============>................] - ETA: 0s - loss: 13537.2070 - mean_absolute_error: 13537.2070\n",
      "Epoch 00366: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12101.2266 - mean_absolute_error: 12101.2266 - val_loss: 21274.9102 - val_mean_absolute_error: 21274.9102\n",
      "Epoch 367/500\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11233.2676 - mean_absolute_error: 11233.2676\n",
      "Epoch 00367: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11314.6211 - mean_absolute_error: 11314.6211 - val_loss: 20292.2715 - val_mean_absolute_error: 20292.2715\n",
      "Epoch 368/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12563.6396 - mean_absolute_error: 12563.6396\n",
      "Epoch 00368: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11954.3838 - mean_absolute_error: 11954.3838 - val_loss: 21066.0820 - val_mean_absolute_error: 21066.0820\n",
      "Epoch 369/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 10819.8994 - mean_absolute_error: 10819.8994\n",
      "Epoch 00369: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 6ms/step - loss: 10819.8994 - mean_absolute_error: 10819.8994 - val_loss: 20189.8594 - val_mean_absolute_error: 20189.8594\n",
      "Epoch 370/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13597.0361 - mean_absolute_error: 13597.0361\n",
      "Epoch 00370: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 14266.9854 - mean_absolute_error: 14266.9854 - val_loss: 20214.9883 - val_mean_absolute_error: 20214.9883\n",
      "Epoch 371/500\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 14957.2080 - mean_absolute_error: 14957.2080\n",
      "Epoch 00371: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 13910.3271 - mean_absolute_error: 13910.3271 - val_loss: 19880.6602 - val_mean_absolute_error: 19880.6602\n",
      "Epoch 372/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 11196.3730 - mean_absolute_error: 11196.3730\n",
      "Epoch 00372: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11718.0488 - mean_absolute_error: 11718.0488 - val_loss: 21426.4492 - val_mean_absolute_error: 21426.4492\n",
      "Epoch 373/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12275.2998 - mean_absolute_error: 12275.2998\n",
      "Epoch 00373: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12387.1572 - mean_absolute_error: 12387.1572 - val_loss: 19887.1055 - val_mean_absolute_error: 19887.1055\n",
      "Epoch 374/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12113.5537 - mean_absolute_error: 12113.5537\n",
      "Epoch 00374: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11705.2988 - mean_absolute_error: 11705.2988 - val_loss: 19908.5098 - val_mean_absolute_error: 19908.5098\n",
      "Epoch 375/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 11603.8516 - mean_absolute_error: 11603.8516\n",
      "Epoch 00375: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11600.1533 - mean_absolute_error: 11600.1533 - val_loss: 20250.4707 - val_mean_absolute_error: 20250.4707\n",
      "Epoch 376/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11345.5586 - mean_absolute_error: 11345.5586\n",
      "Epoch 00376: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11690.0078 - mean_absolute_error: 11690.0078 - val_loss: 20610.8320 - val_mean_absolute_error: 20610.8320\n",
      "Epoch 377/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 11784.0488 - mean_absolute_error: 11784.0488\n",
      "Epoch 00377: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11903.3047 - mean_absolute_error: 11903.3047 - val_loss: 20878.3965 - val_mean_absolute_error: 20878.3965\n",
      "Epoch 378/500\n",
      "18/37 [=============>................] - ETA: 0s - loss: 13115.2314 - mean_absolute_error: 13115.2314\n",
      "Epoch 00378: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12963.0059 - mean_absolute_error: 12963.0059 - val_loss: 21922.7383 - val_mean_absolute_error: 21922.7383\n",
      "Epoch 379/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11370.5244 - mean_absolute_error: 11370.5244\n",
      "Epoch 00379: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11288.1748 - mean_absolute_error: 11288.1748 - val_loss: 20008.5996 - val_mean_absolute_error: 20008.5996\n",
      "Epoch 380/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11288.2734 - mean_absolute_error: 11288.2734\n",
      "Epoch 00380: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11323.5137 - mean_absolute_error: 11323.5137 - val_loss: 20306.1797 - val_mean_absolute_error: 20306.1797\n",
      "Epoch 381/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 10728.8047 - mean_absolute_error: 10728.8047\n",
      "Epoch 00381: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11459.8184 - mean_absolute_error: 11459.8184 - val_loss: 22666.7539 - val_mean_absolute_error: 22666.7539\n",
      "Epoch 382/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11835.4785 - mean_absolute_error: 11835.4785\n",
      "Epoch 00382: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12285.8701 - mean_absolute_error: 12285.8701 - val_loss: 23647.0137 - val_mean_absolute_error: 23647.0137\n",
      "Epoch 383/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13127.0723 - mean_absolute_error: 13127.0723\n",
      "Epoch 00383: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12567.2432 - mean_absolute_error: 12567.2432 - val_loss: 20460.8457 - val_mean_absolute_error: 20460.8457\n",
      "Epoch 384/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 10738.4482 - mean_absolute_error: 10738.4482\n",
      "Epoch 00384: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11140.0645 - mean_absolute_error: 11140.0645 - val_loss: 20281.5762 - val_mean_absolute_error: 20281.5762\n",
      "Epoch 385/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11861.9717 - mean_absolute_error: 11861.9717\n",
      "Epoch 00385: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11646.0791 - mean_absolute_error: 11646.0791 - val_loss: 20174.1113 - val_mean_absolute_error: 20174.1113\n",
      "Epoch 386/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11386.3711 - mean_absolute_error: 11386.3711\n",
      "Epoch 00386: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11093.3975 - mean_absolute_error: 11093.3975 - val_loss: 20215.8262 - val_mean_absolute_error: 20215.8262\n",
      "Epoch 387/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11489.9111 - mean_absolute_error: 11489.9111\n",
      "Epoch 00387: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11896.5732 - mean_absolute_error: 11896.5732 - val_loss: 20640.7891 - val_mean_absolute_error: 20640.7891\n",
      "Epoch 388/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11681.3857 - mean_absolute_error: 11681.3857\n",
      "Epoch 00388: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11960.3096 - mean_absolute_error: 11960.3096 - val_loss: 20215.8281 - val_mean_absolute_error: 20215.8281\n",
      "Epoch 389/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12419.7627 - mean_absolute_error: 12419.7627\n",
      "Epoch 00389: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12374.0996 - mean_absolute_error: 12374.0996 - val_loss: 20452.3438 - val_mean_absolute_error: 20452.3438\n",
      "Epoch 390/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11723.1416 - mean_absolute_error: 11723.1416\n",
      "Epoch 00390: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11355.8818 - mean_absolute_error: 11355.8818 - val_loss: 24180.3750 - val_mean_absolute_error: 24180.3750\n",
      "Epoch 391/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 13589.2715 - mean_absolute_error: 13589.2715\n",
      "Epoch 00391: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12737.1357 - mean_absolute_error: 12737.1357 - val_loss: 20703.4805 - val_mean_absolute_error: 20703.4805\n",
      "Epoch 392/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11161.5117 - mean_absolute_error: 11161.5117\n",
      "Epoch 00392: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11611.8936 - mean_absolute_error: 11611.8936 - val_loss: 22381.9238 - val_mean_absolute_error: 22381.9238\n",
      "Epoch 393/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13123.6104 - mean_absolute_error: 13123.6104\n",
      "Epoch 00393: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13454.0928 - mean_absolute_error: 13454.0928 - val_loss: 19971.0137 - val_mean_absolute_error: 19971.0137\n",
      "Epoch 394/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 12148.8193 - mean_absolute_error: 12148.8193\n",
      "Epoch 00394: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11866.1729 - mean_absolute_error: 11866.1729 - val_loss: 20937.7891 - val_mean_absolute_error: 20937.7891\n",
      "Epoch 395/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12910.2510 - mean_absolute_error: 12910.2510\n",
      "Epoch 00395: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12429.2646 - mean_absolute_error: 12429.2646 - val_loss: 19702.8926 - val_mean_absolute_error: 19702.8926\n",
      "Epoch 396/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12969.6514 - mean_absolute_error: 12969.6514\n",
      "Epoch 00396: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12796.3076 - mean_absolute_error: 12796.3076 - val_loss: 20409.5078 - val_mean_absolute_error: 20409.5078\n",
      "Epoch 397/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12172.7783 - mean_absolute_error: 12172.7783\n",
      "Epoch 00397: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12432.3164 - mean_absolute_error: 12432.3164 - val_loss: 20574.4004 - val_mean_absolute_error: 20574.4004\n",
      "Epoch 398/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12589.7402 - mean_absolute_error: 12589.7402\n",
      "Epoch 00398: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12968.0547 - mean_absolute_error: 12968.0547 - val_loss: 20968.5625 - val_mean_absolute_error: 20968.5625\n",
      "Epoch 399/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 12013.0449 - mean_absolute_error: 12013.0449\n",
      "Epoch 00399: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11900.2354 - mean_absolute_error: 11900.2354 - val_loss: 20869.7930 - val_mean_absolute_error: 20869.7930\n",
      "Epoch 400/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12640.8564 - mean_absolute_error: 12640.8564\n",
      "Epoch 00400: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12158.8916 - mean_absolute_error: 12158.8916 - val_loss: 20884.5020 - val_mean_absolute_error: 20884.5020\n",
      "Epoch 401/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11678.1553 - mean_absolute_error: 11678.1553\n",
      "Epoch 00401: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11426.7920 - mean_absolute_error: 11426.7920 - val_loss: 19780.4316 - val_mean_absolute_error: 19780.4316\n",
      "Epoch 402/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11929.6426 - mean_absolute_error: 11929.6426\n",
      "Epoch 00402: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11648.4316 - mean_absolute_error: 11648.4316 - val_loss: 21154.6621 - val_mean_absolute_error: 21154.6621\n",
      "Epoch 403/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 11834.2500 - mean_absolute_error: 11834.2500\n",
      "Epoch 00403: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12087.5811 - mean_absolute_error: 12087.5811 - val_loss: 21180.7598 - val_mean_absolute_error: 21180.7598\n",
      "Epoch 404/500\n",
      "28/37 [=====================>........] - ETA: 0s - loss: 13043.7207 - mean_absolute_error: 13043.7207\n",
      "Epoch 00404: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 13192.7295 - mean_absolute_error: 13192.7295 - val_loss: 20079.1191 - val_mean_absolute_error: 20079.1191\n",
      "Epoch 405/500\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11652.1562 - mean_absolute_error: 11652.1562\n",
      "Epoch 00405: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11664.9199 - mean_absolute_error: 11664.9199 - val_loss: 20443.0352 - val_mean_absolute_error: 20443.0352\n",
      "Epoch 406/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12528.8398 - mean_absolute_error: 12528.8398\n",
      "Epoch 00406: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11972.4609 - mean_absolute_error: 11972.4609 - val_loss: 20051.5645 - val_mean_absolute_error: 20051.5645\n",
      "Epoch 407/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 10918.8857 - mean_absolute_error: 10918.8857\n",
      "Epoch 00407: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12255.5918 - mean_absolute_error: 12255.5918 - val_loss: 23979.8398 - val_mean_absolute_error: 23979.8398\n",
      "Epoch 408/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14961.0674 - mean_absolute_error: 14961.0674\n",
      "Epoch 00408: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13686.4111 - mean_absolute_error: 13686.4111 - val_loss: 20093.9688 - val_mean_absolute_error: 20093.9688\n",
      "Epoch 409/500\n",
      "35/37 [===========================>..] - ETA: 0s - loss: 11703.4229 - mean_absolute_error: 11703.4229\n",
      "Epoch 00409: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11664.2783 - mean_absolute_error: 11664.2783 - val_loss: 20136.4609 - val_mean_absolute_error: 20136.4609\n",
      "Epoch 410/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/37 [===============>..............] - ETA: 0s - loss: 11117.7617 - mean_absolute_error: 11117.7617\n",
      "Epoch 00410: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11225.0098 - mean_absolute_error: 11225.0098 - val_loss: 20305.8672 - val_mean_absolute_error: 20305.8672\n",
      "Epoch 411/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12308.4062 - mean_absolute_error: 12308.4062\n",
      "Epoch 00411: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12224.7998 - mean_absolute_error: 12224.7998 - val_loss: 20786.4277 - val_mean_absolute_error: 20786.4277\n",
      "Epoch 412/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 10224.6787 - mean_absolute_error: 10224.6787\n",
      "Epoch 00412: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10696.1914 - mean_absolute_error: 10696.1914 - val_loss: 19738.7500 - val_mean_absolute_error: 19738.7500\n",
      "Epoch 413/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11660.4834 - mean_absolute_error: 11660.4834\n",
      "Epoch 00413: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11548.0410 - mean_absolute_error: 11548.0410 - val_loss: 21255.9922 - val_mean_absolute_error: 21255.9922\n",
      "Epoch 414/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12675.5547 - mean_absolute_error: 12675.5547\n",
      "Epoch 00414: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13251.5371 - mean_absolute_error: 13251.5371 - val_loss: 20815.7578 - val_mean_absolute_error: 20815.7578\n",
      "Epoch 415/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13126.5830 - mean_absolute_error: 13126.5830\n",
      "Epoch 00415: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13001.9229 - mean_absolute_error: 13001.9229 - val_loss: 20211.1973 - val_mean_absolute_error: 20211.1973\n",
      "Epoch 416/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11767.3584 - mean_absolute_error: 11767.3584\n",
      "Epoch 00416: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11838.6846 - mean_absolute_error: 11838.6846 - val_loss: 19671.6328 - val_mean_absolute_error: 19671.6328\n",
      "Epoch 417/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11069.8604 - mean_absolute_error: 11069.8604\n",
      "Epoch 00417: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11587.3086 - mean_absolute_error: 11587.3086 - val_loss: 21979.0742 - val_mean_absolute_error: 21979.0742\n",
      "Epoch 418/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 10576.8447 - mean_absolute_error: 10576.8447\n",
      "Epoch 00418: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10733.3838 - mean_absolute_error: 10733.3838 - val_loss: 21863.6758 - val_mean_absolute_error: 21863.6758\n",
      "Epoch 419/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 10886.0957 - mean_absolute_error: 10886.0957\n",
      "Epoch 00419: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11402.3164 - mean_absolute_error: 11402.3164 - val_loss: 22599.8105 - val_mean_absolute_error: 22599.8105\n",
      "Epoch 420/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11828.7588 - mean_absolute_error: 11828.7588\n",
      "Epoch 00420: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12333.4902 - mean_absolute_error: 12333.4902 - val_loss: 24282.4531 - val_mean_absolute_error: 24282.4531\n",
      "Epoch 421/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 13429.6543 - mean_absolute_error: 13429.6543\n",
      "Epoch 00421: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12848.1699 - mean_absolute_error: 12848.1699 - val_loss: 20513.7754 - val_mean_absolute_error: 20513.7754\n",
      "Epoch 422/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13744.7031 - mean_absolute_error: 13744.7031\n",
      "Epoch 00422: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14514.4795 - mean_absolute_error: 14514.4795 - val_loss: 20073.9277 - val_mean_absolute_error: 20073.9277\n",
      "Epoch 423/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11550.8027 - mean_absolute_error: 11550.8027\n",
      "Epoch 00423: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11601.8086 - mean_absolute_error: 11601.8086 - val_loss: 22926.9844 - val_mean_absolute_error: 22926.9844\n",
      "Epoch 424/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11645.9639 - mean_absolute_error: 11645.9639\n",
      "Epoch 00424: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12118.8750 - mean_absolute_error: 12118.8750 - val_loss: 20208.1621 - val_mean_absolute_error: 20208.1621\n",
      "Epoch 425/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12041.2080 - mean_absolute_error: 12041.2080\n",
      "Epoch 00425: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11844.4199 - mean_absolute_error: 11844.4199 - val_loss: 19983.1699 - val_mean_absolute_error: 19983.1699\n",
      "Epoch 426/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 10590.8438 - mean_absolute_error: 10590.8438\n",
      "Epoch 00426: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10746.2959 - mean_absolute_error: 10746.2959 - val_loss: 20768.4609 - val_mean_absolute_error: 20768.4609\n",
      "Epoch 427/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 10957.9697 - mean_absolute_error: 10957.9697\n",
      "Epoch 00427: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10938.4219 - mean_absolute_error: 10938.4219 - val_loss: 19945.8750 - val_mean_absolute_error: 19945.8750\n",
      "Epoch 428/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11755.0586 - mean_absolute_error: 11755.0586\n",
      "Epoch 00428: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11709.5215 - mean_absolute_error: 11709.5215 - val_loss: 20458.3242 - val_mean_absolute_error: 20458.3242\n",
      "Epoch 429/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11067.8506 - mean_absolute_error: 11067.8506\n",
      "Epoch 00429: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11312.7812 - mean_absolute_error: 11312.7812 - val_loss: 20016.4648 - val_mean_absolute_error: 20016.4648\n",
      "Epoch 430/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12170.0371 - mean_absolute_error: 12170.0371\n",
      "Epoch 00430: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11981.6064 - mean_absolute_error: 11981.6064 - val_loss: 24360.8535 - val_mean_absolute_error: 24360.8535\n",
      "Epoch 431/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 13796.5566 - mean_absolute_error: 13796.5566\n",
      "Epoch 00431: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13856.9277 - mean_absolute_error: 13856.9277 - val_loss: 20243.0078 - val_mean_absolute_error: 20243.0078\n",
      "Epoch 432/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 14908.5703 - mean_absolute_error: 14908.5703\n",
      "Epoch 00432: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13842.7783 - mean_absolute_error: 13842.7783 - val_loss: 20169.2012 - val_mean_absolute_error: 20169.2012\n",
      "Epoch 433/500\n",
      "26/37 [====================>.........] - ETA: 0s - loss: 11841.2168 - mean_absolute_error: 11841.2168\n",
      "Epoch 00433: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11757.8154 - mean_absolute_error: 11757.8154 - val_loss: 20015.2578 - val_mean_absolute_error: 20015.2578\n",
      "Epoch 434/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 10896.9590 - mean_absolute_error: 10896.9590\n",
      "Epoch 00434: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10873.6758 - mean_absolute_error: 10873.6758 - val_loss: 20119.7266 - val_mean_absolute_error: 20119.7266\n",
      "Epoch 435/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11169.6719 - mean_absolute_error: 11169.6719\n",
      "Epoch 00435: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10894.7002 - mean_absolute_error: 10894.7002 - val_loss: 20058.4512 - val_mean_absolute_error: 20058.4512\n",
      "Epoch 436/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 12063.3652 - mean_absolute_error: 12063.3652\n",
      "Epoch 00436: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13983.5449 - mean_absolute_error: 13983.5449 - val_loss: 23742.6465 - val_mean_absolute_error: 23742.6465\n",
      "Epoch 437/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 12839.5400 - mean_absolute_error: 12839.5400\n",
      "Epoch 00437: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12685.9844 - mean_absolute_error: 12685.9844 - val_loss: 21154.7578 - val_mean_absolute_error: 21154.7578\n",
      "Epoch 438/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11603.4297 - mean_absolute_error: 11603.4297\n",
      "Epoch 00438: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11887.9561 - mean_absolute_error: 11887.9561 - val_loss: 21573.5117 - val_mean_absolute_error: 21573.5117\n",
      "Epoch 439/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 14405.2900 - mean_absolute_error: 14405.2900\n",
      "Epoch 00439: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13375.6816 - mean_absolute_error: 13375.6816 - val_loss: 20057.0020 - val_mean_absolute_error: 20057.0020\n",
      "Epoch 440/500\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 10833.2646 - mean_absolute_error: 10833.2646\n",
      "Epoch 00440: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 10872.1504 - mean_absolute_error: 10872.1504 - val_loss: 20277.1016 - val_mean_absolute_error: 20277.1016\n",
      "Epoch 441/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11113.9141 - mean_absolute_error: 11113.9141\n",
      "Epoch 00441: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11165.4238 - mean_absolute_error: 11165.4238 - val_loss: 20643.4629 - val_mean_absolute_error: 20643.4629\n",
      "Epoch 442/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 10712.8428 - mean_absolute_error: 10712.8428\n",
      "Epoch 00442: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10817.1504 - mean_absolute_error: 10817.1504 - val_loss: 20823.2344 - val_mean_absolute_error: 20823.2344\n",
      "Epoch 443/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11592.2852 - mean_absolute_error: 11592.2852\n",
      "Epoch 00443: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12090.3311 - mean_absolute_error: 12090.3311 - val_loss: 23162.0625 - val_mean_absolute_error: 23162.0625\n",
      "Epoch 444/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 14530.6289 - mean_absolute_error: 14530.6289\n",
      "Epoch 00444: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 14115.6123 - mean_absolute_error: 14115.6123 - val_loss: 21628.8164 - val_mean_absolute_error: 21628.8164\n",
      "Epoch 445/500\n",
      "18/37 [=============>................] - ETA: 0s - loss: 11642.4746 - mean_absolute_error: 11642.4746\n",
      "Epoch 00445: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11924.6592 - mean_absolute_error: 11924.6592 - val_loss: 20273.5918 - val_mean_absolute_error: 20273.5918\n",
      "Epoch 446/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12337.8486 - mean_absolute_error: 12337.8486\n",
      "Epoch 00446: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12000.8887 - mean_absolute_error: 12000.8887 - val_loss: 20234.5332 - val_mean_absolute_error: 20234.5332\n",
      "Epoch 447/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11250.0459 - mean_absolute_error: 11250.0459\n",
      "Epoch 00447: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11481.6084 - mean_absolute_error: 11481.6084 - val_loss: 19759.5762 - val_mean_absolute_error: 19759.5762\n",
      "Epoch 448/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12259.4014 - mean_absolute_error: 12259.4014\n",
      "Epoch 00448: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11891.2939 - mean_absolute_error: 11891.2939 - val_loss: 19701.5215 - val_mean_absolute_error: 19701.5215\n",
      "Epoch 449/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 10655.8828 - mean_absolute_error: 10655.8828\n",
      "Epoch 00449: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11108.9736 - mean_absolute_error: 11108.9736 - val_loss: 19867.6777 - val_mean_absolute_error: 19867.6777\n",
      "Epoch 450/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 12111.9766 - mean_absolute_error: 12111.9766\n",
      "Epoch 00450: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12032.8301 - mean_absolute_error: 12032.8301 - val_loss: 22993.6230 - val_mean_absolute_error: 22993.6230\n",
      "Epoch 451/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12082.0732 - mean_absolute_error: 12082.0732\n",
      "Epoch 00451: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11735.9150 - mean_absolute_error: 11735.9150 - val_loss: 22336.9219 - val_mean_absolute_error: 22336.9219\n",
      "Epoch 452/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13010.7188 - mean_absolute_error: 13010.7188\n",
      "Epoch 00452: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12165.5361 - mean_absolute_error: 12165.5361 - val_loss: 19555.8867 - val_mean_absolute_error: 19555.8867\n",
      "Epoch 453/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 10973.1982 - mean_absolute_error: 10973.1982\n",
      "Epoch 00453: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12119.3350 - mean_absolute_error: 12119.3350 - val_loss: 20639.9180 - val_mean_absolute_error: 20639.9180\n",
      "Epoch 454/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12087.6104 - mean_absolute_error: 12087.6104\n",
      "Epoch 00454: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11766.2119 - mean_absolute_error: 11766.2119 - val_loss: 20399.5840 - val_mean_absolute_error: 20399.5840\n",
      "Epoch 455/500\n",
      "17/37 [============>.................] - ETA: 0s - loss: 10998.1836 - mean_absolute_error: 10998.1836\n",
      "Epoch 00455: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10994.2529 - mean_absolute_error: 10994.2529 - val_loss: 19599.4805 - val_mean_absolute_error: 19599.4805\n",
      "Epoch 456/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11803.3672 - mean_absolute_error: 11803.3672\n",
      "Epoch 00456: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12336.6914 - mean_absolute_error: 12336.6914 - val_loss: 24282.6758 - val_mean_absolute_error: 24282.6758\n",
      "Epoch 457/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13062.0283 - mean_absolute_error: 13062.0283\n",
      "Epoch 00457: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12699.7539 - mean_absolute_error: 12699.7539 - val_loss: 21996.6641 - val_mean_absolute_error: 21996.6641\n",
      "Epoch 458/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/37 [================>.............] - ETA: 0s - loss: 12221.0352 - mean_absolute_error: 12221.0352\n",
      "Epoch 00458: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11788.3613 - mean_absolute_error: 11788.3613 - val_loss: 20343.4160 - val_mean_absolute_error: 20343.4160\n",
      "Epoch 459/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 10699.3320 - mean_absolute_error: 10699.3320\n",
      "Epoch 00459: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11159.8857 - mean_absolute_error: 11159.8857 - val_loss: 22666.6465 - val_mean_absolute_error: 22666.6465\n",
      "Epoch 460/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 12233.7773 - mean_absolute_error: 12233.7773\n",
      "Epoch 00460: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12565.0156 - mean_absolute_error: 12565.0156 - val_loss: 21091.7969 - val_mean_absolute_error: 21091.7969\n",
      "Epoch 461/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 11260.3145 - mean_absolute_error: 11260.3145\n",
      "Epoch 00461: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12473.9092 - mean_absolute_error: 12473.9092 - val_loss: 21026.3555 - val_mean_absolute_error: 21026.3555\n",
      "Epoch 462/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 10620.5488 - mean_absolute_error: 10620.5488\n",
      "Epoch 00462: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10675.5957 - mean_absolute_error: 10675.5957 - val_loss: 19981.7031 - val_mean_absolute_error: 19981.7031\n",
      "Epoch 463/500\n",
      "23/37 [=================>............] - ETA: 0s - loss: 11069.3604 - mean_absolute_error: 11069.3604\n",
      "Epoch 00463: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10722.1494 - mean_absolute_error: 10722.1494 - val_loss: 24429.3613 - val_mean_absolute_error: 24429.3613\n",
      "Epoch 464/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 13067.3477 - mean_absolute_error: 13067.3477\n",
      "Epoch 00464: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12328.9629 - mean_absolute_error: 12328.9629 - val_loss: 21248.3125 - val_mean_absolute_error: 21248.3125\n",
      "Epoch 465/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 13398.0420 - mean_absolute_error: 13398.0420\n",
      "Epoch 00465: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13557.1035 - mean_absolute_error: 13557.1035 - val_loss: 22533.9941 - val_mean_absolute_error: 22533.9941\n",
      "Epoch 466/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 14071.1416 - mean_absolute_error: 14071.1416\n",
      "Epoch 00466: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12805.0869 - mean_absolute_error: 12805.0869 - val_loss: 20190.8730 - val_mean_absolute_error: 20190.8730\n",
      "Epoch 467/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 10461.8662 - mean_absolute_error: 10461.8662\n",
      "Epoch 00467: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10804.9258 - mean_absolute_error: 10804.9258 - val_loss: 20031.2422 - val_mean_absolute_error: 20031.2422\n",
      "Epoch 468/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 10642.4629 - mean_absolute_error: 10642.4629\n",
      "Epoch 00468: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10934.4902 - mean_absolute_error: 10934.4902 - val_loss: 20521.8086 - val_mean_absolute_error: 20521.8086\n",
      "Epoch 469/500\n",
      "25/37 [===================>..........] - ETA: 0s - loss: 11436.9951 - mean_absolute_error: 11436.9951\n",
      "Epoch 00469: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 11234.7646 - mean_absolute_error: 11234.7646 - val_loss: 20939.3457 - val_mean_absolute_error: 20939.3457\n",
      "Epoch 470/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 10446.6699 - mean_absolute_error: 10446.6699\n",
      "Epoch 00470: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 10601.9951 - mean_absolute_error: 10601.9951 - val_loss: 20466.7715 - val_mean_absolute_error: 20466.7715\n",
      "Epoch 471/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 10967.1094 - mean_absolute_error: 10967.1094\n",
      "Epoch 00471: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11041.9863 - mean_absolute_error: 11041.9863 - val_loss: 19821.4375 - val_mean_absolute_error: 19821.4375\n",
      "Epoch 472/500\n",
      "36/37 [============================>.] - ETA: 0s - loss: 11771.9111 - mean_absolute_error: 11771.9111\n",
      "Epoch 00472: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11861.3594 - mean_absolute_error: 11861.3594 - val_loss: 21365.1914 - val_mean_absolute_error: 21365.1914\n",
      "Epoch 473/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 12818.0771 - mean_absolute_error: 12818.0771\n",
      "Epoch 00473: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12090.4922 - mean_absolute_error: 12090.4922 - val_loss: 20459.1602 - val_mean_absolute_error: 20459.1602\n",
      "Epoch 474/500\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 10982.1641 - mean_absolute_error: 10982.1641\n",
      "Epoch 00474: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 10949.8164 - mean_absolute_error: 10949.8164 - val_loss: 19450.1465 - val_mean_absolute_error: 19450.1465\n",
      "Epoch 475/500\n",
      "27/37 [====================>.........] - ETA: 0s - loss: 11428.1650 - mean_absolute_error: 11428.1650\n",
      "Epoch 00475: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 11469.5811 - mean_absolute_error: 11469.5811 - val_loss: 20300.0957 - val_mean_absolute_error: 20300.0957\n",
      "Epoch 476/500\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 11120.4238 - mean_absolute_error: 11120.4238\n",
      "Epoch 00476: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11054.2881 - mean_absolute_error: 11054.2881 - val_loss: 20012.1035 - val_mean_absolute_error: 20012.1035\n",
      "Epoch 477/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11723.2139 - mean_absolute_error: 11723.2139\n",
      "Epoch 00477: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 13356.0586 - mean_absolute_error: 13356.0586 - val_loss: 20472.5020 - val_mean_absolute_error: 20472.5020\n",
      "Epoch 478/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12318.3203 - mean_absolute_error: 12318.3203\n",
      "Epoch 00478: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12155.9600 - mean_absolute_error: 12155.9600 - val_loss: 21660.0410 - val_mean_absolute_error: 21660.0410\n",
      "Epoch 479/500\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 11335.9951 - mean_absolute_error: 11335.9951\n",
      "Epoch 00479: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11248.9756 - mean_absolute_error: 11248.9756 - val_loss: 20359.7305 - val_mean_absolute_error: 20359.7305\n",
      "Epoch 480/500\n",
      "36/37 [============================>.] - ETA: 0s - loss: 10842.8359 - mean_absolute_error: 10842.8359\n",
      "Epoch 00480: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 10853.4609 - mean_absolute_error: 10853.4609 - val_loss: 21690.9785 - val_mean_absolute_error: 21690.9785\n",
      "Epoch 481/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 10620.9736 - mean_absolute_error: 10620.9736\n",
      "Epoch 00481: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11878.4082 - mean_absolute_error: 11878.4082 - val_loss: 22685.4160 - val_mean_absolute_error: 22685.4160\n",
      "Epoch 482/500\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 11926.4482 - mean_absolute_error: 11926.4482\n",
      "Epoch 00482: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11655.7344 - mean_absolute_error: 11655.7344 - val_loss: 21011.0078 - val_mean_absolute_error: 21011.0078\n",
      "Epoch 483/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 10741.9287 - mean_absolute_error: 10741.9287\n",
      "Epoch 00483: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11008.3301 - mean_absolute_error: 11008.3301 - val_loss: 20784.9941 - val_mean_absolute_error: 20784.9941\n",
      "Epoch 484/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 12444.5410 - mean_absolute_error: 12444.5410\n",
      "Epoch 00484: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12406.0879 - mean_absolute_error: 12406.0879 - val_loss: 20679.2051 - val_mean_absolute_error: 20679.2051\n",
      "Epoch 485/500\n",
      "34/37 [==========================>...] - ETA: 0s - loss: 11922.6514 - mean_absolute_error: 11922.6514\n",
      "Epoch 00485: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12196.4561 - mean_absolute_error: 12196.4561 - val_loss: 19759.9648 - val_mean_absolute_error: 19759.9648\n",
      "Epoch 486/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 14200.9639 - mean_absolute_error: 14200.9639\n",
      "Epoch 00486: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12651.7051 - mean_absolute_error: 12651.7051 - val_loss: 20257.0488 - val_mean_absolute_error: 20257.0488\n",
      "Epoch 487/500\n",
      "20/37 [===============>..............] - ETA: 0s - loss: 10627.3828 - mean_absolute_error: 10627.3828\n",
      "Epoch 00487: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10781.2500 - mean_absolute_error: 10781.2500 - val_loss: 20374.6523 - val_mean_absolute_error: 20374.6523\n",
      "Epoch 488/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11549.6680 - mean_absolute_error: 11549.6680\n",
      "Epoch 00488: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12035.7051 - mean_absolute_error: 12035.7051 - val_loss: 19922.4922 - val_mean_absolute_error: 19922.4922\n",
      "Epoch 489/500\n",
      "32/37 [========================>.....] - ETA: 0s - loss: 11471.7832 - mean_absolute_error: 11471.7832\n",
      "Epoch 00489: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 5ms/step - loss: 11798.3926 - mean_absolute_error: 11798.3926 - val_loss: 21028.9238 - val_mean_absolute_error: 21028.9238\n",
      "Epoch 490/500\n",
      "37/37 [==============================] - ETA: 0s - loss: 12356.8105 - mean_absolute_error: 12356.8105\n",
      "Epoch 00490: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 12356.8105 - mean_absolute_error: 12356.8105 - val_loss: 21221.3145 - val_mean_absolute_error: 21221.3145\n",
      "Epoch 491/500\n",
      "19/37 [==============>...............] - ETA: 0s - loss: 11190.4424 - mean_absolute_error: 11190.4424\n",
      "Epoch 00491: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11630.2178 - mean_absolute_error: 11630.2178 - val_loss: 20009.7090 - val_mean_absolute_error: 20009.7090\n",
      "Epoch 492/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 11143.1992 - mean_absolute_error: 11143.1992\n",
      "Epoch 00492: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11286.8398 - mean_absolute_error: 11286.8398 - val_loss: 23877.7988 - val_mean_absolute_error: 23877.7988\n",
      "Epoch 493/500\n",
      "21/37 [================>.............] - ETA: 0s - loss: 13086.4551 - mean_absolute_error: 13086.4551\n",
      "Epoch 00493: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12361.8086 - mean_absolute_error: 12361.8086 - val_loss: 19394.7012 - val_mean_absolute_error: 19394.7012\n",
      "Epoch 494/500\n",
      "33/37 [=========================>....] - ETA: 0s - loss: 11569.0059 - mean_absolute_error: 11569.0059\n",
      "Epoch 00494: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 4ms/step - loss: 11446.1133 - mean_absolute_error: 11446.1133 - val_loss: 20280.5762 - val_mean_absolute_error: 20280.5762\n",
      "Epoch 495/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11858.4014 - mean_absolute_error: 11858.4014\n",
      "Epoch 00495: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11444.0576 - mean_absolute_error: 11444.0576 - val_loss: 20550.5996 - val_mean_absolute_error: 20550.5996\n",
      "Epoch 496/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 11403.3877 - mean_absolute_error: 11403.3877\n",
      "Epoch 00496: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11424.6426 - mean_absolute_error: 11424.6426 - val_loss: 19871.6113 - val_mean_absolute_error: 19871.6113\n",
      "Epoch 497/500\n",
      "22/37 [================>.............] - ETA: 0s - loss: 12773.8340 - mean_absolute_error: 12773.8340\n",
      "Epoch 00497: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 11788.4482 - mean_absolute_error: 11788.4482 - val_loss: 20347.3652 - val_mean_absolute_error: 20347.3652\n",
      "Epoch 498/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 11181.0166 - mean_absolute_error: 11181.0166\n",
      "Epoch 00498: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10789.2949 - mean_absolute_error: 10789.2949 - val_loss: 19926.7480 - val_mean_absolute_error: 19926.7480\n",
      "Epoch 499/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 10120.8496 - mean_absolute_error: 10120.8496\n",
      "Epoch 00499: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 10593.3770 - mean_absolute_error: 10593.3770 - val_loss: 21882.9336 - val_mean_absolute_error: 21882.9336\n",
      "Epoch 500/500\n",
      "24/37 [==================>...........] - ETA: 0s - loss: 13824.4443 - mean_absolute_error: 13824.4443\n",
      "Epoch 00500: val_loss did not improve from 19168.44141\n",
      "37/37 [==============================] - 0s 3ms/step - loss: 12784.2051 - mean_absolute_error: 12784.2051 - val_loss: 20578.6465 - val_mean_absolute_error: 20578.6465\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22c617d1160>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Third : Train the model :\n",
    "NN_model.fit(train, target, epochs=500, batch_size=32, validation_split = 0.2, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "twelve-detroit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A submission file has been made\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "def make_submission(prediction, sub_name):\n",
    "    my_submission = pd.DataFrame({'Id':pd.read_csv('test.csv').Id,'SalePrice':prediction})\n",
    "    my_submission.to_csv('{}.csv'.format(sub_name),index=False)\n",
    "    print('A submission file has been made')\n",
    "\n",
    "predictions = NN_model.predict(test)\n",
    "make_submission(predictions[:,0],'submission(NN).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "residential-gnome",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Weights-{epoch:03d}--{val_loss:.5f}.hdf5'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "standard-vegetation",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "united-valuation",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
